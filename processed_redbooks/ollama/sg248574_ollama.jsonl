{"text": "RedbooksData and AIFront cover\nSimplify Your AI Journey: \nUnleashing the Power of AI with IBM watsonx.ai\nDeepak Rangarao\nPhillip GerrardCharley BellerCarl BrokerDaniele ComiLakshmana EkambaramShuvanker GhoshKaren MedhatPayal PatelMatthew Price\nShirley ShumMark Simmonds\n\n\n\nIBM Redbooks\nSimplify Your AI Journey: Un leashing the Power of AI \nwith IBM watsonx.ai\nJanuary 2025\nSG24-8574-00\n\n\u00a9 Copyright International Bu siness Machines Corp oration 2025. All rights reserved.\nNote to U.S. Government Users Restricted Rights -- Use, duplication or disclosure re stricted by GSA ADP Schedule\nContract with IBM Corp.First Edition (January 2025)\nThis edition applies to Version 2, Release 1, Modification x of IBM watsonx.ai.Note: Before using this information and the product it supports, read the information in \u201cNotices\u201d on \npage vii.\n\n\u00a9 Copyright IBM Corp. 2025. iiiContents\nNotices  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .", "metadata": {"source": "sg248574.pdf", "chunk_index": 0, "total_chunks": 313}}
{"text": " . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . vii\nTrademarks  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . viii\nForeword . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  ix\nPreface. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ix\nAuthors. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .x\nNow you can become a published author, too!  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . xiiComments welcome. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . xii\nStay connected to IBM Redbooks . . . . . . . . . . . . . . . . . . . . ", "metadata": {"source": "sg248574.pdf", "chunk_index": 1, "total_chunks": 313}}
{"text": " . . . . . . . . . . . . xii\nStay connected to IBM Redbooks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . xiii\nChapter 1.  Competing with artificial intelligence . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1\n1.1  Competing with AI . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  . 2\n1.2  Challenges in building and deploying AI models. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4\n1.2.1  Technical considerations for building and deploying AI models . . . . . . . . . . . . . . . 5\n1.3  Opportunities around using AI on trusted data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\n1.3.1  Enhancing decision-making with accurate insights. . . . . . . . . . . . . . . . . . . . . . . . . 61.3.2  Driving operational efficiency  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6\n1.3.3  Accelerating innovation. . . ", "metadata": {"source": "sg248574.pdf", "chunk_index": 2, "total_chunks": 313}}
{"text": ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6\n1.3.3  Accelerating innovation. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7\n1.3.4  Enhancing governance and compliance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 71.3.5  Unlocking new revenue streams. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7\n1.3.6  Transforming industries with AI and trusted data . . . . . . . . . . . . . . . . . . . . . . . . . . 8\n1.4  Improving AI model reliability  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8\n1.4.1  Enabling cross-enterprise collaboration . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9\n1.4.2  Enhancing real-time decision-making . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9\n1.4.3  Scaling AI-driven ecosystems. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10", "metadata": {"source": "sg248574.pdf", "chunk_index": 3, "total_chunks": 313}}
{"text": "-driven ecosystems. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 101.4.4  Driving sustainability and environmental, social, and governance goals  . . . . . . . 10\n1.4.5  Personalizing customer experiences  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10\n1.5  Creating new AI-enabled products and services. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11\nChapter 2.  Introducing IBM watsonx.ai . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13\n2.1  Overview of watsonx.ai . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14\n2.1.1  Key capabilities . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14\n2.1.2  The watsonx.ai architecture  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 142.1.3  watsonx.ai empowering IBM Software offerings . . . . . . . . . . . . . . .", "metadata": {"source": "sg248574.pdf", "chunk_index": 4, "total_chunks": 313}}
{"text": " . . . . . . . . 142.1.3  watsonx.ai empowering IBM Software offerings . . . . . . . . . . . . . . . . . . . . . . . . . . 14\n2.1.4  Benefits of using watsonx.ai for businesses . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15\n2.2  Synergy between watsonx.ai and other components in the watsonx platform . . . . . . . 15\n2.2.1  Synergy between watsonx.ai and watsonx.data . . . . . . . . . . . . . . . . . . . . . . . . . . 15\n2.2.2  Synergy between watsonx.ai and watsonx.governance . . . . . . . . . . . . . . . . . . . . 16\n2.3  Business impact of these synergies . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16\nChapter 3.  Tools for diverse data science teams . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17\n3.1  Key personas for watsonx.ai . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18\n3.1.1  Data scientists. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .", "metadata": {"source": "sg248574.pdf", "chunk_index": 5, "total_chunks": 313}}
{"text": ".1  Data scientists. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1 8\n3.1.2  Machine learning engineers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18\n3.1.3  AI engineers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1 9\n3.2  Low-code, no-code, and full-code tools  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20\n3.2.1  No-code, low-code, and full-code tools on IBM watsonx.ai. . . . . . . . . . . . . . . . . . 20\nChapter 4.  Building and using artificial intelligence models  . . . . . . . . . . . . . . . . . . . . 27\n\niv Simplify Your AI Journey: Unleashing the Power of AI with IBM watsonx.ai4.1  Prerequisites and assumptions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28\n4.2  How to use this chapter. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ", "metadata": {"source": "sg248574.pdf", "chunk_index": 6, "total_chunks": 313}}
{"text": " 28\n4.2  How to use this chapter. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2 8\n4.3  Building and using AI models in watsonx.ai  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28\n4.3.1  Overview of the watsonx.ai platform . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 284.3.2  Key features and capa bilities  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29\n4.4  Getting started with watsonx.ai: Setting up the environment  . . . . . . . . . . . . . . . . . . . . 29\n4.5  Data preparation and ingestion for AI model building . . . . . . . . . . . . . . . . . . . . . . . . . . 34\n4.5.1  Understanding the importance of data in AI . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 34\n4.5.2  Preparing and cleaning data: data quality considerations. . . . . . . . . . . . . . . . . . . 35\n4.5.3  Handling missing data, outliers, and bias . . . . . . . . . . . . .", "metadata": {"source": "sg248574.pdf", "chunk_index": 7, "total_chunks": 313}}
{"text": " . . . . . . . . . . . 35\n4.5.3  Handling missing data, outliers, and bias . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 354.5.4  Ingesting data into watsonx.ai Studio . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36\n4.5.5  Connecting to data repositories and cloud services . . . . . . . . . . . . . . . . . . . . . . . 36\n4.6  Building AI models in watsonx.ai. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 38\n4.6.1  Choosing the right model for your use case . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 38\n4.6.2  Model creation workflow . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39\n4.7  Deploying AI models in watsonx.ai . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 40\n4.7.1  watsonx.ai Studio deployments  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 40\n4.8  watsonx.ai LLM deployment . . . . . .", "metadata": {"source": "sg248574.pdf", "chunk_index": 8, "total_chunks": 313}}
{"text": " . . . . . . . . . . . . . . . . . . . . . . . . . . . 40\n4.8  watsonx.ai LLM deployment . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 45\n4.8.1  Model packaging and exporting  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 45\n4.9  Operationalizing machine learning and LLM models  . . . . . . . . . . . . . . . . . . . . . . . . . . 50\n4.9.1  Calling ML models by using API calls . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 50\n4.9.2  Calling Prompt Lab LLM models by using API ca lls . . . . . . . . . . . . . . . . . . . . . . . 52\n4.9.3  IBM watsonx Assistant . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 53\n4.10  Additional information and where to go next . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 54\n4.10.1  Additional support and documentation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 554.10.2  watsonx.ai A", "metadata": {"source": "sg248574.pdf", "chunk_index": 9, "total_chunks": 313}}
{"text": "documentation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 554.10.2  watsonx.ai API reference  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 55\n4.10.3  watsonx.ai data pipeline and orchestration. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 55\nChapter 5.  Advanced capabilities of watsonx.ai  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 57\n5.1  Prompt engineering. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 58\n5.1.1  Prompting techniques . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 585.1.2  Importance of system tokens  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 59\n5.1.3  Model-specific peculiarities . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 59\n5.1.4  How watsonx.ai supports prompt engineering  . . . . . . . . . . . . . . . .", "metadata": {"source": "sg248574.pdf", "chunk_index": 10, "total_chunks": 313}}
{"text": " . . . . . . . 59\n5.1.4  How watsonx.ai supports prompt engineering  . . . . . . . . . . . . . . . . . . . . . . . . . . . 60\n5.2  Multitask prompt tuning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6 1\n5.2.1  Prompt tuning parameters  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 625.2.2  Interdependencies and holistic tuning strategies  . . . . . . . . . . . . . . . . . . . . . . . . . 63\n5.3  Fine-tuning  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 64\n5.3.1  Challenges with fine-tuning. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 645.3.2  How watsonx.ai addresses fine-tuning challenges . . . . . . . . . . . . . . . . . . . . . . . . 65\n5.4  InstructLab  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 67\n5.4.1  Advanta", "metadata": {"source": "sg248574.pdf", "chunk_index": 11, "total_chunks": 313}}
{"text": " . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 67\n5.4.1  Advantages of InstructLab  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 705.4.2  How to use InstructLab . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 71\n5.4.3  InstructLab on watsonx.ai Software-as-a-Service. . . . . . . . . . . . . . . . . . . . . . . . . 79\n5.4.4  InstructLab use case examples  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 84\nChapter 6.  Artificial intelligence agents  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 87\n6.1  What makes an AI agent. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 88\n6.2  Why AI agents are needed . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 94\n6.3  Multiple AI agents . . . . . . . . . . . . . . . . . . . . . . . . . .", "metadata": {"source": "sg248574.pdf", "chunk_index": 12, "total_chunks": 313}}
{"text": ". . . . . . . . . . . 94\n6.3  Multiple AI agents . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  . 95\n6.4  AI agents on watsonx.ai  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1006.5  AI agents use case examples . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 107\nChapter 7.  Use cases  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 109\n\n Contents v7.1  Using RAG to aid a medical school admissions office  . . . . . . . . . . . . . . . . . . . . . . . . 110\n7.1.1  The challenge . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 110\n7.1.2  The solution  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 110\n7.1.3  Special considerations  . . . . . . . . . . . . . . . . . . . . . . . . . . .", "metadata": {"source": "sg248574.pdf", "chunk_index": 13, "total_chunks": 313}}
{"text": ". . . . . . 110\n7.1.3  Special considerations  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 111\n7.2  Embedding workflow automation to streamline recommendations . . . . . . . . . . . . . . . 111\n7.2.1  The challenge . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 111\n7.2.2  The solution  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1127.2.3  Special considerations  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 113\nAbbreviations and acronyms  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 115\nRelated publications  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 117\nIBM Redbooks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 117", "metadata": {"source": "sg248574.pdf", "chunk_index": 14, "total_chunks": 313}}
{"text": " . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 117\nOnline resources  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 117\nHelp from IBM  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  . 118\n\nvi Simplify Your AI Journey: Unleashing the Power of AI with IBM watsonx.ai\n\n\u00a9 Copyright IBM Corp. 2025. viiNotices\nThis information was developed for prod ucts and services offered in the US . This material might be available \nfrom IBM in other languages. However, you may be required  to own a copy of the product or product version in \nthat language in order to access it. \nIBM may not offer the products, services, or features di scussed in this document in other countries. Consult \nyour local IBM representative for information on the produc ts and services currently available in your area. Any \nreference to an IBM produ", "metadata": {"source": "sg248574.pdf", "chunk_index": 15, "total_chunks": 313}}
{"text": "ation on the produc ts and services currently available in your area. Any \nreference to an IBM product, program, or service is not intended to state or imply that only that IBM product, \nprogram, or service may be used. Any functionally equi valent product, program, or service that does not \ninfringe any IBM intellectual property right may be used instead. However, it is t he user\u2019s responsibility to \nevaluate and verify the operation of any non-IBM product, program, or service. \nIBM may have patents or pending patent applications covering subject matter described in this document. The \nfurnishing of this document does not grant you any license to these patents. You can send license inquiries, in \nwriting, to:\nIBM Director of Licensing, IBM Corporation, North Castle Drive, MD-NC119, Armonk, NY 10504-1785, US \nINTERNATIONAL BUSINESS MACHINES CORPORATIO N PROVIDES THIS PUBLICATION \u201cAS IS\u201d \nWITHOUT WARRANTY OF ANY KIND, EITHER EXPRESS OR IMPLIED, INCLUDING, BUT NOT LIMITED \nTO, THE IMPLIE", "metadata": {"source": "sg248574.pdf", "chunk_index": 16, "total_chunks": 313}}
{"text": "\nWITHOUT WARRANTY OF ANY KIND, EITHER EXPRESS OR IMPLIED, INCLUDING, BUT NOT LIMITED \nTO, THE IMPLIED WARRANTIES OF NON-INFR INGEMENT, MERCHANTABILITY OR FITNESS FOR A \nPARTICULAR PURPOSE. Some jurisdictions do not allow disclaimer of express or implied warranties in \ncertain transactions, therefore, this statement may not apply to you. \nThis information could include technical inaccuracies or  typographical errors. Changes are periodically made \nto the information herein; th ese changes will be incorporated  in new editions of the publication. IBM may make \nimprovements and/or changes in the product(s) and/or the program(s) described in this publication at any time \nwithout notice. \nAny references in this information to non-IBM websites are provided for convenience only and do not in any \nmanner serve as an endorsement of those websites. The materials at those websites are not part of the \nmaterials for this IBM product and use of those websites is at your own risk. \nIBM may use or di", "metadata": {"source": "sg248574.pdf", "chunk_index": 17, "total_chunks": 313}}
{"text": "he \nmaterials for this IBM product and use of those websites is at your own risk. \nIBM may use or distribute any of the information you provide in any way it believes appropriate without \nincurring any obligation to you. \nThe performance data and c lient examples cited are presented fo r illustrative purposes only. Actual \nperformance results may vary depending on specific configurations and operating conditions. \nInformation concerning non-IBM products was obtained from the suppliers of those products, their published \nannouncements or other publicly available sources. IBM has not tested those products and cannot confirm the \naccuracy of performance, co mpatibility or any other clai ms related to non-IBM pr oducts. Questions on the \ncapabilities of non-IBM products should be addr essed to the suppliers of those products. \nStatements regarding IBM\u2019s future direction or intent are subject to change or withdrawal without notice, and \nrepresent goals and objectives only. \nThis information", "metadata": {"source": "sg248574.pdf", "chunk_index": 18, "total_chunks": 313}}
{"text": " to change or withdrawal without notice, and \nrepresent goals and objectives only. \nThis information contains exam ples of data and reports used in daily business operations. To illustrate them \nas completely as possible, the exam ples include the names of individual s, companies, brands, and products. \nAll of these names are fictitious and any similarity to  actual people or business enterprises is entirely \ncoincidental. \nCOPYRIGHT LICENSE:\nThis information contai ns sample application prog rams in source language, which illustrate programming \ntechniques on various operating platforms. You may co py, modify, and distribute these sample programs in \nany form without payment to IBM, for the purposes of developing, using, marketing or distributing application programs conforming to the application programming interface for the operating platform for which the sample \nprograms are written. These examples have not been th oroughly tested under all conditions. IBM, therefore, \ncannot guar", "metadata": {"source": "sg248574.pdf", "chunk_index": 19, "total_chunks": 313}}
{"text": ". These examples have not been th oroughly tested under all conditions. IBM, therefore, \ncannot guarantee or im ply reliability, serviceability, or function of  these programs. The sample programs are \nprovided \u201cAS IS\u201d, without warranty of any kind. IBM sha ll not be liable for any damages arising out of your use \nof the sample programs. \n\nviii Simplify Your AI Journey: Unleashi ng the Power of AI with IBM watsonx.aiTrademarks\nIBM, the IBM logo, and ibm.com are trademarks or regi stered trademarks of International Business Machines \nCorporation, registered in many jurisdictions worldwide. Other product and service names might be trademarks of IBM or other companies. A current list of IBM trademarks is available on the web at \u201cCopyright \nand trademark information\u201d at https://www.ibm.com/legal/copytrade.shtml  \nThe following terms are trademarks or registered trademarks of International Business Machines Corporation, \nand might also be trademarks or registered trademarks in other countri", "metadata": {"source": "sg248574.pdf", "chunk_index": 20, "total_chunks": 313}}
{"text": "siness Machines Corporation, \nand might also be trademarks or registered trademarks in other countries. \nCloudant\u00ae\nCognos\u00ae\nDataStage\u00ae\nDb2\u00aeIBM\u00ae\nIBM API Connect\u00ae\nIBM Cloud\u00aeIBM Instana\u2122\nIBM Spectrum\u00ae\nIBM Watson\u00ae\nInformix\u00aeInfoSphere\u00ae\nInstana\u00ae\nNetezza\u00aeOrchestrate\u00ae\nRedbooks\u00ae\nRedbooks (logo) \u00ae\nSPSS\u00aeTurbonomic\u00ae\nz/OS\u00ae\nThe following terms are trademarks of other companies:\nThe registered trademark Linux\u00ae is used pursuant to a sublicense from the Linux Foundation, the exclusive \nlicensee of Linus Torvalds, owner of  the mark on a worldwide basis.\nMicrosoft, and the Windows logo are trademarks of Microsoft Corporation in the United States, other \ncountries, or both.\nJava, and all Java-based trademarks and logos are trademarks or registered trademarks of Oracle and/or its \naffiliates.\nRed Hat, Fedora, OpenShift, are trademarks or registered trademarks of Red Hat, Inc. or its subsidiaries in \nthe United States and other countries.\nRStudio, and the RStudio logo are registered trademarks of RStudio, I", "metadata": {"source": "sg248574.pdf", "chunk_index": 21, "total_chunks": 313}}
{"text": "ed States and other countries.\nRStudio, and the RStudio logo are registered trademarks of RStudio, Inc.\nOther company, product, or service names may be trademarks or service marks of others. \n\n\n\u00a9 Copyright IBM Corp. 2025. ixForeword\nThis IBM Redbooks\u00ae publication is part of a trilogy that positions and explains IBM watsonx, \nwhich is IBM\u2019s strategic artificial intelligence (AI) and data platform. Each book focuses on \none of the three main components of the watsonx platform:\n/SM590000IBM watsonx.ai: A next-generation enterprise studio for AI builders to train, validate, tune, \nand deploy both traditional machine learning (ML) and new generative AI (gen AI) capabilities that are powered  by foundation models (FMs).\n/SM590000IBM watsonx.data: A fit-for-purpose data store that is built on an open lakehouse \narchitecture, and is optimized for different and governed data and AI workloads.\n/SM590000IBM watsonx.governance: A set of AI Governance capabilities that e nables trusted AI \nworkflow", "metadata": {"source": "sg248574.pdf", "chunk_index": 22, "total_chunks": 313}}
{"text": "590000IBM watsonx.governance: A set of AI Governance capabilities that e nables trusted AI \nworkflows, which help organizations implement and comply with ever-changing industry and government regulations.\nOrganizations have long recognized the value that IBM Redbooks publications provide in \nguiding them with best practices, frameworks, clear explanations, and use cases as part of their solution evaluations and implementations.\nThis trilogy of books was poss ible because of close collabo ration among many skilled and \ntalented authors that were selected from IBM Technical Sales, IBM Development, IBM Expert Labs, IBM Client Success Management, and consul ting services organizations to use their \ndiverse skills, experiences, and technical knowledge across the watsonx platform.\nThanks to the authors, contributors, reviewers, and the IBM Redbooks team for their \ndedication, time, and effort in making this publication a valuable asset that organizations can use as part of their journey to A", "metadata": {"source": "sg248574.pdf", "chunk_index": 23, "total_chunks": 313}}
{"text": "in making this publication a valuable asset that organizations can use as part of their journey to AI.\nThanks to Mark Simmonds and Deepak Rangarao for taking the lead in shaping this request \ninto yet another successful IBM Redbooks project.\nSteve Astorino, IBM General Manager - Development, Data, AI, and Sustainability\nPreface\nIBM watsonx is IBM\u2019s strategic AI and data platform. This book focuses on watsonx.ai , one of \nthe three main components of the platform. IBM watsonx.ai is a next-generation enterprise studio that you can use to train, validate (test), tune, and deploy both traditional ML and new gen AI capabilities, which are powered by FMs through an open and intuitive user interface (UI). This AI studio provides a range of FMs, training and tuning tools, and a cost-effective infrastructure that facilitates the entire data and AI lifecycle, from data preparation through model development, deployment, and monitoring. Th e studio also includes an FM library that \nprovides IBM\u00ae c", "metadata": {"source": "sg248574.pdf", "chunk_index": 24, "total_chunks": 313}}
{"text": "velopment, deployment, and monitoring. Th e studio also includes an FM library that \nprovides IBM\u00ae curated and trained FMs. FMs use a large, curated set of enterprise data that is backed by a robust filtering and cleansing process, and with an auditable data lineage. These models are trained on language and other modalities, such as code, time-series data, tabular data, geospatial data, and IT events data. \n\nx Simplify Your AI Journey: Unleashing the Power of AI with IBM watsonx.aiHere are some examples of the model categories:\n/SM590000fm.code: Models that automatically generate code for developers through a \nnatural-language interface to boost developer productivity and enable the automation of many IT tasks.\n/SM590000fm.NLP: A collection of large language models (LLMs) for specific or industry-specific \ndomains that use curated data to help mitigate bias and quickly make domains customizable by using client data.\n/SM590000fm.geospatial: Models that are built on climate and remote se", "metadata": {"source": "sg248574.pdf", "chunk_index": 25, "total_chunks": 313}}
{"text": "mizable by using client data.\n/SM590000fm.geospatial: Models that are built on climate and remote sensing data to help \norganizations understand and plan for changes in natural disaster patterns, biodiversity, \nland use, and other geophysical processe s that might impact their businesses\nThe watsonx.ai studio builds on  Hugging Face open-source libraries, which offer thousands of \nHugging Face open models and datasets. Users can leverage the power of IBM Granite LLMs, along with the latest Mistral, Llama, and other third-party LLMs. It is part of IBM's commitment to deliver an open ecosystem approach that enables users to leverage the best models and architecture for their unique business needs.\nThis IBM Redbooks publication provides a broad understanding of watsonx.ai concepts, its \narchitecture, and the services that are available with the product. Also, several common use cases and scenarios are include d that should help you better u nderstand the capabilities of \nthis product. Cod", "metadata": {"source": "sg248574.pdf", "chunk_index": 26, "total_chunks": 313}}
{"text": "enarios are include d that should help you better u nderstand the capabilities of \nthis product. Code samples of common scenarios are available at this GitHub repository . For \nmore examples, which include using Instructlab and AI agents, see this GitHub repository .\nThis publication is for watsonx customers who se ek best practices and real-world examples of \nhow to best implement their solu tions while optimizing the value of their existing and future \ntechnology, AI, data, and skills investments.\nAuthors\nThis book was produced by a team of specialists from around the world:\nDeepak Rangarao  is an IBM Distinguished Engineer and CTO who is responsible for \nTechnical Sales-Cloud Paks. He leads the technical sales team that helps organizations modernize their technology landscape with IBM Cloud Paks. He has broad, cross-industry experience in the data warehousing and analytics space from building analytic applications at large organizations and performing technical pre-sales for start-u", "metadata": {"source": "sg248574.pdf", "chunk_index": 27, "total_chunks": 313}}
{"text": "building analytic applications at large organizations and performing technical pre-sales for start-ups and large enterprise software vendors. Deepak has co-authored several books on many topics, such as OLAP analytics, change data capture, data warehousing, and object storage. He is a regular speaker at technical conferences. He is a certif ied technical specialist in Red Hat OpenShift, \nApache Spark, Microsoft SQL Server, and web development technologies.Note:  Here are the other books in the trilogy:\n/SM590000Simplify Your AI Journey: Ensuring Trustworthy AI with IBM watsonx.governance , \nSG24-8573\n/SM590000Simplify Your AI Journey: Unleashing the Power of AI with IBM watsonx.data,  \nSG24-8570\n\n Foreword xiPhillip Gerrard  is a Project Leader for the International Technical Support Organization \nworking out of Beaverton, Oregon. As part of IBM for over 15 years, he has authored and contributed to hundreds of technical documents that were published to IBM.com, and worked directly with", "metadata": {"source": "sg248574.pdf", "chunk_index": 28, "total_chunks": 313}}
{"text": "tributed to hundreds of technical documents that were published to IBM.com, and worked directly with IBM's largest customers to resolve cr itical situations. As a team lead and subject \nmatter expert (SME) for the IBM Spectrum\u00ae Protect support team, he is experienced in leading and growing international teams of talented IBM employees by developing and implementing team processes,  and creating and de livering education. Ph illip holds a degree \nin computer science and business admini stration from Oregon State University.\nCharley Beller  is a Principal Data Scientist and IBM Master Inventor. He  works with clients \nas the Worldwide Solution Engineering Lead for watsonx.ai and AI Assistants within Technology Expert Labs. Charley has been working with IBM language technologies since \njoining the Watson group in 2014. He is an inventor with over 100 patents, and holds a PhD in Cognitive Science.\nCarl Broker  is an AI Architect at IBM who specializes in enterprise gen AI solutions. With a", "metadata": {"source": "sg248574.pdf", "chunk_index": 29, "total_chunks": 313}}
{"text": "ience.\nCarl Broker  is an AI Architect at IBM who specializes in enterprise gen AI solutions. With a \nbackground in both gen AI and traditional data science, Carl leads design sessions and develops proof-of-concepts for clients. Before this role, he worked as an AI Engineer and Data Scientist at IBM, focusing on predictive modeling and AI-driven solutions. Carl holds a Master of Science degree from Johns Hopkins University. \nDaniele Comi  is a Data Scientist, AI Engineer, and Software Engineer at IBM Italy, with over \n3 years of experience in data analytics, ML, and deep learning (DL). His expertise spans the entire spectrum of AI, from architectural design to scientific research, with a focus on ML, reinforcement learning (RL), and DL. Daniele holds a master's degree in Computer Science \nEngineering, with a specialty in AI frameworks and models. At IBM, Daniele has been a key member of the AI and gen AI team in Italy, where he has designed and implemented complex AI and gen AI archite", "metadata": {"source": "sg248574.pdf", "chunk_index": 30, "total_chunks": 313}}
{"text": "the AI and gen AI team in Italy, where he has designed and implemented complex AI and gen AI architectures for many industr y applications. His technical expertise also \nincludes Fully Homomorphic Encrypted AI, which enables secure AI solutions that help ensure data privacy. \nLakshmana Ekambaram  is an IBM Senior Technical Leader with over 30 years of \nexperience in database development, advanc ed analytics, and building hybrid cloud \nsolutions. He is part of the IBM Expert La bs SWAT organization where he leads the data \nfabric and trusted AI journey for customers worldwide. He has developed many IBM certification courses and co-authored books about data science, AI, and data fabric. \nKaren Medhat is a Customer Success Manager Architect in the UK and the youngest \nIBM Certified Thought Leader Level 3 Techni cal Specialist. She is the Chair of the \nIBM Technical Consultancy Group and an IBM Academy of technology member. She holds a MSc degree with honors in Engineering in AI and Wirele", "metadata": {"source": "sg248574.pdf", "chunk_index": 31, "total_chunks": 313}}
{"text": "IBM Academy of technology member. She holds a MSc degree with honors in Engineering in AI and Wireless Sensor Networks from the Faculty of Engineering, Cairo University, and a BSc de gree with honors in Engineering from the \nFaculty of Engineering, Cairo University. She co-creates curriculum and exams for different \nIBM professional certificates. She also crea ted and co-created cour ses for the IBM Skills \nAcademy in various areas of IBM technologies. She serves on the review board of international conferences and journals in AI and wireless communication. She also is an IBM Inventor who is experienced in creating applications architecture and leading teams of different scales to deliver customers' projects successfully. She frequently mentors IT professionals to help them def ine their career goals, learn ne w technical skills, or acquire \nprofessional certifications. She has authored publications on cloud, IoT, AI, wireless networks, microservices architecture, and blockchain.\n\nxii ", "metadata": {"source": "sg248574.pdf", "chunk_index": 32, "total_chunks": 313}}
{"text": "publications on cloud, IoT, AI, wireless networks, microservices architecture, and blockchain.\n\nxii Simplify Your AI Journey: Unleashing the Power of AI with IBM watsonx.aiPayal Patel works in Data and AI Technical Content Development at IBM, where she creates \ntechnical learning materials for sellers, IBM Busi ness Partners, and clients to enable them to \nget the most value out of IBM Data and AI products and solutions. She has worked in various roles at IBM, which include marketing analytics and as a Solutions Architect in IBM Technology Expert Labs, with a focus on Data and AI. She has worked in various technical roles across the financial services, insura nce, and technology industries. She holds a \nBachelor of Science degree in  Information Science from UNC Chapel Hill, and a Masters in \nAnalytics degree from North Carolina State University.\nMatthew Price  is a Senior watsonx Client Success Man ager with 20 years of experience in IT \nand 10 years of experience focusing on Wats on ", "metadata": {"source": "sg248574.pdf", "chunk_index": 33, "total_chunks": 313}}
{"text": " Success Man ager with 20 years of experience in IT \nand 10 years of experience focusing on Wats on technologies. His previous experience \nincludes writing the base code that went on to become the IBM Watson\u00ae Assistant for Citizens application, which is IBM\u2019s no-charge offering that was released during 2020 to help business and government agencies navigate the pandemic. His previous publications \ncentered on application migration and the cloud.\nShirley Shum is a Senior Software Engineer for the IBM Fusion team. She has worked as a \ntechnical lead on IBM Storage products, such as IBM Storage Insights and Fusion. Her areas of expertise include Kafka, complex event proc essing, backup and restore, and AI solutions, \nsuch as watsonx.ai and InstructLab on the Red Hat OpenShift platform. \nMark Simmonds  is a Program Director with IBM Data and AI. He writes extensively on AI, \ndata science, and data fabrics, and holds multiple author recognition awards. He previously worked as an IT architect", "metadata": {"source": "sg248574.pdf", "chunk_index": 34, "total_chunks": 313}}
{"text": " data fabrics, and holds multiple author recognition awards. He previously worked as an IT architect leading complex infrastructure design and corporate technical architecture projects. He is a member of the British Computer Society, holds a bachelor's degree in Computer Science, is a published author, and a prolific public speaker.\nNow you can become a published author, too!\nHere\u2019s an opportunity to  spotlight your skills , grow your career, and become a published \nauthor\u2014all at the same time! Join an IBM Redbooks residency project and help write a book in your area of expertise, while honing your experience using leading-edge technologies. Your efforts will help to increase pr oduct acceptance and customer satisfaction, as you expand \nyour network of technical contacts and relationships. Residencies run from two to six weeks in length, and you can participate either in person or as a remote resident working from your home base.\nFind out more about the residency program, browse the re", "metadata": {"source": "sg248574.pdf", "chunk_index": 35, "total_chunks": 313}}
{"text": "emote resident working from your home base.\nFind out more about the residency program, browse the residency index, and apply online at:\nibm.com/redbooks/residencies.html\nComments welcome\nYour comments are important to us!\nWe want our books to be as helpful as possible . Send us your comments about this book or \nother IBM Redbooks publications in one of the following ways:\n/SM590000Use the online Contact us  review Redbooks form found at:\nibm.com/redbooks\n/SM590000Send your comments in an email to:\nredbooks@us.ibm.com\n\n Foreword xiii/SM590000Mail your comments to:\nIBM Corporation, IBM Redbooks\nDept. HYTD Mail Station P0992455 South RoadPoughkeepsie, NY 12601-5400\nStay connected to IBM Redbooks\n/SM590000Find us on LinkedIn:\nhttps://www.linkedin.com/groups/2130806\n/SM590000Explore new Redbooks publications, residencies, and workshops with the IBM Redbooks \nweekly newsletter:\nhttps://www.redbooks.ibm.com/subscribe\n/SM590000Stay current on recent Redbooks publications with RSS Feeds:\nhttps:", "metadata": {"source": "sg248574.pdf", "chunk_index": 36, "total_chunks": 313}}
{"text": "books.ibm.com/subscribe\n/SM590000Stay current on recent Redbooks publications with RSS Feeds:\nhttps://www.redbooks.ibm.com/rss.html\n\nxiv Simplify Your AI Journey: Unleashi ng the Power of AI with IBM watsonx.ai\n\n\u00a9 Copyright IBM Corp. 2025. 1Chapter 1. Competing with artificial \nintelligence\nIn today's fast-paced digital landscape, artificial intellig ence (AI) has emerged as a \ngame-changer that is revolutionizing the way bus inesses operate, innovate, and compete. As \nAI technologies continue to advance and becom e increasingly ubiquitous, organizations are \nfaced with the daunting task of competing with AI-driven rivals while also leveraging AI to stay ahead of the competition. This chapter delves into the world of competing with AI by exploring the challenges, opportunities, and strategies that organizations can employ to remain competitive in an AI-dominated market.\nThe following topics are described in this chapter:\n/SM5900001.1, \u201cCompeting with AI\u201d on page 2\n/SM5900001.2, \u201cChalle", "metadata": {"source": "sg248574.pdf", "chunk_index": 37, "total_chunks": 313}}
{"text": "ics are described in this chapter:\n/SM5900001.1, \u201cCompeting with AI\u201d on page 2\n/SM5900001.2, \u201cChallenges in building and deploying AI models\u201d on page 4\n/SM5900001.3, \u201cOpportunities around using AI on trusted data\u201d on page 5\n/SM5900001.4, \u201cImproving AI mo del reliability\u201d on page 8\n/SM5900001.5, \u201cCreating new AI-enabled pr oducts and services\u201d on page 111\n\n2 Simplify Your AI Journey: Unleashing the Power of AI with IBM watsonx.ai1.1  Competing with AI\nTo harness the competitive advantage of using AI, organizations must first understand the AI \nlandscape and the various types of AI that exis t. Organizations must also be aware of the \nvarious AI technologies that are being used to drive innovation and competitiveness, which include the following ones:\n/SM590000Machine learning (ML): ML represents a pi votal subset of AI where algorithms are \ndeveloped and trained to recognize patterns and make data-driven predictions or decisions. Unlike traditiona l programming, ML systems learn iterati", "metadata": {"source": "sg248574.pdf", "chunk_index": 38, "total_chunks": 313}}
{"text": "make data-driven predictions or decisions. Unlike traditiona l programming, ML systems learn iteratively from data, \nimproving performance with ex perience. These systems rely on vast datasets to develop \nstatistical models that enable predictions across diverse applications, such as anomaly detection, natural language processing (NLP), and image recognition. The training process involves feeding labeled (supervi sed learning) or unlabeled (unsupervised \nlearning) data to the algorithm. Over time, the system refines its parameters to minimize errors and maximize predictive accuracy. ML algorithms are central to AI's practical applications, and they drive everything from recommendation systems to fraud detection in modern business ecosystems.\n/SM590000Deep learning (DL): DL is an advanced branch of ML that employs artificial neural \nnetworks that are modeled after the human brain's structure and functioning. Unlike traditional ML, which often depends on manual feature engineering, DL au", "metadata": {"source": "sg248574.pdf", "chunk_index": 39, "total_chunks": 313}}
{"text": "ure and functioning. Unlike traditional ML, which often depends on manual feature engineering, DL automates the extraction of complex features from raw data through multiple layers of interconnected neurons. DL excels in handling unstructured data such as images, audio, and text, making it instrumental in solving tasks like computer vision, spee ch recognition, and language \ntranslation. For example, convolutional n eural networks (CNNs) specialize in image \nprocessing by identifying spatial hierarchies in pixels, and recurrent neural networks (RNNs) and transformers tackle sequential data with unparalleled efficiency. By leveraging high-performance computing and large datasets, DL approximates nonlinear functions to enable machines to solve intricate, high-dimensional problems.\n/SM590000Unsupervised learning: Unsupervised learning focuses on deriving patterns and \nstructures from unlabeled datasets. This method trains algorithms to identify inherent groupings, clusters, or association", "metadata": {"source": "sg248574.pdf", "chunk_index": 40, "total_chunks": 313}}
{"text": "led datasets. This method trains algorithms to identify inherent groupings, clusters, or associations in data without human-provided annotations. Common techniques include clustering algorithms, such  as k-means and hier archical clustering, \nand dimensionality reduction methods, such as Principal Component Analysis (PCA) and t-SNE. Applications of unsupervised learning are vast, ranging from customer segmentation in marketing to anomaly detection in cybersecurity. These systems are \nparticularly valuable in exploratory data a nalysis, where insights emerge from raw data \nwithout prior assumptions. By uncovering hidden relationships, unsupervised learning enhances your understanding of data and informs decision-making processes.\n/SM590000Reinforcement learning (RL): RL is a paradigm of ML where algorithms learn optimal \nbehaviors by interacting with an environment and receiving feedback in the form of rewards or penalties. RL systems employ agents that act based on policies, and aim to", "metadata": {"source": "sg248574.pdf", "chunk_index": 41, "total_chunks": 313}}
{"text": "in the form of rewards or penalties. RL systems employ agents that act based on policies, and aim to maximize cumulative rewards over time. Core to RL are concepts such as the exploration-exploitation tradeoff, Markov deci sion processes (MDPs), and value functions. \nTechniques such as Q-learning  and Deep Q-Networks (DQNs) extend RL\u2019s capabilities to \nenable applications in robotics, game play ing, and autonomous vehicles. RL's emphasis \non learning through trial and error aligns it closely with real-world problem-solving, where dynamic environments require adaptive strategies.\n\nChapter 1. Competing wit h artificial intelligence 3/SM590000Foundation models: Foundation models (FMs) represent a transformative leap in AI and \nML, characterized by their scala bility, versatility, and ability to genera lize across tasks. \nThese models, such as Granite, are pre-trained on vast and diverse datasets, enabling them to adapt to specific applications with minimal fine-tuning. Unlike traditional ", "metadata": {"source": "sg248574.pdf", "chunk_index": 42, "total_chunks": 313}}
{"text": "asets, enabling them to adapt to specific applications with minimal fine-tuning. Unlike traditional ML \nmodels that are tailored to single tasks, FMs leverage their pre-trained knowledge to excel in multiple domains. This adaptability is achieved throug h transfer learning, where the \nmodel's pre-trained weights are fine-tuned on domain-specific data sets. FMs empower organizations to reduce the cost and complexity of training AI systems while achieving state-of-the-art performance in tasks like natural language understanding, summarization, and multimodal reasoning.\nLeveraging AI for co mpetitive advantage\nTo thrive in an AI-driven landscape, organizati ons must strategically harness AI technologies \nto drive innovation, enhance operational efficiency, and improve decision-making. Key areas of focus include the following ones:\n/SM590000AI-powered automation: Automation that is fueled by AI enables the running of repetitive \nand high-volume tasks with speed and precision,  such as appl", "metadata": {"source": "sg248574.pdf", "chunk_index": 43, "total_chunks": 313}}
{"text": " AI enables the running of repetitive \nand high-volume tasks with speed and precision,  such as applications in Robotic Process \nAutomation (RPA), intelligent document processing, and automated workflows. By offloading routine operations, organizations can redirect human resources to strategic and creative endeavors, which foster innovation and competitive differentiation.\n/SM590000AI-driven analytics: AI-powered analytics transform raw data into actionable insights, \nwhich equips businesses to make data-informed decisions. Predictive analytics, which is powered by ML, enables forecasting trends and identifying potential challenges, and prescriptive analytic s suggests optimal courses of action. These ca pabilities enable \norganizations to stay ahead in dynamic market s by responding proactively to opportunities \nand risks.\n/SM590000AI-based innovation: AI acts as a catalyst for innovation to enable organizations to \nconceptualize and deliver groundbreaking products, services, and busi", "metadata": {"source": "sg248574.pdf", "chunk_index": 44, "total_chunks": 313}}
{"text": "on to enable organizations to \nconceptualize and deliver groundbreaking products, services, and business FMs. From personalized healthcare solutions to autonomous logistics systems, AI's potential to redefine industries is immense. By embedding AI in their innovation processes, companies can create unique value propositions that resonate with customers and stakeholders alike.\nBy embracing these AI strategies, organizations can position themselves as leaders in the era \nof digital transformation. As AI  continues to evolve, its syner gy with trusted data will unlock \nunprecedented op portunities, which will re shape the competitive landscape and drive \nsustainable growth.\n\n4 Simplify Your AI Journey: Unleashing the Power of AI with IBM watsonx.ai1.2  Challenges in building and deploying AI models\nBuilding and deploying AI models is a complex and challenging endeavor that requires \nexpertise, resources, and infrastructure. Despite the potential benefits of AI, many organizations struggle", "metadata": {"source": "sg248574.pdf", "chunk_index": 45, "total_chunks": 313}}
{"text": "se, resources, and infrastructure. Despite the potential benefits of AI, many organizations struggle to overcome the numerous hurdles that are associated with AI model development and deployment. Here are some of the key challenges:\n/SM590000Data quality and availability: AI  models require vast amounts of high-quality,  relevant, and \ndiverse data to learn, train, and validate. However, many organizations face challenges in collecting, processing, and integrating data from disparate sources, which can lead to issues with data quality, consistency, an d availability. Furthermo re, data privacy and \nsecurity concerns can limit access to sensitive data, which can hinder the development of accurate and reliable AI models.\n/SM590000Model complexity and in terpretability: As AI models be come increasingly complex, they \ncan be difficult to interpret and understand, which makes it challenging to identify biases, errors, or flaws in the decision-making process. The lack of transparency and \ne", "metadata": {"source": "sg248574.pdf", "chunk_index": 46, "total_chunks": 313}}
{"text": "to identify biases, errors, or flaws in the decision-making process. The lack of transparency and \nexplainability in AI models can lead to mistrust, regulat ory issues, and reputational \ndamage. Moreover, the complexity of AI models can make it difficult to integrate them with existing systems, processes, and infrastructure.\n/SM590000Talent acquisition and retention: The development and deployment of AI models require \nspecialized skills and expertise, which in clude data science, ML, and software \nengineering. However, the demand for AI talent far exceeds the supply, which can lead to challenges in acquiring and retaining top talent. Furthermore, the constant evolution of AI technologies means that professionals must continually update their skills to remain relevant, which can add to the talent acquisition and retention challenges.\n/SM590000Infrastructure and scalability:  AI models require significan t computational resources, \nmemory, and storage to process and analyze large datase", "metadata": {"source": "sg248574.pdf", "chunk_index": 47, "total_chunks": 313}}
{"text": "quire significan t computational resources, \nmemory, and storage to process and analyze large datasets. However, many organizations lack the necessary infrastructure to support the development and deployment of AI models, which can lead to  issues with scalability, performance, and \nreliability. Furthermore, the inte gration of AI models with existing systems and processes \ncan be complex, requiring si gnificant investment in infrastructure and architecture.\n/SM590000Bias and fairness: AI models can perpetuate and amplify existing biases and inequalities if \nthey are trained on biased data or designed with a particular world view. The lack of diversity and inclusion in AI development t eams can exacerbate these issues, which can \nlead to unfair outcomes and reputational damage. Furthermore, the identification and mitigation of bias in AI models can be challe nging, which requires significant expertise and \nresources.\n/SM590000Regulatory compliance: The development and deployment of AI ", "metadata": {"source": "sg248574.pdf", "chunk_index": 48, "total_chunks": 313}}
{"text": "cant expertise and \nresources.\n/SM590000Regulatory compliance: The development and deployment of AI models are subject to \nvarious regulations and laws, which include data protection, intellectual property, and anti-discrimination legislation. However, the rapidly evolving nature of AI technologies can make it challenging to ensure regulatory compliance, particular ly in industries with strict \nregulations, such as healthcare and finance.\n/SM590000Model maintenance and updates: AI models require continuous maintenance and updates \nto help ensure that they remain accurate, reliable, and relevant. However, the process of updating AI models can be complex and require significant resources and expertise. Furthermore, the integration of updated AI models with existing systems and processes can be challenging, which can lead to issues with compatib ility and performance.\n\nChapter 1. Competing wit h artificial intelligence 5/SM590000Explainability and transpar ency: The lack of explainability", "metadata": {"source": "sg248574.pdf", "chunk_index": 49, "total_chunks": 313}}
{"text": "wit h artificial intelligence 5/SM590000Explainability and transpar ency: The lack of explainability a nd transparency in AI models \ncan make it challenging to understand the decision-making process, which can lead to \nmistrust and reputational damage. Furthermore, the identification and mitigation of errors or biases in AI models can be difficult, which can require expertise and resources.\n/SM590000Cybersecurity: AI models can be vulnerable to cyberthreats, such as data poisoning, \nmodel hijacking, and adversarial attacks. The identification and mitigation of these threats can be challenging and require expertise and resources. Furthermore, the integration of AI models with existing security systems and processes can be complex, which can lead to issues with compatib ility and performance.\n1.2.1  Technical considerations fo r building and depl oying AI models\nWhen building and deploying AI models, there are several technical considerations that must \nbe accounted for:\n/SM590000Data pr", "metadata": {"source": "sg248574.pdf", "chunk_index": 50, "total_chunks": 313}}
{"text": " AI models, there are several technical considerations that must \nbe accounted for:\n/SM590000Data preprocessing: Ensuring that the data that is used to train and test the model is \naccurate, complete, and relevant.\n/SM590000Model selection: Choosing the most suitable algorithm and model architecture for the \nproblem being addressed.\n/SM590000Hyper-parameter tuning: Optimizing the mode l's hyper-parameters to achieve the best \npossible performance.\n/SM590000Model evaluation: Evaluating the model's perfor mance by using metric s such as accuracy, \nprecision, and recall.\n/SM590000Model deployment: Deploying the model in a production-ready environment, such as a \ncloud-based API or a containerized application.\n/SM590000Model monitoring: Continuously monitoring the model's performance and updating it as \nnecessary to help ensure that it  remains accurate  and relevant.\nIn addition to these technical considerations, organizations must also consider the following \nitems:\n/SM590000Data governa", "metadata": {"source": "sg248574.pdf", "chunk_index": 51, "total_chunks": 313}}
{"text": "chnical considerations, organizations must also consider the following \nitems:\n/SM590000Data governance: Establishi ng policies and procedures for data management, which \ninclude data quality, security, and compliance.\n/SM590000Model governance: Establishing policies and procedures for model development, \ndeployment, and maintenance, which include model validation, testing, and updating.\n/SM590000Infrastructure governance: Establishing po licies and procedures for infrastructure \nmanagement, which include infrastructure provisioning, scaling, and security.\nBy being conscious of these technical consider ations and establishing effective governance \npolicies and procedures, organizations can help ensure the successful development and deployment of AI models that drive business value and competitiveness.\n1.3  Opportunities around using AI on trusted data\nAI thrives on data. However, the effectiveness of AI systems is not solely dependent on the volume of data but also on its quality and t", "metadata": {"source": "sg248574.pdf", "chunk_index": 52, "total_chunks": 313}}
{"text": "ectiveness of AI systems is not solely dependent on the volume of data but also on its quality and trustworthiness. Trusted data (data that is accurate, consistent, secure, and compliant) serves as the foundation for reliable AI-driven insights. Organizations today are exploring opportunities to harness AI on trusted data to drive operational efficiency, enhance decision-maki ng, and unlock new revenue streams. This \nsection explores the myriad possibilities that AI unlocks when it operate s on a foundation of \nhigh-quality, trusted data.\n\n6 Simplify Your AI Journey: Unleashing the Power of AI with IBM watsonx.ai1.3.1  Enhancing de cision-making with accurate insights\nThe fusion of AI and trusted data is reshapin g decision-making processes across industries, \nand enabling organizations to derive precise and actionable insights. This transformation is \ncritical in domains where de cisions significantly impact outcomes, such as healthcare, \nfinance, and supply chain management. By leve ", "metadata": {"source": "sg248574.pdf", "chunk_index": 53, "total_chunks": 313}}
{"text": "s significantly impact outcomes, such as healthcare, \nfinance, and supply chain management. By leve raging high-quality, trusted data, AI systems \ncan identify patterns, predict outcomes, and provide recommendations that drive superior decisions.\nFor example, in healthcare, AI systems that are powered by trusted clinical and patient data \nenhance diagnostic precision, predict pati ent outcomes with remarkable accuracy, and \nsuggest personalized treatment plans that are tailored to individual needs. In the financial sector, AI models that are trained on trusted datasets excel in detecting fraudulent activities, assessing credit risks, and automating sophisticated trading strategies that are based on dynamic market trends. These examples illustrate how truste d data amplifies the reliability \nand impact of AI-driven decision-making,  minimizing risks and maximizing outcomes.\nOne of the most transformative applications of AI on trusted data is in improving \ndecision-making. High-quality d", "metadata": {"source": "sg248574.pdf", "chunk_index": 54, "total_chunks": 313}}
{"text": "t transformative applications of AI on trusted data is in improving \ndecision-making. High-quality data enables AI algorithms to deliver precise and actionable \ninsights, which are beneficial in industries like healthcare, finance, and supply chain management, where even minor errors in decision-making can have significant consequences.\n/SM590000Healthcare: Trusted data enables AI systems  to accurately predict patient outcomes, \nsuggest personalized treatment plans, and enhance diagnostic accuracy.\n/SM590000Finance: In financial services, AI models that are trained on trusted data can detect fraud, \nassess credit risks, and automate trading stra tegies based on market predictions. \n1.3.2  Driving operational efficiency\nAI's ability to automate  and optimize complex processes is  magnified when it is built on a \nfoundation of trusted data. By eliminating inefficiencies and reducing the need for human \nintervention, organizations can achieve unpr ecedented levels of operational efficien", "metadata": {"source": "sg248574.pdf", "chunk_index": 55, "total_chunks": 313}}
{"text": "eed for human \nintervention, organizations can achieve unpr ecedented levels of operational efficiency.\nIn the manufacturing and energy sectors, predictive maintenance systems leverage trusted \nsensor data to foresee equipment failures, which enable preemptive interventions that \nminimize downtime and reduce maintenance costs. Similarly, AI-powered customer service platforms, which are underpinned by reliable customer interaction data, provide accurate, context-aware responses that deliver personalized experiences while alleviating the workload of human agents. These advancements highlight the transformative potential of combining AI with trusted data to streamline operations across industries.\nWhen AI is applied to trusted data, it automates complex processes, which reduce the need \nfor human intervention, and improves efficiency:\n/SM590000Predictive maintenance: In the manufacturing and energy sectors, AI systems use trusted \nsensor data to predict equipment failures, which minimize ", "metadata": {"source": "sg248574.pdf", "chunk_index": 56, "total_chunks": 313}}
{"text": "d energy sectors, AI systems use trusted \nsensor data to predict equipment failures, which minimize downtime and optimizes maintenance schedules.\n/SM590000Customer service automation: AI-powered chatbots, which are fueled by reliable customer \ndata, provide accurate responses and deliver personalized experiences, which reduce the burden of human agents.\n\nChapter 1. Competing wit h artificial intelligence 71.3.3  Accelerating innovation\nThe convergence of AI and trusted data is a catalyst for innovation, which unlocks hidden \npatterns and opportunities that were previously  inaccessible. By analyzing vast amounts of \nhigh-quality data, AI systems empower organizations to develop groundbreaking products and solutions.\nFor example, in product development, companies use AI to analyze customer feedback, \nmarket trends, and usage data th at is extracted from trusted sources to create offerings that \nresonate with consumer preferences. In the realm of scientific rese arch, AI accelerates \ndis", "metadata": {"source": "sg248574.pdf", "chunk_index": 57, "total_chunks": 313}}
{"text": " that \nresonate with consumer preferences. In the realm of scientific rese arch, AI accelerates \ndiscovery processes by interpreting extensive experimental datasets, which lead to advancements in fields such as drug develop ment and material science. Trusted data \nenhances the accu racy of these insights and helps ensure the repr oducibility of  outcomes, \nwhich drive sustained innovation.\nThe combination of AI and trusted data fosters innovation by uncovering hidden patterns and \nopportunities that were previously inaccessible:\n/SM590000Product development: Companies leverage AI to analyze customer feedback and market \ntrends from trusted datasets, which helps the companies to design products that align with consumer preferences.\n/SM590000Research and development: In scientific rese arch, AI accelerates discovery by analyzing \nlarge volumes of trusted experimental data, which can lead t o breakthroughs in areas \nsuch as d rug discovery and material science.\n1.3.4  Enhancing gover nanc", "metadata": {"source": "sg248574.pdf", "chunk_index": 58, "total_chunks": 313}}
{"text": " o breakthroughs in areas \nsuch as d rug discovery and material science.\n1.3.4  Enhancing gover nance and compliance\nIn an era where regulatory landscapes are bec oming increasingly stringent, trusted data \nplays a pivotal role in helping ensure that AI systems operate within legal and ethical frameworks. Governance and co mpliance initiatives are fortified by AI systems that \ncontinuously monitor operations, detect anomalies, and flag potential risks.\nFor example, compliance monitoring AI tool s analyze operational data to help ensure \nadherence to industry regulations and standa rds, which reduce the risk of noncompliance \npenalties. Also, the usage of diverse and repres entative trusted datasets mitigates biases in \nAI model training, which foster fairness and ethi cal outcomes in critical applications such as \nhiring or loan approvals. Trusted data serves as a cornerstone for responsible AI development and deployment.\nTrusted data helps ensure that AI systems operate within legal a", "metadata": {"source": "sg248574.pdf", "chunk_index": 59, "total_chunks": 313}}
{"text": "ible AI development and deployment.\nTrusted data helps ensure that AI systems operate within legal and ethical boundaries, which \ncritical factors in maintain ing customer trust and avoiding regulatory penalties:\n/SM590000Compliance monitoring: AI models can continuously analyze operational data to help \nensure adherence to regulations by flagging any potential compliance risks.\n/SM590000Bias mitigation: Trusted data, when diverse and representative, helps train AI models that \nare fair and unbiased, which helps ensure ethical outcomes in areas like hiring or loan approvals.\n1.3.5  Unlocking new revenue streams\nThe monetization of trusted data through AI-driven services and products has emerged as a significant avenue for revenue generation. Or ganizations across sectors are capitalizing on \nthis synergy to create innovative business models.\n\n8 Simplify Your AI Journey: Unleashing the Power of AI with IBM watsonx.aiFor example, in telecommunications and retail, companies offer AI-power", "metadata": {"source": "sg248574.pdf", "chunk_index": 60, "total_chunks": 313}}
{"text": "wer of AI with IBM watsonx.aiFor example, in telecommunications and retail, companies offer AI-powered insights or \nanalytics as services to their partners and c lients, which transform data into a valuable asset. \nMoreover, trusted customer data enables hyper-targeted marketing campaigns, which enhance conversion rates and foster customer loyalty. By harnessing the power of trusted data, organizations can unlock untapped revenue opportunities while delivering value to stakeholders.\nOrganizations are monetizing their trusted data through AI-driven services and products:\n/SM590000Data monetization: Companies in sectors such as telecommunications and retail generate \nnew revenue by offering AI-powered insights or analytics as a service to their partners and \nclients.\n/SM590000Personalized marketing: AI leverages trusted customer data to deliver hyper-targeted \nmarketing campaigns that increase conversion rates and customer loyalty.\n1.3.6  Transforming industrie s with AI and trusted data", "metadata": {"source": "sg248574.pdf", "chunk_index": 61, "total_chunks": 313}}
{"text": "ease conversion rates and customer loyalty.\n1.3.6  Transforming industrie s with AI and trusted data\nThe integration of AI with trusted data is revolutionizing industries in unique and profound \nways. Retailers use transaction and customer data to fuel recommendation engines, which enhance sales and customer satisfaction. In agriculture, AI models analyze environmental and crop data to optimize farming practices an d maximize yields. Similarly, in the energy \nsector, AI systems leverage consumption and grid data to predict demand, optimize distribution, and enhance energy efficiency. These transformative applications underscore the versatility and impact of trusted data-driven AI across diverse domains.\nDifferent industries are leveraging AI and trusted data in unique ways:\n/SM590000Retail: Trusted transaction and customer data power recommendation engines that boost \nsales and improve customer experiences.\n/SM590000Agriculture: AI models analyze trusted environmental and crop data to ", "metadata": {"source": "sg248574.pdf", "chunk_index": 62, "total_chunks": 313}}
{"text": "ustomer experiences.\n/SM590000Agriculture: AI models analyze trusted environmental and crop data to optimize farming \npractices and increase yield.\n/SM590000Energy: AI systems use trusted consumption and grid data to predict demand and \noptimize energy distribution.\n1.4  Improving AI model reliability\nThe reliability and interp retability of AI models  are enhanced when they are tr ained and \nvalidated on trusted data. High-quality data helps ensure that AI systems deliver consistent and accurate outputs, which foster stakeholder trust a nd facilitate br oader adoption.\nFor example, explainable AI (XAI) models rely  on trusted data to generate transparent and \ninterpretable insights, which address concerns  about the \u201cblack-box\u201d nature of AI. Also, \ntrusted data simplifies model auditing and debugging by enabling the identification of inconsistencies and anomalies, which leads to continuous performance improvements. By prioritizing data quality, organizations can overcome one of the pr", "metadata": {"source": "sg248574.pdf", "chunk_index": 63, "total_chunks": 313}}
{"text": "ous performance improvements. By prioritizing data quality, organizations can overcome one of the primary challenges of scaling AI systems.\n\nChapter 1. Competing wit h artificial intelligence 9Trusted data enhances t he reliability and interpre tability of AI models, addressing one of the \nmajor challenges in deploying AI at scale:\n/SM590000Explainability and trust: AI m odels that are trained on hi gh-quality data provide more \nconsistent and interpretable outputs, which enable stakeholders to trust and adopt AI-driven solutions.\n/SM590000Model auditing and debugging: Trusted data helps identify inconsistencies and anomalies \nin AI predictions, which make it easier to debug models and improve their performance over time.\n1.4.1  Enabling cross-enterprise collaboration\nTrusted data serves as a bridge for collaboratio n across organizational silos and with external \npartners. This capability enhance s operational transparency and fosters innovation by \nenabling seamless data sharing and ", "metadata": {"source": "sg248574.pdf", "chunk_index": 64, "total_chunks": 313}}
{"text": "ty enhance s operational transparency and fosters innovation by \nenabling seamless data sharing and integration.\nEnterprises can leverage trusted data infrastructures to break down silos so that \ncross-functional teams can work collaboratively on shared objectives. Secure data exchange mechanisms further facilitate partnerships  across geographies, which helps ensure \ncompliance with data privacy regulations and fosters rust among stakeholders. Such collaborative ecosystems are critical for driving comprehensive digital transformation initiatives.\nAI on trusted data enables organizations to collaborate more effectively across departments \nand even with external partners:\n/SM590000Data sharing across silos: Enterprises can break down data silos and enable \ncross-functional collaboration to enhance operational transparency.\n/SM590000Secure data exchange: Trusted data infrastructures help ensure that shared data between \npartners or across geographies remain secure and compliant.\n1.4.2  E", "metadata": {"source": "sg248574.pdf", "chunk_index": 65, "total_chunks": 313}}
{"text": "nsure that shared data between \npartners or across geographies remain secure and compliant.\n1.4.2  Enhancing real -time decision-making\nThe ability to make real-time de cisions is a cornerstone of mo dern business strategies, and \ntrusted data is a key enabler of  this capability. By processing and analyzing data  streams in \nreal time, AI systems empower organizations to act swiftly and effectively.\nIn industries like finance, dynamic pricing models use real-time trusted data to optimize \nstock-pricing strategies based on demand and in ventory levels. Financia l institutions employ \nAI systems to perform instant risk assessments to mitigate fraud and help ensure secure \ntransactions. These applicatio ns demonstrate how trusted da ta enhances the agility and \nresponsiveness of AI-driven decision-making processes.\nReal-time analytics that are powered by trusted data enable businesses to make faster, more \ninformed decisions:\n/SM590000Dynamic pricing: In e-commerce or travel industries, ", "metadata": {"source": "sg248574.pdf", "chunk_index": 66, "total_chunks": 313}}
{"text": "ake faster, more \ninformed decisions:\n/SM590000Dynamic pricing: In e-commerce or travel industries, AI leverages real-time trusted data to \noptimize pricing strategies based on demand and inventory levels.\n/SM590000Real-time risk assessment: Fi nancial institutions use AI to perform instant risk \nassessments for transactions to hel p mitigate fraud or credit risks.\n\n10 Simplify Your AI Journey: Unleashing the Power of AI with IBM watsonx.ai1.4.3  Scaling AI-driven ecosystems\nLarge-scale AI implementations  depend on the robustness and reliability of trusted data \necosystems. By building scalable infrastructures that integrate trusted data with advanced AI capabilities, organizations can unlock the full potentia l of AI-driven solutions.\nAI as a Service (AIaaS) platforms exemplify this integration by offering modular services such \nas ML models, NLP, and predictive analytics that are powered by trusted data. In parallel, the integration of IoT devices with AI systems generates vast volu", "metadata": {"source": "sg248574.pdf", "chunk_index": 67, "total_chunks": 313}}
{"text": "red by trusted data. In parallel, the integration of IoT devices with AI systems generates vast volumes of real-time data to enable actionable insights in sectors like logistics, healthcare, and smart cities. These scalable \necosystems are the foundation for sustained growth and innovation.\nTrusted data serves as the backbone for large- scale AI implementations, fostering robust AI \necosystems:\n/SM590000AI as a Service (AIaaS): Companies are building scalable platforms where trusted data \npowers modular AI services like ML models, NLP, and predictive analytics.\n/SM590000Integration with IoT: IoT devices generate vast amounts of data. Trusted IoT data enables \nAI systems to deliver real-time analytics for industries like logistics, healthcare, and smart cities.\n1.4.4  Driving sustainability and envi ronmental, social, an d governance goals\nAI-powered sustainabilit y initiatives are gain ing momentum, with trus ted data playing a \ncentral role in achieving environmental, social, and gove", "metadata": {"source": "sg248574.pdf", "chunk_index": 68, "total_chunks": 313}}
{"text": "ng momentum, with trus ted data playing a \ncentral role in achieving environmental, social, and governance (ESG) objectives. By analyzing environmental and operational datasets, AI systems help organizations optimize resource usage, reduce carbon footprints, and enhance supply chain transparency.\nFor example, sustainabilit y analytics tools use trusted data to identify inefficiencies and \nrecommend strategies for improv ing energy efficiency. Similarl y, AI systems provide visibility \ninto supply chains to enable organizations to address waste and improve sustainability \npractices. By aligning AI initiatives with ESG goals, organizations can demonstrate their commitment to responsible and ethical operations.\nAI, combined with trusted data, helps organizations meet ESG objectives:\n/SM590000Sustainability analytics: AI mode ls analyze trusted environmen tal and operational data to \noptimize resource usage and reduce carbon footprints.\n/SM590000Supply chain transparency: Truste d data pro", "metadata": {"source": "sg248574.pdf", "chunk_index": 69, "total_chunks": 313}}
{"text": "e resource usage and reduce carbon footprints.\n/SM590000Supply chain transparency: Truste d data provides visibility into the supply chain so that AI \ncan identify inefficiencies, reduce waste, and improv e sustainability practices.\n1.4.5  Personalizing customer experiences\nCustomer-centric in dustries are leveraging AI's abilit y to deliver highly personalized \nexperiences, which is a capability that is ro oted in truste d data. By analyzing customer \nbehavior, preferences, and interactions, AI systems create tailored experiences that enhance satisfaction and loyalty.\nFor example, adaptive AI systems use real-time trusted data to modify services dynamically \nto help ensure relevance and engagement. Behavioral analytics enable companies to predict customer needs, which reduce churn and fosters long-term relationships. Trusted data empowers organizations to elevate customer experiences to new heights.\n\nChapter 1. Competing with artificial intelligence 11Customer-centric in dustries are ", "metadata": {"source": "sg248574.pdf", "chunk_index": 70, "total_chunks": 313}}
{"text": " new heights.\n\nChapter 1. Competing with artificial intelligence 11Customer-centric in dustries are capitalizing on AI's ab ility to deliver highly personalized \nexperiences through trusted data:\n/SM590000Adaptive AI systems: Real-time, trusted cu stomer data enables AI systems to adapt and \ntailor services to create more engaging user experiences.\n/SM590000Behavioral analytics: Trusted behavioral data enables companies to predict customer \npreferences, which reduce churn and increase satisfaction.\n1.5  Creating new AI-enabled products and services\nTrusted data serves as the foundation for dev eloping innovative AI-enabled products and \nservices that redefine industries. By harnessin g historical and real-time data, organizations \ncan anticipate needs and deliver solutions proactively.\nFor example, proactive support systems leverage AI to predict and address issues before \nthey escalate, which enhances cu stomer satisfaction and operational efficiency. Custom AI \nsolutions, which are t", "metadata": {"source": "sg248574.pdf", "chunk_index": 71, "total_chunks": 313}}
{"text": " which enhances cu stomer satisfaction and operational efficiency. Custom AI \nsolutions, which are tailo red to specific market niches, furt her demonstrate the transformative \npotential of trusted data. As organizations continue to invest in data governance and quality, the opportunities for creating AI-driven innovations will expand.\nBy aligning AI initiatives with business objectives and prioritizing trusted data infrastructures, \norganizations can unlock unparalleled levels of  efficiency, innovation, and growth. As the \ncomplexity of data landscapes continues to evolve, the role of trusted data in enabling AI to achieve its full potential becomes increasingly indispensable.\nTrusted data opens doors to innovations that can redefine industries:\n/SM590000Proactive support systems: AI systems, which are trained on historical  and real-time data, \npredict customer or machine needs before problems occur to offer preemptive solutions.\n/SM590000Custom AI solutions: Organizations use their", "metadata": {"source": "sg248574.pdf", "chunk_index": 72, "total_chunks": 313}}
{"text": " problems occur to offer preemptive solutions.\n/SM590000Custom AI solutions: Organizations use their proprietary trusted data to build AI products \nthat are tailored to niche market requirements.\nBy continuously investing in trusted data infr astructures and aligning AI initiatives with \nbusiness goals, organizations can unlock new levels of efficiency, growth, and innovation.AI and trusted data offers a powerful opportunity to drive growth, innovation, and operational excellence. Organizations that prioritize data governance, ensure data quality, and build AI systems on trusted data are better positioned to harness these opportunities. As the volume \nand complexity of data continue to grow, the role of trusted data in enabling AI to deliver its full potential will become more critical.\n\n12 Simplify Your AI Journey: Unleashing the Power of AI with IBM watsonx.ai\n\n\u00a9 Copyright IBM Corp. 2025. 13Chapter 2. Introducing IBM watsonx.ai\nIBM watsonx is IBM\u2019s next-generation platform that is de", "metadata": {"source": "sg248574.pdf", "chunk_index": 73, "total_chunks": 313}}
{"text": "25. 13Chapter 2. Introducing IBM watsonx.ai\nIBM watsonx is IBM\u2019s next-generation platform that is designed to help businesses accelerate \ntheir journey into artificial in telligence (AI)-driven insights, de cision-making, and automation. \nThe platform offers a comprehensive suite of t ools and services that are tailored to simplify \nand streamline the development and deployment of AI solutions. It is built on three foundational pillars:\n/SM590000IBM watsonx.data: A scalable data lakehouse that is designed for efficient and secure \ndata management to enable hybrid cloud deployments and optimize data for AI workloads.\n/SM590000IBM watsonx.governance: Provides robust governance to help ensure that AI models \nremain ethical, transparent, and compliant with regulatory standards. It also helps businesses monitor and mitigate AI-related risks.\n/SM590000IBM watsonx.ai: A cutting-edge AI development and deployment environment. It supports \nthe full lifecycle of AI, from model training and fine-", "metadata": {"source": "sg248574.pdf", "chunk_index": 74, "total_chunks": 313}}
{"text": "ent and deployment environment. It supports \nthe full lifecycle of AI, from model training and fine-tuning to deployment and monitoring.\nThe seamless integration of these components enables enterprises to leverage trusted data \n(watsonx.data), enforce governance and ethical standards (watsonx.governance), and develop AI-powered solutions (watsonx.ai). Together, they form a comprehensive ecosystem for deploying enterprise-grade AI at scale.\nThe following topics are described in this chapter:\n/SM5900002.1, \u201cOverview of watsonx.ai\u201d on page 14\n/SM5900002.2, \u201cSynergy between watsonx.ai and other components in the watsonx platform\u201d on \npage 15\n/SM5900002.3, \u201cBusiness impact of these synergies\u201d on page 162\n\n14 Simplify Your AI Journey: Unleashing the Power of AI with IBM watsonx.ai2.1  Overview of watsonx.ai\nwatsonx.ai serves as the core engine of the watsonx platform, which is focused on the rapid \ndevelopment and deployment of AI models. Its architecture is designed to support various AI wo", "metadata": {"source": "sg248574.pdf", "chunk_index": 75, "total_chunks": 313}}
{"text": "apid \ndevelopment and deployment of AI models. Its architecture is designed to support various AI workloads, such as traditional machine learning  (ML), deep learning (DL), and generative AI \n(gen AI).\n2.1.1  Key capabilities\nHere are the key capab ilities of watsonx.ai:\n/SM590000Foundation models (FMs): watsonx.ai provides access to pre-trained FMs, such as large \nlanguage models (LLMs) and vision models, wh ich can be fine-tuned for specific business \nneeds.\n/SM590000Machine learning operations (MLOps): The platform integrates tools for version control, \nmodel monitoring, and deployment to streamline AI lifecycle management.\n/SM590000Multi-cloud compatibility: Su pports hybrid and multi-cl oud environments so that \nbusinesses can run AI workloads wherever they see fit.\n/SM590000Extensibility: Developers can br ing their own models or inte grate open-source frameworks \nlike PyTorch and TensorFlow.\n2.1.2  The watsonx.ai architecture\nThe watsonx.ai architecture components include the fo", "metadata": {"source": "sg248574.pdf", "chunk_index": 76, "total_chunks": 313}}
{"text": "TensorFlow.\n2.1.2  The watsonx.ai architecture\nThe watsonx.ai architecture components include the following items:\n/SM590000Model Studio: An interface for training, fine-tuning, and deploying models.\n/SM590000Inference Engine: Optimized for running AI models in production environments to help \nensure low latency and high scalability.\n/SM590000Integration Layer: Enables seamless integration with watsonx.data for real-time data \naccess and watsonx.governance for compliance.\n2.1.3  watsonx.ai empoweri ng IBM Software offerings\nThe watsonx.ai FMs are being infused throughout all of IBM's major software offerings. The \nFMs are as follows:\n/SM590000IBM watsonx Code Assistant: Uses gen AI so  that developers can automatically generate \ncode by using a natural-language prompt.\n/SM590000IBM watsonx AIOps Insights: Includes FMs for code and natural language processing \n(NLP) to provide greater visibility in to performance acro ss IT environments.\n/SM590000IBM watsonx Assistant and IBM watsonx Or", "metadata": {"source": "sg248574.pdf", "chunk_index": 77, "total_chunks": 313}}
{"text": "ibility in to performance acro ss IT environments.\n/SM590000IBM watsonx Assistant and IBM watsonx Orchestrate\u00ae: Boosted by an NLP FM, IBM's \ndigital labor products enhance employee prod uctivity and customer service experiences.\n/SM590000Environmental Intelligence  Suite: powered by th e IBM geospatial FM, \nIBM EIS Builder Edition creates tailored solutions that address and mitigate environmental risks.\n\nChapter 2. Introducing IBM watsonx.ai 152.1.4  Benefits of using watsonx.ai for businesses\nAdopting watsonx.ai offers several key advantages for enterprises looking to harness the \npower of AI:\n/SM590000Accelerated AI development: watsonx.ai simplifies the development process with \npre-trained FMs and built-in tools for traini ng and deployment. Businesses can achieve \nfaster time-to-value by reducing the complexity of building AI from scratch.\n/SM590000Enhanced productivity and efficiency: Through automation of repetitive tasks, watsonx.ai \nenables teams to focus on high er-value acti", "metadata": {"source": "sg248574.pdf", "chunk_index": 78, "total_chunks": 313}}
{"text": "cy: Through automation of repetitive tasks, watsonx.ai \nenables teams to focus on high er-value activities. gen AI capabilities can handle complex \nprocesses, which improve the mean time to resolution for IT incidents and streamlining customer service.\n/SM590000Scalable and cost-efficient: watsonx.ai support for hybrid cloud and open architecture \nprovides cost flexibility. Businesses can choose the most economical deployment \nenvironment and scale AI workloads as needed.\n/SM590000Trust and governance: With watsonx.governance tightly integrated, watsonx.ai helps \nensure that AI models operate transparently and ethically. Businesses can meet regulatory compliance standards, which mitigate risks that are associated with biased or unexplainable AI decisions.\n/SM590000Business innovation: watsonx.ai enables companies to explore new AI-driven \nopportunities, such as personalizing customer experiences, optimizing supply chains, and driving data-driven decision-making.\nwatsonx.ai is a transfo", "metadata": {"source": "sg248574.pdf", "chunk_index": 79, "total_chunks": 313}}
{"text": "eriences, optimizing supply chains, and driving data-driven decision-making.\nwatsonx.ai is a transformative tool that empowers businesses to unlock the full potential of AI. \nBy integrating seamlessly with watsonx.data and watsonx.governance, it offers a unified platform that combines innovation, efficiency, and compliance. Organizations adopting watsonx.ai can expect to gain a competitive edge through smarter automation, better decision-making, and faster scaling of AI solutions.\n2.2  Synergy between watsonx.a i and other components in the \nwatsonx platform \nThis section covers the following topics:\n/SM590000Synergy between watsonx.ai and watsonx.data\n/SM590000Synergy between watsonx.ai and watsonx.governance\n2.2.1  Synergy between wa tsonx.ai and watsonx.data\nwatsonx.ai and watsonx.data streamline the development and deployment of AI models by \nensuring that AI systems are powe red by high-quality, trusted data. Here is how their synergy \ncreates value:\n/SM590000Efficient AI model de", "metadata": {"source": "sg248574.pdf", "chunk_index": 80, "total_chunks": 313}}
{"text": "high-quality, trusted data. Here is how their synergy \ncreates value:\n/SM590000Efficient AI model development: watsonx.data provides a robust and scalable data \nlakehouse that is optimized for AI workloads.  This lakehouse helps ensure that watsonx.ai \nhas instant access to vast amounts of clean, organized, and queryable data, which accelerates training and fine-tuning of AI models.\n/SM590000Real-time data for AI: watson x.data facilitates real-time da ta streaming, which enables \nwatsonx.ai to build and run AI models on up-to-date information. This approach enables dynamic AI use cases, such as predictive maintenance and fraud detection.\n\n16 Simplify Your AI Journey: Unleashing the Power of AI with IBM watsonx.ai/SM590000Hybrid and multi-cloud flexibility: Both wats onx.ai and watsonx.data  support deployment \nacross hybrid and multi-clou d environments, which help en sure scalability and cost \nefficiency while keeping data sovereignty intact.\n/SM590000Unified data governance: With  w", "metadata": {"source": "sg248574.pdf", "chunk_index": 81, "total_chunks": 313}}
{"text": "nd cost \nefficiency while keeping data sovereignty intact.\n/SM590000Unified data governance: With  watsonx.data acting as th e backbone, organizations can \nensure data integrity, enhance data sharing, and maintain a single source of truth for AI models that are developed in watsonx.ai.\n2.2.2  Synergy between wats onx.ai and watsonx.governance\nThe relationship between watsonx.ai and watsonx.governance helps ensure that AI models \nare high-performing, compliant, ethical, and transparent. Here is how they complement each other:\n/SM590000Ethical AI deployment: watsonx.governance provides guardrails for AI models that are \ndeveloped and deployed through watsonx.ai. These guardrails include bias detection, \nexplainability, and compliance trac king to help ensure  that AI decisions are fair and aligned \nwith regulatory standards.\n/SM590000Lifecycle management and monitoring: watsonx.governance tracks the entire lifecycle of \nAI models by monitoring performance, drift, and adherence to governa", "metadata": {"source": "sg248574.pdf", "chunk_index": 82, "total_chunks": 313}}
{"text": "tracks the entire lifecycle of \nAI models by monitoring performance, drift, and adherence to governance policies. This approach enables watsonx.ai users to maintain the integrity of deployed models over time.\n/SM590000Transparency and a uditability: Models that are built  on watsonx.ai benefit from the \nwatsonx.governance robust repo rting and audit capabilities, which provide stakeholders \nwith clear insights into how AI models make decisions, which help ensure trustworthiness.\n/SM590000Risk mitigation and remediation: If there are anomalies or breaches in governance \npolicies, watsonx.governance en ables quick remediation. Th is capability is crucial for \nmission-critical applications where trust in AI outputs is paramount.\n2.3  Business impact of these synergies\nBy leveraging the combined strengths of watsonx.ai, watsonx.data, and watsonx.governance, enterprises can achieve the following goals:\n/SM590000Help ensure that their AI models are trained on trusted, compliant data.\n/SM5900", "metadata": {"source": "sg248574.pdf", "chunk_index": 83, "total_chunks": 313}}
{"text": "ing goals:\n/SM590000Help ensure that their AI models are trained on trusted, compliant data.\n/SM590000Maintain high performance and ethical standards across AI deployments.\n/SM590000Accelerate innovation while minimizing the risks that are associated with AI adoption.\nThis holistic approach empowers organizations to maximize ROI on their AI investments and \ngain a competitive edge in their industries.\n\n\u00a9 Copyright IBM Corp. 2025. 17Chapter 3.Tools for diverse data science \nteams\nData science teams today are di verse in terms of skill sets, ba ckgrounds, and experiences. \nThese teams are also diverse in terms of the types of solutions that are implemented. Common roles of data science teams are data scientists, machine learning (ML) engineers, and artificial intelligence (AI) engineers. Therefore, different types of tools and solutions are needed to support data science teams. \nThis chapter describes a few of the key personas for IBM watsonx.ai and how the different \ntypes of tools that", "metadata": {"source": "sg248574.pdf", "chunk_index": 84, "total_chunks": 313}}
{"text": "er describes a few of the key personas for IBM watsonx.ai and how the different \ntypes of tools that are available on watsonx.ai support these individuals in their day-to-day \nwork. \nThe following topics are described in this chapter:\n/SM5900003.1, \u201cKey personas for watsonx.ai\u201d on page 18\n/SM5900003.2, \u201cLow-code, no-code, and full-code tools\u201d on page 203\n\n18 Simplify Your AI Journey: Unleashing the Power of AI with IBM watsonx.ai3.1  Key personas for watsonx.ai \nMany organizations are building data science te ams. Depending on the level of data science \nmaturity within the organization, the types of ro les and the experience of individuals in these \nroles can vary. Common roles in data science te ams include data analysts, data scientists, \nML engineers, and AI engineers. Other roles in organizations that can benefit from IBM watsonx.ai include, but are not limited to, data science leaders, directors of enterprise architecture, and line-of-business users. This section goes through a fe", "metadata": {"source": "sg248574.pdf", "chunk_index": 85, "total_chunks": 313}}
{"text": "rs, directors of enterprise architecture, and line-of-business users. This section goes through a few of these key personas by providing an overview of each ro le\u2019s responsibilities, common challenges that \nindividuals in this role often fa ce, and how IBM watsonx.ai is designed to enable individuals in \nthese roles. \n3.1.1  Data scientists\nData scientists use data to solve proble ms and improve decision making within an \norganization. Depending on th e team and organ ization, their respon sibilities include data \ncollection, model development, data analysis, communication of findings, and providing recommendations. Data scientists often have a background in mathematics, specifically \nstatistics and linear algebra, and programming.\nIndividuals in these roles often face challenges  that are related to a lack of self-service \naccess to the correct, or accurate data, for cleaning, transforming, and generating insights. They also lack integrated tools across the model lifecycle, and depend", "metadata": {"source": "sg248574.pdf", "chunk_index": 86, "total_chunks": 313}}
{"text": "ing, and generating insights. They also lack integrated tools across the model lifecycle, and depending on their level of experience and skill set, they might lack experi ence with creating models by using certain \ntools or programming languages.\nIBM watsonx.ai addressees this situation with vari ous tools within the platform to provide data \nscientists with the flexibility that  they need to build  models. These tools include no-code, \nlow-code, and full-co de solutions such as AutoAI, IBM SPSS\u00ae Modeler, and Jupyter \nNotebooks. watsonx.ai provides many tools to select from because the correct tool to use varies based on factors such as the indivi duals\u2019 level of expertise and the project \nrequirements.\nData scientists often collaborate with others in their team, such as business stakeholders, \ndata science leaders, or fellow data scientists. watsonx.ai enables storing and sharing of assets among users within an organization through projects. In watsonx.ai, \nprojects  are \ncollaborativ", "metadata": {"source": "sg248574.pdf", "chunk_index": 87, "total_chunks": 313}}
{"text": "ets among users within an organization through projects. In watsonx.ai, \nprojects  are \ncollaborative workspaces where individuals can work with and share data and other assets to \naccomplish a specific goal.\n3.1.2  Machine learning engineers\nML engineers work with data scientists and other IT experts, such as software developers to automate and move ML models into production. Typically, ML engineers have a background in computer science, mathematics, statistics, or software engineering. ML engineers are responsible for the data science pipeline, which can include sourcing and preparing data, building and training models, deploying models to production, and maintaining and improving existing ML systems. \nCommon challenges that are faced by ML engi neers include difficulty in defining short and \nlong-term goals, difficulty in scaling ML models , general lack of support for the services that \nare used by various teams, an d incompatibility between tools.\n\nChapter 3. Tools for diverse dat", "metadata": {"source": "sg248574.pdf", "chunk_index": 88, "total_chunks": 313}}
{"text": "at \nare used by various teams, an d incompatibility between tools.\n\nChapter 3. Tools for diverse data science teams 19IBM watsonx.ai helps overcome these challenges by providing various no-code, low-code, \nand full-code tools, which are compatible with each one. Also, with IBM Watson Machine Learning on IBM watsonx.ai, the model deployment process is simplified through capabilities \nsuch as deployment spaces. Regardless of the tool on watsonx.ai that is used to develop the model, ML engineers can deploy the model, which makes it simpler to deploy and manage ML assets. \n3.1.3  AI engineers\nAI engineers are responsible for developing, maintaining, and implementing AI systems. Common tasks that are performed by AI engineers include building and maintaining AI systems, and tuning AI models. AI engineers generally have a background in computer science, mathematics, software engineering, or programming.\nBecause the AI engineer role is new to many organizations, a common challenge many \nteams", "metadata": {"source": "sg248574.pdf", "chunk_index": 89, "total_chunks": 313}}
{"text": "ogramming.\nBecause the AI engineer role is new to many organizations, a common challenge many \nteams and individuals in this ro le face involves having varying levels of technical skills and \nexperience to implement AI solutions. Also, other challenges include selecting and fine-tuning models for a specific use case, and managing the cost to implement and maintain an AI solution. \nIBM watsonx.ai helps AI engineers overcome these challenges in a few ways, starting with \nthe foundation model (FM) library that is provid ed by IBM. This library includes a diverse \nselection of AI models, such as the following ones:\n/SM590000IBM trained models (the Granite and Slate model series) \n/SM590000IBM selected open-source models through Hugging Face\n/SM590000Third-party models such  as llama and mixtral \nTeams can choose among many different FMs for their use case, and choose a model that is \nbest suited for their use case. Teams are not locked into one specific vendor or model series. Also, for mo", "metadata": {"source": "sg248574.pdf", "chunk_index": 90, "total_chunks": 313}}
{"text": "ited for their use case. Teams are not locked into one specific vendor or model series. Also, for more advanced AI engineers, th ey can upload and deploy their own FMs. \nWith watsonx.ai, there are different ways for AI engineers to work with models. The Prompt \nLab tool in watsonx.ai enables AI engineers to write effective prompts (by using a GUI) to deploy to FMs for inferencing. For individu als who have more programming experience and \ntechnical expertise, there is also the programmatic alternative to the Prompt Lab, where users can prompt FMs by using the Python library or REST API. \nYou can use the tuning studio in watsonx.ai to tune a smaller FM to improve its performance. \nAI engineers can tune a smaller FM to achieve comparable results to larger models in the same model family, which can lead to reduced inference costs in the long term. \n\n20 Simplify Your AI Journey: Unleashing the Power of AI with IBM watsonx.ai3.2  Low-code, no-code, and full-code tools\nBecause the demand for", "metadata": {"source": "sg248574.pdf", "chunk_index": 91, "total_chunks": 313}}
{"text": "he Power of AI with IBM watsonx.ai3.2  Low-code, no-code, and full-code tools\nBecause the demand for data scientists has grown over the years, finding experienced data \nscientists is difficult for many organizations. For organizations that are newer to data science, \nthey find that experienced data scientists often request higher salaries or tend to seek opportunities with interesting and advanced problems to solve.\nTherefore, it is important for organizations to find ML and AI platforms that support individuals \nwith varying skill sets. There are many different types of tools for implementing data science, \nmachine learning operations (MLOps), and generative AI (gen AI) solutions. At a high level, they can fall into one of three categories: no-code, low-code, or full-code. \n/SM590000With no-code tools, users can create soluti ons and applications without writing code. The \ntool provides a GUI and includes \u201cdrag-and-drop\u201d features so that users can build models with little to no prog r", "metadata": {"source": "sg248574.pdf", "chunk_index": 92, "total_chunks": 313}}
{"text": " a GUI and includes \u201cdrag-and-drop\u201d features so that users can build models with little to no prog ramming knowledge. \n/SM590000Low-code tools provide a visual approach to  development so that users can generate \nsolutions, such as models, with minimal ha nd-coding. Like no-code tools, these tools \ntypically provide a GUI and include \u201cdrag-and-drop\u201d features. Low-code tools enable users with minimal coding experience, such as citize n data scientists or business analysts to \nquickly build and implement a solution.\n/SM590000With full-code tools, users can write their own code to develop solutions. These tools are \ntypically leveraged by experien ced data scientists. Full-code to ols enable greater flexibility \nand more customization, but require deeper programming knowledge and expertise. \n3.2.1  No-code, low-code, and fu ll-code tools on  IBM watsonx.ai\nWhen to use a no-code, lo w-code, or full-code tool varies by project requirements, team skill \nset, and the time and cost that a spec", "metadata": {"source": "sg248574.pdf", "chunk_index": 93, "total_chunks": 313}}
{"text": "or full-code tool varies by project requirements, team skill \nset, and the time and cost that a specific solution has for an organization. IBM watsonx.ai provides data scientists, ML e ngineers, and AI engin eers with the flexibility of choose the right \ntool for a use case by providing various no-code, low-code, and full-code tools as part of the overall platform. \nNo-code solutions on IBM watsonx.ai\nThis section highlights a few of the no-code tools that are available on the IBM watsonx.ai \nplatform. \nAutoAI\nAutoAI is a no-code tool that data scientists can use to develop and prototype models quickly, \nwithout requiring the user to code or have programming knowledge. AutoAI helps data scientists and data science teams compare the resu lts of multiple models efficiently, thus \nproviding teams with the opportunity to save time and money.\nFigure 3-1 on page 21 shows an AutoAI experiment on watsonx.ai. \n\nChapter 3. Tools for diverse data science teams 21Figure 3-1   AutoAI experiment on ", "metadata": {"source": "sg248574.pdf", "chunk_index": 94, "total_chunks": 313}}
{"text": "n watsonx.ai. \n\nChapter 3. Tools for diverse data science teams 21Figure 3-1   AutoAI experiment on IBM watsonx.ai\nAlthough AutoAI is a no-code tool, the ML pipelines that are generated by an AutoAI \nexperiment can be exported as a notebook. Therefore, more experienced data scientists can view the code \u201cunder the hood\u201d and make modifications and updates to the underlying code. \nFigure 3-2 shows an example notebook that was created from a pipeline that was generated \nfrom an AutoAI experiment. \nFigure 3-2   Pipeline notebook that wa s generated from an AutoAI experiment\n\n\n22 Simplify Your AI Journey: Unleashing the Power of AI with IBM watsonx.aiAutoAI for Retrieval-Augmented Generation \nRetrieval-Augmented Generation (RAG) is an AI framework for improving the quality of large \nlanguage model (LLM)-generated responses by grounding the model in external sources of knowledge to supplement the LLM\u2019s internal representation of information. The key benefits of RAG solutions include reducing ", "metadata": {"source": "sg248574.pdf", "chunk_index": 95, "total_chunks": 313}}
{"text": "he LLM\u2019s internal representation of information. The key benefits of RAG solutions include reducing the chance that an LLM leaks sensitive data or \u2018hallucinate\u2019 incorrect or misleading information, and reducing the need for users to continuously train the model on new data, thus resulting in lower computational and financial costs. For more information about RAG, see What is Retrieval-Augmented Generation?\nMany organizations are implementing RAG solutions  as part of their gen AI efforts. Although \nRAG has many benefits, there are challenges too, such as creating a robust and scalable pipeline, and the time to deliver and implement RAG solutions. \nAutoAI for RAG is a tool that was created by IBM. Similar to AutoAI, AutoAI for RAG is \nintended to help AI engineers quickly build RAG solutions. With AutoAI for RAG, AI engineers can quickly build and test multiple  RAG pipelines without writing code. From the pipelines that \nare generated, the AI engineer can assess the performance of each", "metadata": {"source": "sg248574.pdf", "chunk_index": 96, "total_chunks": 313}}
{"text": "ing code. From the pipelines that \nare generated, the AI engineer can assess the performance of each pipeline, select the best pipeline for their team and project, and deploy it into a production or non-production environment.\nFigure 3-3 shows an AutoAI for RAG experiment.\nFigure 3-3   AutoAI for RAG experiment on IBM watsonx.ai \nFor more information about AutoAI for RAG, view the documentation and demo video at \nCreating a RAG experiment (fast path) (Beta) .\nSynthetic Data Generator \nThe Synthetic Data Generator is a no-code tool that you can use to generate tabular data for \nmodel training. Users have two options to genera te synthetic data by using the graphical flow \neditor in the Synthetic Data Generator tool:\n/SM590000Generate synthetic tabular data based on production data, with the goal of masking and \nmimicking this data. \n/SM590000Generate synthetic data from a custom data sc hema that is defined by the user by using \nvisual flows and modeling algorithms. \n\n\nChapter 3. Tools ", "metadata": {"source": "sg248574.pdf", "chunk_index": 97, "total_chunks": 313}}
{"text": "ema that is defined by the user by using \nvisual flows and modeling algorithms. \n\n\nChapter 3. Tools for diverse data science teams 23Figure 3-4 shows a view of the Synthetic Data Generator interface on watsonx.ai. \nFigure 3-4   Synthetic Data Generator on IBM watsonx.ai\nData Refinery\nData Refinery is a no-code tool that you can use to prepare and visualize data without writing \nany code. With this tool, you can prepare the da ta for analysis by applying operations such as \nfilters and aggregations, and you can generate visualizations such as pie charts and bar charts to extract insights and share findings with stakeholders. \nFigure 3-5 shows an example of a Data Refinery flow on watsonx.ai. \nFigure 3-5   Data Refinery flow on IBM watsonx.ai\n\n\n24 Simplify Your AI Journey: Unleashing the Power of AI with IBM watsonx.aiPrompt Lab\nPrompt Lab is a tool in IBM watsonx.ai that  you can use to experiment with prompting \ndifferent FMs, and create and share effective prompts to submit to deploye", "metadata": {"source": "sg248574.pdf", "chunk_index": 98, "total_chunks": 313}}
{"text": "xperiment with prompting \ndifferent FMs, and create and share effective prompts to submit to deployed FMs for inferencing. Prompt Lab is a no-code tool that provides AI engineers with three different edit \nmodes for prompt editi ng: Chat, Structured, and  Freeform. This flexib ility enables novice and \nexperienced AI engineers to get the most out of Prompt Lab and watsonx.ai. The Chat mode enables users to converse with a FM of their choice. The Structured mode is great for novice users because it helps them create effective pr ompts by providing defined fields, and also by \nproviding sample templates to build on. The Freeform mode is great for more experienced AI engineers who know how to format a prompt; with this option, users submit prompts in plain text. \nFigure 3-6 shows the Chat mode in Prompt Lab on watsonx.ai.\nFigure 3-6   Prompt Lab Chat on IBM watsonx.ai\nLow-code solutions on IBM watsonx.ai\nThis section highlights a few of the low-code tools that are available on the IBM wat", "metadata": {"source": "sg248574.pdf", "chunk_index": 99, "total_chunks": 313}}
{"text": "IBM watsonx.ai\nThis section highlights a few of the low-code tools that are available on the IBM watsonx.ai \nplatform.\nSPSS Modeler\nSPSS Modeler is a low-code tool that you can use to  transform data and build models with \nlittle to no-programming experience. You can drag-and-drop various nodes onto the canvas to create a flow to perform various tasks, such as importing data, merging data, and creating models. \nFigure 3-7 on page 25 shows an exampl e SPSS Modeler flow in watsonx.ai. \n\n\nChapter 3. Tools for diverse data science teams 25Figure 3-7   SPSS Modeler flow on IBM watsonx.ai\nFull-code solutions on IBM watsonx.ai\nThis section highlights a few of the full-code tools that are available on the IBM watsonx.ai \nplatform. \nJupyter Notebook editor\nThe Jupyter Notebook editor is a full-code tool  that is available on IBM watsonx.ai. Jupyter \nNotebooks enable more experienced data scientists and developers to write and run code directly on the IBM watsonx.ai platform. Teams can build mor", "metadata": {"source": "sg248574.pdf", "chunk_index": 100, "total_chunks": 313}}
{"text": "ts and developers to write and run code directly on the IBM watsonx.ai platform. Teams can build more customized and flexible solutions. \nFigure 3-8 shows an example of a Jupyter Notebook on the watsonx.ai platform. \nFigure 3-8   Jupyter Notebook on IBM watsonx.ai\n\n\n26 Simplify Your AI Journey: Unleashing the Power of AI with IBM watsonx.aiRStudio\nRStudio, like the Jupyter Notebook editor, is  a full-code tool that is available on \nIBM watsonx.ai. RStudio enables individuals with  programming experience in R to visualize \ndata, create models, and build solutions by using the R programming language on the IBM watsonx.ai platform. \nFigure 3-9 shows the RStudio interface on the watsonx.ai platform. \nFigure 3-9   RStudio on IBM watsonx.ai\nProgrammatic alternative to Prompt Lab\nIBM watsonx.ai has a Python library and REST API that you can use to prompt FMs. This \napproach is an alternative to the GUI in the Prompt Lab that is used to prompt FMs. This option is great for users who have more ", "metadata": {"source": "sg248574.pdf", "chunk_index": 101, "total_chunks": 313}}
{"text": " the GUI in the Prompt Lab that is used to prompt FMs. This option is great for users who have more programming or technical experience, and for projects and teams that might require an alternative to the Prompt Lab.\nFor more information about using the REST API or Python library to prompt FMs, see Coding \ngenerative AI solutions .\n\n\n\u00a9 Copyright IBM Corp. 2025. 27Chapter 4.Building and using artificial \nintelligence models\nThis chapter serves as a resource for setting up , building, fine-tuning, and deploying artificial \nintelligence (AI) models within  the IBM watsonx.ai ecosystem. By exploring key features, and \nbest practices, it aims to empower users (begin ners or experienced practitioners) to harness \nthe power of AI for developing effective business solutions and enhancing their AI initiatives.\nThe following topics are described in this chapter:\n/SM5900004.1, \u201cPrerequisites and assumptions\u201d on page 28\n/SM5900004.2, \u201cHow to use this chapter\u201d on page 28\n/SM5900004.3, \u201cBuilding and", "metadata": {"source": "sg248574.pdf", "chunk_index": 102, "total_chunks": 313}}
{"text": "sumptions\u201d on page 28\n/SM5900004.2, \u201cHow to use this chapter\u201d on page 28\n/SM5900004.3, \u201cBuilding and using AI models in watsonx.ai\u201d on page 28\n/SM5900004.4, \u201cGetting started with watsonx.ai: Setting up the environment\u201d on page 29\n/SM5900004.5, \u201cData preparation and ingestion for AI model building\u201d on page 34\n/SM5900004.6, \u201cBuilding AI models in watsonx.ai\u201d on page 38\n/SM5900004.7, \u201cDeploying AI models in watsonx.ai\u201d on page 40\n/SM5900004.8, \u201cwatsonx.ai LLM deployment\u201d on page 45\n/SM5900004.9, \u201cOperationalizing machine learning and LLM models\u201d on page 50\n/SM5900004.10, \u201cAdditional information and where to go next\u201d on page 544\n\n28 Simplify Your AI Journey: Unleashing the Power of AI with IBM watsonx.ai4.1  Prerequisites and assumptions\nIn this chapter, it is assumed that you have met the following prerequisites:\n/SM590000An active IBM Cloud\u00ae account: You have an ac tive IBM Cloud account. If you do not have \none, see watsonx.ai .\n/SM590000Familiarity with Jupyter Noteboo ks: You understa", "metadata": {"source": "sg248574.pdf", "chunk_index": 103, "total_chunks": 313}}
{"text": "If you do not have \none, see watsonx.ai .\n/SM590000Familiarity with Jupyter Noteboo ks: You understand how to na vigate and work with Jupyter \nNotebooks for data exploration and model development.\n/SM590000Proficiency in Python: You have basic to intermediate knowledge of Python programming \nbecause many examples, scripts, and workfl ows in this chapter use Python code.\n/SM590000Cloud computing concepts: You have a basic und erstanding of cloud computing principles, \nincluding concepts such as APIs, data storage, computing resources, and cloud-based environments.\n/SM590000Knowledge of large language models (LLMs): A general understanding of LLMs, their \ncapabilities, and use cases is  beneficial for build ing and fine-tuning AI models within \nwatsonx.ai.\n/SM590000You read Chapters 1 - 3 of this book.\n4.2  How to use this chapter\nThis chapter is structured to help users of varying expertise levels by providing a general \napproach to understanding, building, deploying, and optimizing AI ", "metadata": {"source": "sg248574.pdf", "chunk_index": 104, "total_chunks": 313}}
{"text": "se levels by providing a general \napproach to understanding, building, deploying, and optimizing AI models by using the watsonx.ai platform. \nFor beginners, start with the overview sections to familiarize yourself with the platform's \nfeatures and capabilities. Progress through the chapter sequentially, beginning with \nenvironment setup and basic concepts before delving into more comp lex topics, such as \nmodel building an d optimization. \nFor experienced users, you can go directly to sp ecific chapters of in terest, such as model \noptimization techniques, deployment strategies, or advanced configurations. Each section is modular and provides targeted information and best practices that you can apply immediately to your projects. \nThroughout the chapter, you find practical examples, hands-on exercises, and links to more \nresources to help ensure a well-rounded learning experience. \n4.3  Building and using AI models in watsonx.ai\nThis section covers the following topics:\n/SM590000Overvi", "metadata": {"source": "sg248574.pdf", "chunk_index": 105, "total_chunks": 313}}
{"text": "Building and using AI models in watsonx.ai\nThis section covers the following topics:\n/SM590000Overview of the watsonx.ai platform\n/SM590000Key features and capabilities\n4.3.1  Overview of the watsonx.ai platform\nwatsonx.ai is an enterprise-grade AI studio that you use to streamline the development, \ntraining, tuning, and depl oyment of AI models. It  includes generative AI  (gen AI) capabilities \nthat are powered by foundation models (FMs).\n\nChapter 4. Building and using artificial intelligence models 294.3.2  Key features and capabilities\nHere are the key features a nd capabilities of watsonx.ai:\n/SM590000Foundation models: Access various powerful, low-cost, and fit-for-purpose models, such \nas the IBM Granite series and other LLMs for tasks such as content generation, summarization, and classification.\n/SM590000Data preparation: Use tools for refining and visualizing data to help ensure high-quality \ninputs for model training. \n/SM590000Model development: Build machine learning (ML) ", "metadata": {"source": "sg248574.pdf", "chunk_index": 106, "total_chunks": 313}}
{"text": "e high-quality \ninputs for model training. \n/SM590000Model development: Build machine learning (ML) models by using open-source \nframeworks with options for code-based, automated, or visual data science approaches.\n/SM590000Prompt Lab: Experiment with gen AI prompts to enable tasks like question answering, \ncontent generation, summarization, text classification, and data extraction.\n/SM590000Tuning Studio: Fine-tune FMs to customize outputs for specific use cases to enhance \nmodel performance and accuracy.\n/SM590000InstructLab: At the time of writing, this feature is planned to be integrated into watsonx.ai \nin the future.\n4.4  Getting started with watsonx .ai: Setting up the environment\nTo set up the watsonx.ai environment, you must have an IBM Cloud account. To register for \nan account, see Create an IBM Cloud account .\nAt the time of writing, here are the high-level steps to provision watsonx.ai in a \nSoftware-as-a-Service (SaaS) environment:\n1. Set up your IBM Cloud account.2. Crea", "metadata": {"source": "sg248574.pdf", "chunk_index": 107, "total_chunks": 313}}
{"text": " watsonx.ai in a \nSoftware-as-a-Service (SaaS) environment:\n1. Set up your IBM Cloud account.2. Create a Project in watsonx:\na. Log in to https://dataplatform.cloud.ibm.com/login\nb. Expand the \u2018hamburger\u2019 navigation menu, as shown in Figure 4-1.\nFigure 4-1   watsonx navigation menu icon\nc. Select Projects \u2192 View all projects , as shown in Figure 4-2.\nFigure 4-2   View all projects menu\n\n\n30 Simplify Your AI Journey: Unleashing the Power of AI with IBM watsonx.aid. Click New project + , as shown in Figure 4-3.\nFigure 4-3   New project+ menu\ne. Enter the project name and, if app licable, upload lo cal files. Click Create , as shown in \nFigure 4-4.\nFigure 4-4   Create menu\n3. Provision watsonx.ai Studio:\na. Log in to https://cloud.ibm.com/ .\nb. To add services from the catalog, use the search box that is shown in Figure 4-5.\nFigure 4-5   watsonx.ai utilities search box\nc. Enter \u201cwatsonx.ai Studio\u201d and choose the studio from the catalog, as shown in \nFigure 4-6.\nFigure 4-6   wastonx.ai uti", "metadata": {"source": "sg248574.pdf", "chunk_index": 108, "total_chunks": 313}}
{"text": "Studio\u201d and choose the studio from the catalog, as shown in \nFigure 4-6.\nFigure 4-6   wastonx.ai utilities list\nd. Select a pricing plan ( Lite or Professional ), and then click Create .\nFigure 4-7   watsonx.ai pricing plan selection\n4. Generate a watsonx.ai API key:\na. Go to https://cloud.ibm.com/iam/apikeys .\nb. Click Create , as shown in Figure 4-8.\nFigure 4-8   Create API key menu option\n\n\nChapter 4. Building and using artificial intelligence models 31c. Enter the relevant information, and then click Create, as shown in Figure 4-9.\nFigure 4-9   Create IBM Cloud API key\nd. After the API key is successf ully created, copy or downlo ad the key and save it locally, \nas shown in Figure 4-10\nFigure 4-10   API key creation\n5. Open watsonx.ai Studio and associate the watsonx.ai service:\na. In the upper left of your screen, click the four horizontal lines, as shown in Figure 4-11\nFigure 4-11   watsonx.ai studio menu icon\n\n\n32 Simplify Your AI Journey: Unleashing the Power of AI with IBM wat", "metadata": {"source": "sg248574.pdf", "chunk_index": 109, "total_chunks": 313}}
{"text": "  watsonx.ai studio menu icon\n\n\n32 Simplify Your AI Journey: Unleashing the Power of AI with IBM watsonx.aib. Select Resource list , as shown in Figure 4-12.\nFigure 4-12   watsonx.ai studio Resource list option\nc. Expand AI / Machine Learning , as shown in Figure 4-13.\nFigure 4-13   AI / Machine Learning menu option\nd. Click the watsonx.ai Studio  record, as shown in Figure 4-14.\nFigure 4-14   watsonx.ai Studio record icon\ne. Click View full details , as shown in Figure 4-15.\nFigure 4-15   watsonx.ai studio details\nf. Select Launch in \u2192 IBM watsonx , as shown in Figure 4-16.\nFigure 4-16   watsonx.ai Launch in option\nFigure 4-17 shows the Welcome to watsonx window.\nFigure 4-17   Welcome to watsonx window\n\n\nChapter 4. Building and using artificial intelligence models 33g. Click the + in the  Projects table.\nh. Enter a project name, for example, test_project , as shown in Figure 4-18.\nFigure 4-18   Define details window\ni. Select Storage (if required).\nj. Click Create .\nk. Select Chat and", "metadata": {"source": "sg248574.pdf", "chunk_index": 110, "total_chunks": 313}}
{"text": "e 4-18   Define details window\ni. Select Storage (if required).\nj. Click Create .\nk. Select Chat and build prompts with foundations models .\nl. Click Associate service  to associate a Watson ML servic e to the project, as shown in \nFigure 4-19.\nFigure 4-19   Clicking Associate service \nm. Select the displayed Machine Learning  service and click Associate , as shown in \nFigure 4-20.\nFigure 4-20   watsonx machine learning: Associate service\n\n\n34 Simplify Your AI Journey: Unleashing the Power of AI with IBM watsonx.ain. Go to the Assets  tab, and then click New asset , as shown in Figure 4-21.\nFigure 4-21   watsonx projects: All assets\no. Select Chat and build prompts with foundation models , as shown in Figure 4-22. \nFigure 4-22   Chat and build pr ompts with foundation models tile\n4.5  Data preparation and ingestion for AI model building\nThis section describes the following topics:\n/SM590000Understanding the importance of data in AI\n/SM590000Preparing and cleaning data: data quality con", "metadata": {"source": "sg248574.pdf", "chunk_index": 111, "total_chunks": 313}}
{"text": "000Understanding the importance of data in AI\n/SM590000Preparing and cleaning data: data quality considerations\n/SM590000Handling missing data, outliers, and bias\n/SM590000Ingesting data into watsonx.ai Studio\n/SM590000Connecting to data repositories and cloud services\n4.5.1  Understanding the importance of data in AI\nData is the backbone of AI. It shapes the accuracy, effectiveness, and reliability of AI models. \nHigh-quality data enables AI to learn patterns, make predictions, and deliver meaningful \ninsights. Understanding the importance of data in AI goes beyond mere volume; it involves ensuring data accuracy, consistency, and fairness. Poor data quality, bias, or gaps can lead to flawed models, incorrect predictions, and poten tial ethical issues. Therefore, this section \nfocuses on the robust data preparation, cleaning, and validation that is essential for building AI systems that are trustworthy, transparent,  and impactful in real-world applications.\n\n\nChapter 4. Building and u", "metadata": {"source": "sg248574.pdf", "chunk_index": 112, "total_chunks": 313}}
{"text": "are trustworthy, transparent,  and impactful in real-world applications.\n\n\nChapter 4. Building and using artificial intelligence models 354.5.2  Preparing and cleaning data: data quality considerations\nData quality is a critical factor in the success of  AI models because it directly influences their \nperformance and accuracy. Here are some key considerations:\n/SM590000Accuracy: Ensuring that data is correct, consistent, and error-free is vital for creating \nreliable AI models. Inaccurate data can lead to faulty predictions and flawed decision-making.\n/SM590000Completeness: AI models rely on comprehensive datasets to learn effectively. Missing \ndata can skew results, which cause incomplete or biased predictions.\n/SM590000Consistency: Data must be consistent across different sources and formats to help ensure \nthe AI model functions as expected.\n/SM590000Relevance: Data should be pertinent to the problem the AI aims to solve. Irrelevant data \nmight introduce noise and reduce model effec", "metadata": {"source": "sg248574.pdf", "chunk_index": 113, "total_chunks": 313}}
{"text": "t to the problem the AI aims to solve. Irrelevant data \nmight introduce noise and reduce model effectiveness.\n/SM590000Bias and fairness: Addressing data biases and ensuring fairness are critical for building \nethical and unbiased AI systems. Give careful attention to the diversity and representation in data to avoid discrimination and ensure balanced outcomes.\nHigh data quality maximizes th e accuracy, transparency, an d applicability of AI systems, \nwhich ultimately enhances their value and impact.\n4.5.3  Handling missing data, outliers, and bias\nHandling missing data, outliers, and bias is cruc ial for ensuring the accuracy and fairness of \nAI models. Here is how each one is managed: \n/SM590000Handling missing data:\n\u2013 Imputation techniques: Missing data can be filled by using st atistical techniques such \nas mean, median, or mode imputation, or more complex methods like k-nearest neighbors (KNNs) or predictive models.\n\u2013 Data removal: Sometimes, records with significant missing value", "metadata": {"source": "sg248574.pdf", "chunk_index": 114, "total_chunks": 313}}
{"text": "hbors (KNNs) or predictive models.\n\u2013 Data removal: Sometimes, records with significant missing values are removed if they \nare unlikely to add useful information.\n\u2013 Domain knowledge: Input from domain experts can help determine whether missing \ndata should be treated differently based on context. \n/SM590000Handling outliers:\n\u2013 Detection: Outliers are identified by usi ng methods like Z-scores, Interquartile Range \n(IQR), or visualization techniques like boxplots.\n\u2013 Treatment: Once detected, outliers can be managed by removal, transformation (for \nexample, log transformation), or capping values based on acceptable thresholds.\n\u2013 Contextual consideration: Not all outliers are problematic; they might represent \ngenuine data points. Understanding their impact is crucial before deciding on a course of action.\n/SM590000Addressing bias:\n\u2013 Data auditing: Systematic review of datasets to identify sources of bias, such as \nunderrepresentation of specific groups. \n\u2013 Data balancing: Techniques like", "metadata": {"source": "sg248574.pdf", "chunk_index": 115, "total_chunks": 313}}
{"text": "sources of bias, such as \nunderrepresentation of specific groups. \n\u2013 Data balancing: Techniques like oversampling, undersampling, or generating synthetic \ndata (for example, SMOTE) can help balance datasets.\n\n36 Simplify Your AI Journey: Unleashing the Power of AI with IBM watsonx.ai\u2013 Algorithmic bias mitigation: Algorithms can be fine-tuned by using fairness constraints \nor reweighting schemes to minimize bias during model training.\n\u2013 Regular monitoring: Bias can emerge or c hange over time, which requires continuous \nassessment and model updates to maintain fairness and inclusivity.\nBy handling missing data, outliers, and bias, AI models can provide more accurate, reliable, \nand ethical outcomes, which ultimately increa se their utility and impact across diverse \napplications.\n4.5.4  Ingesting data into watsonx.ai Studio\nThis section describes the following topics:\n/SM590000Supported data formats and sources\n/SM590000Manually uploading data to watsonx.ai Studio\nSupported data formats", "metadata": {"source": "sg248574.pdf", "chunk_index": 116, "total_chunks": 313}}
{"text": "ata formats and sources\n/SM590000Manually uploading data to watsonx.ai Studio\nSupported data formats and sources\nwatsonx.ai Studio supports seamless ingestion of diverse data formats and sources to \nfacilitate efficient model devel opment and deployment. Suppor ted formats incl ude structured \ndata (CSV, JSON, and Parquet), semi-structured data (XML and Avro), and unstructured data (plain text and PDF). Data can be sourced from cloud storage platforms (such as AWS S3 and IBM Cloud Object Storage), databases (such as PostgreSQL and MySQL), APIs, and on-premises file systems.\nThe ingestion process is op timized for scalability and ca n handle large datasets while \nensuring data integrity and co mpatibility with downstream AI workflows. Integration with \nwatsonx.data and watsonx.governance tools enables a secure, governed data pipeline, which enhances traceabilit y and compliance.\nManually uploading data to watsonx.ai Studio\nYou can upload files through the watsonx.ai Studio interface by ", "metadata": {"source": "sg248574.pdf", "chunk_index": 117, "total_chunks": 313}}
{"text": "uploading data to watsonx.ai Studio\nYou can upload files through the watsonx.ai Studio interface by dragging the files there, as \nshown in Figure 4-23. \nFigure 4-23   watsonx Studio data upload window\n4.5.5  Connecting to data re positories and cloud services\nwatsonx.ai provides robust connectivity options to integrate with various data repositories and \ncloud services, which help ensure smooth data access for AI model development. Users can \nconnect to cloud storage solutions such as IBM Cloud Object Storage, AWS S3, Azure Blob Storage, and Google Cloud Storage, and traditional databases like PostgreSQL, MySQL, and MongoDB.\nFigure 4-24 on page 37 shows the watsonx cloud services connections window.\n\n\nChapter 4. Building and using artificial intelligence models 37Figure 4-24   watsonx cloud services connections \nAt the time of publication, here are the re positories and services that are supported:\n/SM590000Amazon Redshift\n/SM590000Amazon S3\n/SM590000Apache Cassandra\n/SM590000Apache De", "metadata": {"source": "sg248574.pdf", "chunk_index": 118, "total_chunks": 313}}
{"text": " supported:\n/SM590000Amazon Redshift\n/SM590000Amazon S3\n/SM590000Apache Cassandra\n/SM590000Apache Derby\n/SM590000Apache HDFS\n/SM590000Apache Hive\n/SM590000Apache Impala\n/SM590000Apache Kafka\n/SM590000Box\n/SM590000DataStax Enterprise\n/SM590000Denodo\n/SM590000Dremio\n/SM590000Dropbox\n/SM590000Elasticsearch\n/SM590000Google BigQuery\n/SM590000Google Cloud Pub/Sub\n/SM590000Google Cloud Storage\n/SM590000Google Locker\n/SM590000Greenplum Database\n/SM590000IBM Cloud Data Engine\n/SM590000IBM Cloud Object Storage\n/SM590000IBM Cloudant\u00ae\n/SM590000IBM Cognos\u00ae Analytics\n/SM590000IBM Data Virtualization Manager for IBM z/OS\u00ae\n/SM590000IBM DataStage\u00ae for Cloud Pak for Data\n/SM590000IBM Db2\u00ae\n/SM590000IBM Informix\u00ae\n/SM590000IBM InfoSphere\u00ae DataStage\n/SM590000IBM Match 360\n/SM590000IBM MQ\n/SM590000IBM Netezza\u00ae Performance Server\n/SM590000IBM Planning Analytics\n/SM590000IBM watsonx.data\n/SM590000MariaDB\n/SM590000Microsoft Azure Blob Storage\n/SM590000Microsoft Azure Cosmos DB\n/SM590000Microsoft Azure Data Lake", "metadata": {"source": "sg248574.pdf", "chunk_index": 119, "total_chunks": 313}}
{"text": "00Microsoft Azure Blob Storage\n/SM590000Microsoft Azure Cosmos DB\n/SM590000Microsoft Azure Data Lake Storage\n\n\n38 Simplify Your AI Journey: Unleashing the Power of AI with IBM watsonx.ai/SM590000Microsoft Azure Databricks\n/SM590000Microsoft Azure Files\n/SM590000Microsoft Azure SQL Database\n/SM590000Microsoft Azure Synapse Analytics\n/SM590000Microsoft Power BI\n/SM590000Microsoft SQL Server\n/SM590000Milvus\n/SM590000MongoDB\n/SM590000MySQL\n/SM590000Oracle Database\n/SM590000PostgreSQL\n/SM590000Presto\n/SM590000Salesforce API\n/SM590000SAP ASE\n/SM590000SAP IQ\n/SM590000SAP S/4HANA\n/SM590000SingleStoreDB\n/SM590000Snowflake\n/SM590000Tableau\n/SM590000Teradata database\n/SM590000Vertica\nwatsonx.ai supports secure connection protoc ols, which include API-based integrations, \nJDBC/ODBC drivers, and file transfer mechanisms like SFTP. With built-in authentication and access controls, watsonx.ai helps ensure data  security while main taining flexibility for \nenterprise-scale data workflows.  By streamli", "metadata": {"source": "sg248574.pdf", "chunk_index": 120, "total_chunks": 313}}
{"text": "ure data  security while main taining flexibility for \nenterprise-scale data workflows.  By streamlining access to da ta repositories and services, \nthe platform empowers teams to leverage their existing data infrastructure efficiently.\n4.6  Building AI models in watsonx.ai\nThis section describes the following topics:\n/SM590000Choosing the right model for your use case\n/SM590000Model creation workflow\n4.6.1  Choosing the right model for your use case\nwatsonx.ai supports many model types to meet diverse business needs: \n/SM590000Supervised models  for predictive tasks by using labeled data.\n/SM590000Unsupervised models  for discovering patterns in unlabeled data.\n/SM590000Reinforcement learning  (RL) models for decision-making through rewards and penalties.\n/SM590000Large language models  (LLMs) for natural language understanding and generation. \nPretrained LLMs streamline AI development, which enables faster implementation and powerful insights across applications.\nIn addition to its n", "metadata": {"source": "sg248574.pdf", "chunk_index": 121, "total_chunks": 313}}
{"text": " which enables faster implementation and powerful insights across applications.\nIn addition to its native capa bilities, watsonx.ai embraces flexibility with the IBM Bring Your \nOwn Model (BYOM) feature, which enables users to integrate and fine-tune their own LLMs within the platform for customized solutions. Furthermore, watsonx.ai supports integration with Hugging Face, which enables access to a vast library of pretrained models and tools. This collaboration accelerates development by leveraging open-source innovations while maintaining watsonx.ai enterprise-grade secu rity and scalability.\n\nChapter 4. Building and using artificial intelligence models 394.6.2  Model creation workflow\nThis section describes the workflow of model creation.\nModel selection and configuration\nSelecting the appropriate AI model is key to achieving your business objectives, and \nwatsonx.ai provides the flexib ility to support both LLM and non-LLM models. Whether your \nneeds involve predictive analytics, pa", "metadata": {"source": "sg248574.pdf", "chunk_index": 122, "total_chunks": 313}}
{"text": "b ility to support both LLM and non-LLM models. Whether your \nneeds involve predictive analytics, pattern discovery, decision-making, or natural language \nprocessing (NLP), watsonx.ai helps ensure th at the correct tools are at your fingertips.\nFor non-LLM tasks, the platform accommodates models such as regression, classification, \nclustering, and RL, which enable a wide range of traditional ML applications.\nWhen working with LLMs, watsonx.ai offers various pretrained models in different sizes, from \nlightweight options for tasks that require efficiency and speed to larger, more complex models that are ideal for nuanced language understanding and generation. Choosing the correct size depends on your specific use case, with sm aller models excelling in cost-effective, \nlower-latency scenarios and larger models delivering superior accuracy and depth for intricate applications.\nWith watsonx.ai, you can confidently match the model type and size to your project\u2019s unique \nrequirements to hel", "metadata": {"source": "sg248574.pdf", "chunk_index": 123, "total_chunks": 313}}
{"text": ".ai, you can confidently match the model type and size to your project\u2019s unique \nrequirements to help ensure scalability, efficiency, and impact.\nTraining the model\nTraining your AI model is a crucial step in ta iloring it to your specific business needs. \nwatsonx.ai provides powerful tools and workflows for training both non-LLM models and LLM models, which help ensure flexibility and pr ecision at every stage of development.\nNon-LLM models\nFor traditional ML tasks, watson x.ai offers robust training ca pabilities that leverage tools like \nwatsonx.ai Studio and AutoAI to streamline and enhance the development process.\nwatsonx.ai Studio\nwatson.ai Studio provides a collaborative env ironment for data scientists, developers, and \nanalysts to prepare data, build, and train ML models. With features like Jupyter Notebooks, Python libraries, and model monitoring, wats on.ai Studio is desi gned for flexibility and \nscalability to accommodate pr ojects of any complexity.\nFor more information a", "metadata": {"source": "sg248574.pdf", "chunk_index": 124, "total_chunks": 313}}
{"text": " for flexibility and \nscalability to accommodate pr ojects of any complexity.\nFor more information about watsonx.ai Studio, see IBM Watson Studio .\nAutoAI\nIf you want o accelerate the development process, AutoAI automates key stages of ML, which \ninclude feature engineering, algorithm selection, and hyperparameter optimization. It simplifies the model-building process to make it  accessible to users with varying technical \nexpertise while still deliverin g highly accurate results.\nFor more information about AutoAI, see IBM AutoAI .\nLLM models\nwatsonx.ai provides advanced features for trai ning and fine-tuning LLMs to deliver seamless \ncustomization and performance.\n\n40 Simplify Your AI Journey: Unleashing the Power of AI with IBM watsonx.aiPrompt Lab\nPrompt Lab is an environment for creating and testing prompts that are tailored to specific \ntasks. With Prompt Lab, users can interact with  pretrained LLMs, evaluate their outputs, and \nrefine instructions for optimal results, all withou", "metadata": {"source": "sg248574.pdf", "chunk_index": 125, "total_chunks": 313}}
{"text": "h  pretrained LLMs, evaluate their outputs, and \nrefine instructions for optimal results, all without extensive coding expertise.\nWithin Prompt Lab, you can explore and train various training LLM training methodologies, \nsuch as Zero-Shot, Few-Shot, Multi-Shot, and Retrieval-Augmented Generation (RAG). \nFor more information about Prompt Lab, see Prompt Lab .\nTuning Studio\nFor deeper customization, Tuning Studio enables fine-tuning of LLMs on your proprietary \ndata, which helps ensure that the model adapts  to your specific dom ain while maintaining \nhigh performance. This feature is ideal for organizations seeking more targeted insights and applications from their AI. \nFor more information about Tuning Studio, see Tuning Studio .\nInstructLab\nAt the time of writing, InstructLab is not available. \nInstructLab will revolutionize the training proc ess by enabling users to craft task-specific \ninstructions, which further enhance the prec ision of LLMs in generating accurate and \nactionable ", "metadata": {"source": "sg248574.pdf", "chunk_index": 126, "total_chunks": 313}}
{"text": " \ninstructions, which further enhance the prec ision of LLMs in generating accurate and \nactionable outputs. This tool simplifies the proc ess of aligning model behavior with unique \nbusiness objectives.\nWith these comprehensive training tools, watsonx.ai empowers users to harness the full \npotential of their models, whether refining traditional ML algorithms or unleashing the power of cutting-edge LLMs.\n4.7  Deploying AI models in watsonx.ai\nThis section explores the process of deploying AI models in the watsonx.ai platform. It provides a detailed overview of two major deployment options: Studio and Prompt Lab. From deploying models as APIs for real-time infe rence to batch processing workflows, the \nwatsonx.ai platform helps ensure flexibility and scalability. Readers gain insights into selecting \nthe most appropriate deployment strategy for thei r use case while also learning best practices \nto optimize performance and reliab ility in production environments.\n4.7.1  watsonx.ai Studi", "metadata": {"source": "sg248574.pdf", "chunk_index": 127, "total_chunks": 313}}
{"text": "ctices \nto optimize performance and reliab ility in production environments.\n4.7.1  watsonx.ai Studio deployments\nDeploying models in watsonx.ai St udio involves several key steps to help ensure that your AI \nassets are effectively managed and operational. Here is a concise guide to help you through \nthe process:\n1. Create a deployment space: Begin by estab lishing a deployment space within the studio. \nThis space serves as a collaborative environment where you can manage and deploy your AI assets. To set up a deployment space, go to the Deployment Space section in the Studio interface and follow the prompts to create a space (Figure 4-25 on page 41).\n\nChapter 4. Building and using artificial intelligence models 41Figure 4-25   watsonx.ai studio projects: Deployments\n2. Promote or import your model: When your deployment space is ready, add your trained \nmodel to it. If your model is in a project, promote it to the deployment space. Alternatively, you can import models that are trained ", "metadata": {"source": "sg248574.pdf", "chunk_index": 128, "total_chunks": 313}}
{"text": " project, promote it to the deployment space. Alternatively, you can import models that are trained externally by uploading them directly into the deployment space. Ensure that the model files are in a compatible format and that any necessary dependencies are addressed. \na. Click the three dots, and then click Promote to space  (Figure 4-26).\nFigure 4-26   Model interface window\nb. Enter deployment_test  in to the Name  field, select Production  under Deployment \nstage, and then click Create  (Figure 4-27).\nFigure 4-27   Create a deployment spaceNote:  To help ensure that your trained model is in the right format and compressed, see \nAdding a model by using UI .\n\n\n42 Simplify Your AI Journey: Unleashing the Power of AI with IBM watsonx.ai3. Create the deployment: With your model in the deployment space, initiate the deployment \nprocess:\na. Go to the Deployments window (Figure 4-28).\nFigure 4-28   Deployments window\na. Select deployment_test\nb. Click the generated model\u2019s  service (Figu", "metadata": {"source": "sg248574.pdf", "chunk_index": 129, "total_chunks": 313}}
{"text": "re 4-28   Deployments window\na. Select deployment_test\nb. Click the generated model\u2019s  service (Figure 4-29).\nFigure 4-29   Services\nc. Click New deployment , which opens the window that is shown in Figure 4-30 on \npage 43.\n\n\nChapter 4. Building and using artificial intelligence models 43Figure 4-30   Create a deployment\nd. Under Deployment type, select either  Online or Batch , and enter \nregression_model_deployment  under Name  and regression_model_service  under \nServing name. Click Create .\nOnline deployment is ideal for real-time processing, where the model handles input \ndata and provides immediate predictions. Batch deployment is suitable for processing \nlarge datasets in bulk, which generate predictions for a collection of inputs at scheduled intervals or on-demand. \n\n\n44 Simplify Your AI Journey: Unleashing the Power of AI with IBM watsonx.ai4. Test the deployment: After deployment, validate the model\u2019s functions by going to the \nnewly created deployment and clicking regressio", "metadata": {"source": "sg248574.pdf", "chunk_index": 130, "total_chunks": 313}}
{"text": "ent, validate the model\u2019s functions by going to the \nnewly created deployment and clicking regression_model_deployment , as shown in \nFigure 4-31. \nFigure 4-31   Deployment overview\nwatsonx.ai Studio provides multiple ways to test the deployment, such as the Test tab and \ncode snippets (Figure 4-32).\nFigure 4-32   Deployment testing\n\n\nChapter 4. Building and using artificial intelligence models 45By following these steps, you can effectively deploy and manage your AI models within \nwatsonx.ai Studio, which helps ensure that the models are ready for production use and \ncapable of delivering valuable insights. \n4.8  watsonx.ai LLM deployment\nDeploying models in watsonx.ai St udio involves several key steps to help ensure that your AI \nassets are effectively managed and operational. This section provides a concise guide to help you through the process:\n4.8.1  Model packaging and exporting\nTo package and export a model, complete the following steps:\n1. Go to the Prompt Lab window, and if y", "metadata": {"source": "sg248574.pdf", "chunk_index": 131, "total_chunks": 313}}
{"text": "o package and export a model, complete the following steps:\n1. Go to the Prompt Lab window, and if you do not already have a prompt set up, populate it \nby using the example that is shown in Figure 4-33. In this lab, you use a text classification prompt. \nFigure 4-33   watsonx Prompt Lab\n\n\n46 Simplify Your AI Journey: Unleashing the Power of AI with IBM watsonx.ai2. Generate a response by the prompt. Keep the decoding method as Greedy , and set the \nmax tokens to 5 to produce Positive and Negative text only (Figure 4-34).\nFigure 4-34   Model parameters\n3. Click Generate , which tests the prompt. Then, click the View code icon (Figure 4-35).\nFigure 4-35   View code icon\n4. Copy the code to a notepad application (Figure 4-36).\nFigure 4-36   Code example\n\n\nChapter 4. Building and using artificial intelligence models 47The code (Figure 4-37) is an example of a REST call that starts the model. watsonx.ai \nalso provides a Python API for model invoca tion, which you review later in this lab. ", "metadata": {"source": "sg248574.pdf", "chunk_index": 132, "total_chunks": 313}}
{"text": ". watsonx.ai \nalso provides a Python API for model invoca tion, which you review later in this lab. \nThe header of the REST request includes the URL where the model is hosted and a \nplaceholder for the authentication token. At the time of writing, all users share a single model inference endpoint. In the future, IBM plans to provide dedicated model endpoints.\nSecurity is managed by the IBM Cloud authentication token, which is described later in \nthis section. \nThe body of the request contains the entire prompt. \nFigure 4-37   Curl command example\n5. At the end of the request, you specify the model parameters and the project ID, as shown \nin Figure 4-38 . \nFigure 4-38   Curl command details\n\n\n48 Simplify Your AI Journey: Unleashing the Power of AI with IBM watsonx.aiTo look up the project ID, select Project \u2192 General \u2192 Manage  in the watsonx.ai project, \nas shown in Figure 4-39.\nFigure 4-39   Projects Manage view\n6. Save the newly configured prompt as a notebook. Select Standard noteboo", "metadata": {"source": "sg248574.pdf", "chunk_index": 133, "total_chunks": 313}}
{"text": "39   Projects Manage view\n6. Save the newly configured prompt as a notebook. Select Standard notebook as the \nasset type and then select Save as , as shown in Figure 4-40.\nFigure 4-40   Notebook save icon\n7. You will now create an authentication token. Open the na vigation menu (four horizontal \nbars) in the upper left of the watsonx interface and select Access (IAM) , as shown in \nFigure 4-41 on page 49.\n\n\nChapter 4. Building and using artificial intelligence models 49Figure 4-41   Access (IAM) menu item\n8. Select API Keys \u2192 Create . Give the token a name and save it in a notepad (Figure 4-42). \nYou use the token in a Python notebook.\nFigure 4-42   API keys\n9. Go to your watsonx project and open the notebook that you saved in step 8 (Figure 4-43). \nFigure 4-43   watsonx Studio projects overview\n\n\n50 Simplify Your AI Journey: Unleashing the Power of AI with IBM watsonx.ai10.Review the sample notebook. \nThis notebook acts as a cli ent application that starts the deployed LLM with a Pyth", "metadata": {"source": "sg248574.pdf", "chunk_index": 134, "total_chunks": 313}}
{"text": "mple notebook. \nThis notebook acts as a cli ent application that starts the deployed LLM with a Python SDK. \nYou use the notebook as a client for simplicity of testing during this lab.\nEnterprise client applications can be implemented in Python, Java, .NET, and many other \nprogramming languages. LLMs that are deployed in watsonx.ai can be started either with REST calls or the Python SDK.\nRun the notebook to test the LLM with your prompts.\n4.9  Operationalizing machine learning and LLM models\nNow that you have a machine learning (ML) model or LLM built, you now enter the operational \nphase. Much like how traditional application development created the need for formal DevOps tools and systems, so too have AI models created the need for ModelOps. ModelOps is the practice of enabling the deployment and management of models throughout the application development and deploymen t lifecycle with the goal of operat ionalizing models in production. \nAs a joint endeavor with traditional DevOps, M", "metadata": {"source": "sg248574.pdf", "chunk_index": 135, "total_chunks": 313}}
{"text": " the goal of operat ionalizing models in production. \nAs a joint endeavor with traditional DevOps, ModelOps takes the feedback and measurements that are taken in the DevOps lifecycle to iterate on the training, testing and deploying stages of th e ModelOps lifecycle. \nKey stages in the ModelOps lifecycle include governance, monitoring, deployment of \ninfrastructure, and m odel versioning. IBM offers variou s tools to help facilitate these \nprocesses, each of which has its own place in the lifecycle. Examples of such tools include \nthe following ones: \n/SM590000IBM watsonx.gov  helps govern and monitor model key performance indicators (KPIs).\n/SM590000IBM Instana \u00ae\u2122 helps monitor LLM performance, responsiveness, and throughput at the \napplication level.\n/SM590000IBM Turbonomic \u00ae can help dynamically scale up and down infrastructure as the workload \nagainst your models changes.\n/SM590000IBM API Connect \u00ae provides a GUI wizard to create AI-aware APIs and products, plus \nintegration with A", "metadata": {"source": "sg248574.pdf", "chunk_index": 136, "total_chunks": 313}}
{"text": "M API Connect \u00ae provides a GUI wizard to create AI-aware APIs and products, plus \nintegration with AI services to forward requests and manage responses.\nTo demonstrate how these models can be deployed into existing applicat ions, we briefly walk \nthrough how to call these models, and integrate them into the DevOps and ModelOps lifecycle. \n4.9.1  Calling ML mode ls by using API calls\nWhen you have built a model, your ML model is live and ready to perform as an inference \nendpoint. This endpoint is your gateway to interact with the model so that you can send data and receive predictions in return. Here, we walk through how you can use it effectively. \nSecuring your API key \nBefore making any calls to your endpoint, yo u need an API key for se cure access. For more \ninformation about generating this key, see 4.8, \u201cwatsonx.ai LLM deployment\u201d on page 45. Here is a quick overview: \n1. Go to your deployed model in watsonx.ai Studio.\n2. Go to the Access  tab under the Deployment settings. \n3. ", "metadata": {"source": "sg248574.pdf", "chunk_index": 137, "total_chunks": 313}}
{"text": "ur deployed model in watsonx.ai Studio.\n2. Go to the Access  tab under the Deployment settings. \n3. Generate your API key and store it securely. (You use it to authenticate your requests.) \n\nChapter 4. Building and using artificial intelligence models 51Making an API call\nWith your API key in hand, you are ready to communicate with your model. Figure 4-44 shows \nan example of a simple POST request (by using a cURL command) to send input data and \nretrieve predictions.\nFigure 4-44   watsonx.ai regr ession model deployment tool\nNote:  The watsonx.ai user interface (UI) prepopulates different ways to call the model, \nsuch as cURL, Java, JavaScript, Python, Scala, and others. \n\n\n52 Simplify Your AI Journey: Unleashing the Power of AI with IBM watsonx.aiVisualizing the process\nFigure 4-45 shows a simple way to visua lize what occurs during an API call.\nFigure 4-45   API call visualization\nYour application sends input data to the endpoint; the model processes the data; and the \nresults are s", "metadata": {"source": "sg248574.pdf", "chunk_index": 138, "total_chunks": 313}}
{"text": "r application sends input data to the endpoint; the model processes the data; and the \nresults are sent back as predictions. Whether you are handling real-time data (through online deployment) or batch processing, this streamlined interaction helps ensure that you can make the most of your deployed model.\n4.9.2  Calling Prompt Lab LLM  models by using API calls\nCalling an LLM model from Prompt Lab is sim ilar to calling an LLM model from watsonx.ai\u2019s \nStudio; the only difference is where to find the code within the UI to do so. To accomplish this task, complete the following steps:\n1. Go to Prompt Lab, and then build your prompt in either the Chat , Structured , or Freeform  \ntab. \n2. In the upper right, click the View code  icon (Figure 4-46).\nFigure 4-46   View code icon\nThe Prompt Lab automatically creates everything that you need to copy and paste your \nprompt into the application of your choosing (in either cURL, Node.js, or Python), as shown in Figure 4-47 on page 53. \n\n\nChapter ", "metadata": {"source": "sg248574.pdf", "chunk_index": 139, "total_chunks": 313}}
{"text": " your choosing (in either cURL, Node.js, or Python), as shown in Figure 4-47 on page 53. \n\n\nChapter 4. Building and using artificial intelligence models 53Figure 4-47   watsonx.ai Prompt Lab code window \n4.9.3  IBM watsonx Assistant\nOperationalizing AI and ML models by using IBM technology helps ensure seamless \ndeployment and management across enterprise environments while delivering measurable business outcomes. IBM watsonx.ai provides a robust platform for building, fine-tuning, and deploying AI models to enable data scientists to leverage pre-trained models or create custom solutions. Once models are developed, they can be containerized and deployed by using Red Hat OpenShift, which is the IBM enterprise Kubernetes platform, which helps ensure scalability, high availabilit y, and integration with an existi ng infrastructure. IBM Watson \nStudio simplifies model lifecycle management by providing end- to-end capabilities for version \ncontrol, testing, and collaboration. Real-time moni", "metadata": {"source": "sg248574.pdf", "chunk_index": 140, "total_chunks": 313}}
{"text": " providing end- to-end capabilities for version \ncontrol, testing, and collaboration. Real-time monitoring is enabled through IBM Instana Observability so that teams can track KPIs, detect anomalies, and maintain model health in \nproduction environments.Note:  Include your bearer access token. For more information about this token within the \nIBM ecosystem, see Generating a bearer token .\n\n\n54 Simplify Your AI Journey: Unleashing the Power of AI with IBM watsonx.aiFigure 4-48 shows an overview of IBM watsonx Assistant.\nFigure 4-48   IBM watsonx Assistant overview\nEnsuring the ongoing success of operational AI and ML solutions requires integrating \ngovernance, automation, and business alignment. IBM watsonx.governance enforces responsible AI principles by providing tool s for bias detection, lineage tracking, and \ncompliance management, which help organizations meet regulatory requirements and ethical standards. Automated deployment pipelines with IBM DevOps for AI streamline continuous", "metadata": {"source": "sg248574.pdf", "chunk_index": 141, "total_chunks": 313}}
{"text": "s and ethical standards. Automated deployment pipelines with IBM DevOps for AI streamline continuous integration and continuous delivery (CI/CD), which enables rapid updates and retraining to address data drift or evolving business needs. Feedback loops that are powered by IBM Watson Discovery facilitate continuous improvement by analyzing real-world user \ninteractions to enhance model performance. By leveraging IBM\u2019s AI and hybrid cloud capabilities, organizations can operationalize AI and ML soluti ons effectively, which drive \ninnovation while helpin g ensure reliability and trustworthiness.\nFor more information about tools that are related to operationalizing your models, see 4.10.3, \n\u201cwatsonx.ai data pipeline and orchestration\u201d on page 55.\n4.10  Additional information and where to go next\nIn this chapter, you le arned the following things:\n/SM590000How to set up your environment, which includes IBM Cloud accounts and project \nconfiguration.\n/SM590000The key features of watsonx.ai,", "metadata": {"source": "sg248574.pdf", "chunk_index": 142, "total_chunks": 313}}
{"text": "ich includes IBM Cloud accounts and project \nconfiguration.\n/SM590000The key features of watsonx.ai, such as FMs, Prompt Lab, and Tuning Studio.\n/SM590000The importance of data quality, cleaning, and ingestion for AI model development.\n/SM590000Building and training AI models, which include traditional ML and LLMs, by using tools like \nAutoAI, Tuning Studio, and InstructLab.\n/SM590000Deploying AI models as APIs for real-time or batch processing and integrating them with \nenterprise systems.\n\n\nChapter 4. Building and using artificial intelligence models 554.10.1  Additional support and documentation\nwatsonx.ai has extensive support and documentat ion to help users maximize the platform's \ncapabilities. The IBM watsonx Documentation Portal  offers a comprehensive collection of \nresources, which include detailed user guides, tutorials, API references, and best practices. Whether you are starting or looking to optimize your AI workflows, the portal helps ensure that you have the guidance t", "metadata": {"source": "sg248574.pdf", "chunk_index": 143, "total_chunks": 313}}
{"text": "rting or looking to optimize your AI workflows, the portal helps ensure that you have the guidance that you need to succeed.\nHighlights include th e following resources:\n/SM590000Getting Started Guides: Step-by-step instructions for onboarding and initial setup.\n/SM590000Model Development Resources: In-depth documentation about training, fine-tuning, and \ndeploying both LLM and non-LLM models.\n/SM590000Troubleshooting and FAQs: Solutions to common issues and tips for resolving challenges \nefficiently.\n/SM590000Integration Guidance: Instructions for incorporating watsonx.ai into existing workflows and \nleveraging tools, such as Hugging Face and BYOM.\nThis rich repository of knowledge empowers users at every skill level to confidently build, \ndeploy, and scale AI solutions with watsonx.ai.\n4.10.2  watsonx.ai API reference\nFor comprehensive guidan ce about using watsonx. ai capabilities, the IBM watsonx API \nDocumentation  offers detailed information about avail able APIs, including endpo", "metadata": {"source": "sg248574.pdf", "chunk_index": 144, "total_chunks": 313}}
{"text": "e IBM watsonx API \nDocumentation  offers detailed information about avail able APIs, including endpoints, request \nparameters, and response structures. This resource is essential for developers that want to integrate watsonx.ai into their applications by  providing clear instructions and examples to \nfacilitate seamless implementa tion. Whether you are working with FMs, performing text \ninference, or managing deployments, this docum entation serves as a valuable reference to \nhelp ensure effective and efficient usage of watsonx.ai features.\n4.10.3  watsonx.ai data pipeline and orchestration\nFor more information about data pipelining and orchestration, see the following resources:\n/SM590000IBM Orchestration Pipelines:\nhttps://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/ml-orchestrati\non-overview.html?context=wx\n/SM590000IBM Seismic: Introducing AI Agent Orchestration (IBMid required):\nhttps://ibm.seismic.com/Link/Content/DCbHf2RCFTPf3G9Cc2PBGggJWfGV\n/SM590000Instana: \nhttps", "metadata": {"source": "sg248574.pdf", "chunk_index": 145, "total_chunks": 313}}
{"text": "equired):\nhttps://ibm.seismic.com/Link/Content/DCbHf2RCFTPf3G9Cc2PBGggJWfGV\n/SM590000Instana: \nhttps://www.ibm.com/products/instana/generative-ai-monitoring\n/SM590000Turbonomic:\nhttps://community.ibm.com/community/user/aiops/blogs/cheuk-hung-lam/2024/05/28/\nturbonomic-tackles-gpus-for-genai-workloadshttps://www.ibm.com/case-studies/ibm-big-ai-models-turbonomic\n\n56 Simplify Your AI Journey: Unleashing the Power of AI with IBM watsonx.ai\n\n\u00a9 Copyright IBM Corp. 2025. 57Chapter 5.Advanced capabilities of \nwatsonx.ai\nwatsonx.ai embodies IBM\u2019s extensiv e expertise in artificial in telligence (AI) and foundation \nmodels (FMs), which combine advanced AI research with practical tools to make large language models (LLMs) efficient and versatile across many applications. Underlying watsonx.ai is its integration of FMs that are tuned to accelerate and optimize business operations. These models are positioned to perform at the intersection of language understanding, structured data processing, and ", "metadata": {"source": "sg248574.pdf", "chunk_index": 146, "total_chunks": 313}}
{"text": "ositioned to perform at the intersection of language understanding, structured data processing, and knowledge retrieval, which enhance the ability to extract, refine, and use va st amounts of unstructured data.\nThe platform's capabilities ex tend beyond simple text processing to include complex \ninteractions between structured and unstructured data sources, which enable the model to draw relevant information and learn domain-specific knowledge. For example, watsonx.ai supports both general- purpose and highly specialized mode l architectures, which facilitate \nthe design of task-optimized LLMs that serve nuanced business needs while ensuring data privacy and regulatory complia nce. Its multi-modal capabilit ies enable seamless handling of \ndiverse data types (such as text, image, and audio inputs) and applications to traverse disparate data landscapes cohesively, which achi eves a high level of contextual relevance \nand adaptability.\nThe watsonx.ai platform has several capabilities to ", "metadata": {"source": "sg248574.pdf", "chunk_index": 147, "total_chunks": 313}}
{"text": "evel of contextual relevance \nand adaptability.\nThe watsonx.ai platform has several capabilities to support advanced use cases such as \nprompt engineering, multi-task prompt tuning, and fine-tuning. \nThe following topics are described in this chapter:\n/SM5900005.1, \u201cPrompt engineering\u201d on page 58\n/SM5900005.2, \u201cMultitask prompt tuning\u201d on page 61\n/SM5900005.3, \u201cFine-tuning\u201d on page 64\n/SM5900005.4, \u201cInstructLab\u201d on page 675\n\n58 Simplify Your AI Journey: Unleashing the Power of AI with IBM watsonx.ai5.1  Prompt engineering\nPrompt engineering within the watsonx.ai ecosystem serves as an essential component in \nharnessing the full potential of language models. By precisely framing prompts, users can guide LLM responses to ward relevance and co herence, which greatly enhances the utility of \ngenerated outputs. The process of prompt engineering in watsonx.ai is highly nuanced, and it involves detailed adjustments to phrasing, context, and iterative feedback mechanisms to yield wanted output", "metadata": {"source": "sg248574.pdf", "chunk_index": 148, "total_chunks": 313}}
{"text": " detailed adjustments to phrasing, context, and iterative feedback mechanisms to yield wanted outputs consistently. Prompt engineering plays a pivotal role in directing LLMs to perform specific tasks with high precision, a ta sk that requires linguistic adjustments and a \ndeep understanding of the underlying model dynamics.\nThe reason why prompt engineering is important is because it is a way to make generalist \nmodels (LLMs) perform a specific task. Without quality informat ion, well-defin ed instructions, \nand a clear set of examples, the model might misbehave and hallucinate in various ways.\nPrompt engineering is about writing something in a better, clearer, and cleaner form. It also \ninvolves using specific system tokens that are for only the model that is used and, if available, a series of examples that provide better information to the model so that it can perform as intended. This approach is explored more in-depth in this section.\n5.1.1  Prompting techniques\nThere are three ma", "metadata": {"source": "sg248574.pdf", "chunk_index": 149, "total_chunks": 313}}
{"text": "s approach is explored more in-depth in this section.\n5.1.1  Prompting techniques\nThere are three main prompting techniques: \n/SM590000Zero-shot prompting\n/SM590000One-shot prompting\n/SM590000Few-shot prompting\nThese techniques are not learning techniques, but prompting techniques only, which improve \nmodel performances at inference-time without modifying the original model.\nThese techniques leverage the model's existing capabilities with out requiring fine-tuning or \nparameter updates, which make them lightweight and adaptable solutions for various use cases. This section provides an explanation of each prompting technique, and when it is best to use each approach.\n/SM590000Zero-shot prompting: Relies solely on the model's pre-trained knowledge to generate \nresponses without providing any task-specific examples in the prompt. Instead, the input typically includes clear instructions or a well-defined query that guides the model to perform the task, for example, asking a model to summar", "metadata": {"source": "sg248574.pdf", "chunk_index": 150, "total_chunks": 313}}
{"text": " well-defined query that guides the model to perform the task, for example, asking a model to summarize a paragraph or translate a sentence into another language without providi ng prior examples. The effectiveness of this \napproach hinges on the clarity and precision of the prompt and the model's inherent ability \nto generalize across diverse tasks.\n/SM590000One-shot prompting: In this approach, a single example of the task is embedded within the \nprompt, alongside the query or instructions. This example serves as a reference for the \nmodel to infer the behavior. By including a single demonstration, one-shot prompting can \nenhance performance for tasks that require nuanced or domain-specific understanding because it provides a concre te context for the model to interpret the instructions.\n\nChapter 5. Advanced cap abilities of watsonx.ai 59/SM590000Few-shot prompting: Expands on this concept by incorporating multiple examples of the \ntask in the prompt. The additional examples provide ", "metadata": {"source": "sg248574.pdf", "chunk_index": 151, "total_chunks": 313}}
{"text": "cept by incorporating multiple examples of the \ntask in the prompt. The additional examples provide a richer context and help the model \nbetter understand complex patterns or subtle variations in the task. Few-shot prompting is useful for tasks that require multi-step reasoning, handling of ambiguous inputs, or understanding domain-specific jargon. However, it demands careful prompt construction to balance informativeness and brevity because excessive length can lead to token limitations or diminished performance.\nFigure 5-1   LLM prompting method types overview\n5.1.2  Importance of system tokens\nIn addition to zero-shot, one-shot, and few-shot prompting techniques, system tokens  (also \nknown as system-level instructions  or control tokens) play a critical role in crafting effective \nprompts. These tokens provide metadata or guidance to steer the behavior of the language model at a higher level, often defining the co ntext, tone, or expected behavior of the model \nduring inference. Im", "metadata": {"source": "sg248574.pdf", "chunk_index": 152, "total_chunks": 313}}
{"text": "er level, often defining the co ntext, tone, or expected behavior of the model \nduring inference. Importantly, the implementati on and interpretation of these tokens can vary \nacross different models, making their effective use model specific.\nSystem tokens enable users to establish a \u201crole\u201d or context for the model, shaping its \nresponses beyond what is specified in the natural language prompt. \nBy embedding these tokens, users can accomplish the following goals:\n/SM590000Control output behavior: Ensure the order of prompt completions between the main \nprompt areas of System, Assistant, and User\n/SM590000Reduce ambiguity: Guide the model's interpretation of the task, especially in contexts \nwhere instructions alone might be misinterpreted.\n/SM590000Enhance few-shot learning: When combined with example-based prompting, system \ntokens can provide an overarching framework that amplifies the impact of the examples.\n5.1.3  Model-specific peculiarities\nDifferent language models interpret an", "metadata": {"source": "sg248574.pdf", "chunk_index": 153, "total_chunks": 313}}
{"text": "e impact of the examples.\n5.1.3  Model-specific peculiarities\nDifferent language models interpret and use system tokens in unique ways due to their architecture and pre-training data. The best practices for incorporating system tokens are to understand model documentation. Because the behavior of system tokens is model-dependent, consulting the model's technical documentation is essential to understanding how tokens are implemented and what variations are supported.\n\n\n60 Simplify Your AI Journey: Unleashing the Power of AI with IBM watsonx.ai5.1.4  How watsonx.ai suppo rts prompt engineering\nRegarding prompt engineering, the simplest way to interact with LLMs is extensive but \npeculiar. Fortunately, the watsonx.ai platform enables prompt engineering by providing a series of tools for its usage. Figure 5-2 shows a series of these tools in the Prompt Lab section of watsonx.ai.\nFigure 5-2   watsonx.ai Prompt Lab dashboard\nPrompt Lab is the main area to access and interact with LLMs. Here,", "metadata": {"source": "sg248574.pdf", "chunk_index": 154, "total_chunks": 313}}
{"text": " watsonx.ai Prompt Lab dashboard\nPrompt Lab is the main area to access and interact with LLMs. Here, it is possible to interact with models and perform prompt engineering techniques. In Prompt Lab, users have three modes to select from to interact with LLMs:\n/SM590000Chat mode: Provides a simplisti c, multimodal chatbot-like inte raction with capabilities such \nas memory and document understanding. It is good for model interaction and for simple system prompt definition and a zero-shot-prompting approach.\n/SM590000Structured mode: Provides a way to set up your prompt to create a particular prompt \nengineering setting within the main model Instructions and Examples, where the examples are the input/output series that is provided in a few-shot-prompting setting. It automatically applies the system tokens for a specific model to best fit the one/few-shot-prompting setting.\n/SM590000Freeform mode: Provides more advanced users with the option to be free of crafting their \nraw prompt by usin", "metadata": {"source": "sg248574.pdf", "chunk_index": 155, "total_chunks": 313}}
{"text": " mode: Provides more advanced users with the option to be free of crafting their \nraw prompt by using all the possible prompt  engineering capabilitie s that leverage raw \nsystem tokens. Although this mode leverages the power of prompt engineering and freedom, it requires specific skills in unde rstanding system tokens, what they are for a \nspecific model, and how to use them.\nAlthough prompt engineering provides a faster way to the objective, it is not always the best \ntool to use or the most capable tool that is  available. As task difficulty and complexity \nincreases, watsonx.ai can use more advanced model enhancing techniques. We explore these techniques in the following sections of this chapter. \n\n\nChapter 5. Advanced cap abilities of watsonx.ai 615.2  Multitask prompt tuning\nMultitask prompt tuning  within watsonx.ai builds on traditional prompt engineering by \nimplementing adaptive mechanisms to refine the prompt\u2019s interpretative accuracy over time. This approach differs fundame", "metadata": {"source": "sg248574.pdf", "chunk_index": 156, "total_chunks": 313}}
{"text": "e mechanisms to refine the prompt\u2019s interpretative accuracy over time. This approach differs fundamentally from prompt engineering because it modifies prompt content and continuously aligns the model\u2019s interpretative layers with domain-specific expectations. In essence, prompt tuning enables models to retain learned adjustments across sessions, which support consistency and reduce  the need for extensive re-engineering.\nPrompt tuning leverages techniques such as embedding adjustments and parameter scaling \nto influence the model\u2019s internal state and guide responses within boundaries. Using the watsonx.ai dynamic configuration settings, de velopers can set up continuous tuning \nprocesses that adapt prompts based on evolving  business contexts, which lead to a finely \ncalibrated model that re flects current operation al realities. This c apability enables rapid \nadaptation without costly retraining, and the watsonx.ai architecture permits this tuning to take place seamlessly, which enabl", "metadata": {"source": "sg248574.pdf", "chunk_index": 157, "total_chunks": 313}}
{"text": "etraining, and the watsonx.ai architecture permits this tuning to take place seamlessly, which enables real-time adjustments as new data is ingested or as user preferences change.\nIn this setting, it is not the LLM that is modified. Instead, a dedicated, smaller LLM is trained to \ngenerate the best possible prompt adjustment for each prompt in the input. The smaller LLM leverages the system tokens that are available for each LLM on watsonx.ai and produces new, compatible virtual tokens to enhance the performances. The smaller LLM is trained by using a loss function that accounts for the resulting response from the immutable (in this setting) generative LLM model that you want to improve, and adapts its weights to create better prompts through a \ntunable soft prompt , as shown in Figure 5-3.\nFigure 5-3   Prompt tuning overview \nWith prompt tuning, you create a model that automatizes the prompt engineering task, which makes it dynamically adaptive to new, incoming inputs over time. The k", "metadata": {"source": "sg248574.pdf", "chunk_index": 158, "total_chunks": 313}}
{"text": "rompt engineering task, which makes it dynamically adaptive to new, incoming inputs over time. The key benefit of prompt tuning is performing tuning in ways that are better than what experts can do for certain tasks, that is, the best token leading to a successful completion of the input task. Prompt tuning can do this task because it leverages 100 - 10000 examples to learn whic h token is the best one \nto add to a starting pre-engineered prompt to minimize the loss of the generative model. \n\n\n62 Simplify Your AI Journey: Unleashing the Power of AI with IBM watsonx.aiThe watsonx.ai platform provides a simplistic way of using prompt tuning, as shown in \nFigure 5-4.\nFigure 5-4   Prompt tuning in watsonx.ai Tuning Studio\n5.2.1  Prompt tuning parameters\nIn watsonx.ai Tuning Studio, you can use multitask prompt tuning by leveraging various prompt tuning parameters. The process of optimizing hyperparameters for prompt tuning, such as batch size, the number of epochs, the learning rate, and a", "metadata": {"source": "sg248574.pdf", "chunk_index": 159, "total_chunks": 313}}
{"text": "yperparameters for prompt tuning, such as batch size, the number of epochs, the learning rate, and accumulation steps, plays a critical role in achieving task-specific adaptation and helping ensure effective usage of LLMs. Each of these parameters impacts the training process in unique ways by influencing the generalization ability, st ability, computational ef ficiency, and pe rformance of th e fine-tuned \nprompts.\n/SM590000\nBatch size  refers to the number of training samples that are processed simultaneously \nduring each forward and backward pass through the model. It is a fundamental factor in determining the balance between computational efficiency and the quality of gradient updates. Larger batch sizes tend to stabiliz e gradient updates by averaging over more \nsamples, which enable faster convergence.  However, they often require significant \ncomputational resources and might overlook fine -grained variations in  the dataset, which \nmight potentially limit the prompt's ability t", "metadata": {"source": "sg248574.pdf", "chunk_index": 160, "total_chunks": 313}}
{"text": "look fine -grained variations in  the dataset, which \nmight potentially limit the prompt's ability to address nuanced tasks.  Conversely, smaller \nbatch sizes enable greater granularity in gradi ent computations, which is advantageous for \nsmall datasets or specific tasks. However, small batches introduce noisier gradient updates, which require more iterations to c onverge effectively. To optimize batch size, \npractitioners should aim for a balance that satisfies computat ional feasibility while meeting \nthe requirements of the task. Dynamic batch sizing (adjusting the batch size during training) can further stabilize the learning process and e nhance overall effectiveness.\n/SM590000The \nnumber of epochs  represents the total number of complete passes that the training \nalgorithm makes through the dataset. This parameter directly influences how thoroughly the model explores the data to refine its prompt parameters. A higher number of epochs allows the model to capture in tricate patter", "metadata": {"source": "sg248574.pdf", "chunk_index": 161, "total_chunks": 313}}
{"text": "efine its prompt parameters. A higher number of epochs allows the model to capture in tricate patterns, which improv es task-specific adaptation. \nHowever, this approach  comes with the risk of overfitting, especially with smaller datasets, \nwhich reduce the generalization of the prompt s. Conversely, a lower number of epochs \nminimizes the risk of overfitting but might lead to underoptimized prompts that fail to leverage the model's full potential. To strike the right balance, monitor validation loss and apply early stopping criteria to help ensure that training halts before overfitting occurs. \nUsing pre-trained checkpoints can also reduc e the need for extensive epochs because \nthese starting points encapsulate foundatio nal knowledge that accelerates convergence.\n\n\nChapter 5. Advanced cap abilities of watsonx.ai 63/SM590000The learning rate  governs the size of the updates that are made to prompt parameters \nduring each optimization step. It influences the speed and stability of th", "metadata": {"source": "sg248574.pdf", "chunk_index": 162, "total_chunks": 313}}
{"text": "ade to prompt parameters \nduring each optimization step. It influences the speed and stability of th e training process. \nA high learning rate expedites convergenc e, which reduces training time but risks \novershooting optimal solutions, and can lead to suboptimal performance or even divergence. Conversely, a low learning rate enables a more precise exploration of the \nparameter space, which increases the likelihood of finding an optimal solution at the cost of prolonged training. Effective strategies include employing learning rate schedules, such as cosine decay or step-based decay, which adjust the learning rate dynamically during training. Warm-up strategies, where the learning rate gradually increases at the start of training, can also mitigate in itial instability and improve overall training robustness.\n/SM590000The concept of \naccumulation steps  addresses memory constraints by enabling gradient \naccumulation across several mini-batches before updating the model\u2019s parameters. T", "metadata": {"source": "sg248574.pdf", "chunk_index": 163, "total_chunks": 313}}
{"text": "nabling gradient \naccumulation across several mini-batches before updating the model\u2019s parameters. This approach effectively simulates larger batch sizes without exceeding hardware memory limits, which make it valuab le for memory-constrained environments. Accumulation steps \nsmooth gradient updates by averaging across multiple mini-batches, which improve stability at the cost of increased training time . Optimizing this parame ter involves selecting \nan accumulation step size that balances memory efficiency with the effective batch size. Combining this approach with batch size tuning can further optimize resource usage and enhance performance.\n5.2.2  Interdependencies an d holistic tuning strategies\nThese hyperparameters are interdependent be cause changes in one can influence the \nbehavior of others. For example, increasing the number of epochs without modifying the \nlearning rate might lead to overfitting, and combining a high batch size with too few epochs might result in undertrai", "metadata": {"source": "sg248574.pdf", "chunk_index": 164, "total_chunks": 313}}
{"text": "t lead to overfitting, and combining a high batch size with too few epochs might result in undertrained prompts. To navigate these interdependencies, practitioners can employ regularization techniques such as data augmentation to counteract overfitting in high-epoch scenarios. Gradient c lipping can also be used to prev ent instability during training, \nparticularly when high accumulation steps are involved.\nPerformance metrics, which include task-spec ific measures like accuracy or F1-scores, \nshould guide the evaluation of prompt tuning effectiveness. Monitoring loss convergence and gradient stability help ensure that the chosen hy perparameters lead to tangible \nimprovements.\nCarefully calibrating batch size, the number of epochs, the learning rate, and accumulation \nsteps enables precise optimization of prompt tuning, which unlocks the full potential of LLMs for specific tasks. By managing these para meters holistically, practitioners can achieve \nperformance gains while balancing ", "metadata": {"source": "sg248574.pdf", "chunk_index": 165, "total_chunks": 313}}
{"text": "naging these para meters holistically, practitioners can achieve \nperformance gains while balancing computational efficiency and resource constraints.\n\n64 Simplify Your AI Journey: Unleashing the Power of AI with IBM watsonx.ai5.3  Fine-tuning\nFine-tuning within the watsonx.ai ecosys tem represents the next layer of model \nspecialization, where foundation LLMs undergo retraining on domain-specific datasets to enhance accuracy and relevance for specific applications. Fine-tuning goes beyond prompt adjustments by modifying the model\u2019s weights to encode new knowledge or adapt to complex industry-specific language structures, terminologies, and operational protocols. This process is beneficial for industries that require high precision in terminology and context, such as \nhealthcare, finance, and legal services. Fi ne-tuning within the watsonx.ai ecosystem \nexemplifies a sophisticated approach to model specialization, which enables foundation LLMs \nto adapt to domain-specific needs through", "metadata": {"source": "sg248574.pdf", "chunk_index": 166, "total_chunks": 313}}
{"text": "ch to model specialization, which enables foundation LLMs \nto adapt to domain-specific needs through retr aining. Unlike prompt tuning, which focuses on \nlightweight modifications to steer model behavior, fine-tuning directly alters the model\u2019s weights to encode new knowledge or align with complex industry-specific language structures and terminologies.\n5.3.1  Challenges with fine-tuning\nTo fully appreciate the significan ce of watsonx.ai capabilities, it  is essential to understand the \ninherent complexity of fine-tuning in general. At its core, fine-tuning involves retraining a model\u2019s internal weights on care fully curated datasets to refine its understanding of specific \nterminologies, language patterns, or operational protocols. This process differs from lightweight techniques like prompt tuning, wh ich adjusts model behavior externally without \naltering its core structure. Fine-tuning, by contrast, modifies the model itself, embedding new knowledge directly in to its architecture", "metadata": {"source": "sg248574.pdf", "chunk_index": 167, "total_chunks": 313}}
{"text": "ing, by contrast, modifies the model itself, embedding new knowledge directly in to its architecture. \nWhile this approach enables unparalleled precis ion and customization, it introduces many \nchallenges. Here are some common challenges with fine-tuning:\n/SM590000Data management: One of the primary difficulties with fine-tuning. Fine-tuning demands \ndatasets that are relevant and meticulously prepared, which includes ensuring that the data is formatted correctly, free from bias, and representative of the target domain. Even determining the appropriate size of the dataset requires careful consideration because too little data risks underfitting, and too much can lead to overfitting or unnecessary computational burdens. For example, in watsonx.ai, datasets are limited to 200 MB for JSON or JSONL files, or up to 10,000 examples when sourced from connected data stores. These constraints are carefully balanced to optimize efficiency without sacrificing \nperformance, but managing these para", "metadata": {"source": "sg248574.pdf", "chunk_index": 168, "total_chunks": 313}}
{"text": " carefully balanced to optimize efficiency without sacrificing \nperformance, but managing these parameters manually would be daunting for most users.\n/SM590000Precise calibration of numerous hyperparameters: These hyperparameters include the \nlearning rate, batch size, number of training epochs, and strategies for regularization, among others. Each of these parameters is in terdependent, which means that altering one \ncan have cascading effects on others. Achieving the optimal configuration often involves extensive trial-and-error or the usage of advanced hyperparameter optimization techniques like Bayesian search . This complexity is compo unded when working with large \nmodels, which can have billions of parameters, which requir e significant computational \nresources and expertise to manage effectively.\n\nChapter 5. Advanced cap abilities of watsonx.ai 65/SM590000Computationally demanding workloads requiring a high-performance architecture: Large \nmodels can have billions of  parameter", "metadata": {"source": "sg248574.pdf", "chunk_index": 169, "total_chunks": 313}}
{"text": "g workloads requiring a high-performance architecture: Large \nmodels can have billions of  parameters, which require a significant amount of \ncomputational resources. Even with the right data and parameters in place, fine-tuning remains computationally demanding. Training these large LLMs requires access to high-performance hardware, such as multi-GPU, along with robust memory and storage capabilities. For organizations without dedicated AI infrastructure, thes e requirements are \noften prohibitive.\n/SM590000Ensuring stability during the tr aining process: Large-scale op timization algorithms are \nprone to issues like exploding or vanishing gradients, so achieving convergence without diverging from the optimal solution requires careful tuning and monitoring.\n5.3.2  How watsonx.ai addr esses fine-tuning challenges\nBy automating the complexities of fine-tuning, watsonx.ai transforms what was once a \nlabor-intensive and technically demanding process into an accessible, streamlined experie", "metadata": {"source": "sg248574.pdf", "chunk_index": 170, "total_chunks": 313}}
{"text": "as once a \nlabor-intensive and technically demanding process into an accessible, streamlined experience. This approach lowers the barrier to entry for organizations looking to adopt AI and enables experienced practitioners to focus on higher-level strategic goals rather than \ngetting bogged down in technical minutiae. With its combination of cutting-edge technologies, managed infrastructure, and user-centric design, watsonx.ai empowers businesses to harness the full potential of fine-tuning, which unlocks new levels of precision, efficiency, and innovation in AI-driven solutions. \nwatsonx.ai provides the following features:\n/SM590000Hardware and resource allocation automation: The platform\u2019s automation begins with its \nability to manage hardware and resource allocation seamle ssly. Users do not need to \nworry about provisioning servers, config uring GPUs, or scaling their setups to \naccommodate large datasets or models. Instead, watsonx.ai handles these tasks behind the scenes, helping", "metadata": {"source": "sg248574.pdf", "chunk_index": 171, "total_chunks": 313}}
{"text": "mmodate large datasets or models. Instead, watsonx.ai handles these tasks behind the scenes, helping ensure that every fine-tuning operation runs on optimized configurations. \n/SM590000Supervised Fine-Tuning Trainer (SFTTrainer): At the heart of watsonx.ai fine-tuning \ncapabilities is the SFTTr ainer, which is a powerful tool that is developed in collaboration \nwith Hugging Face. This framework simplifies the optimization of model weights by automating key aspects of the training process, which includes the application of advanced learning rate schedules and warm-u p strategies. These techniques are crucial \nfor maintaining stab ility during training, particularl y when dealing with complex or \nhigh-dimensional data. By leveraging SFTTrainer, watsonx.ai helps ensure that models converge rapidly and reliably without the need for extensive manual intervention. \n/SM590000Low-rank adaptation (LoRA) and quantized low-rank adaptation (QLoRA): In addition to \nSFTTrainer, watsonx.ai incorporat", "metadata": {"source": "sg248574.pdf", "chunk_index": 172, "total_chunks": 313}}
{"text": " (LoRA) and quantized low-rank adaptation (QLoRA): In addition to \nSFTTrainer, watsonx.ai incorporates cutting-edge techniques like LoRA and QLoRA. These methods represent a paradigm shift in fine-tuning efficiency. Rather than retraining all of a model\u2019s parameters, LoRA focuses on fine-tuning small modula r blocks of weights \nwhile freezing most the model. This approach reduces the computational and memory requirements of the process, which makes fine-tuning accessible even on resource-constrained hardware. QLoRA goes a step further by lowering the precision of certain parameters during training, which further optimizes performance without compromising accuracy. These innovations enable watsonx.ai to deliver results faster and with fewer resources than traditional approaches. \n/SM590000Tuning Studio integration: Another key advantage of watsonx.ai is its integration with the \nTuning Studio, which provides access to a library of pre-configured model templates. These templates enable u", "metadata": {"source": "sg248574.pdf", "chunk_index": 173, "total_chunks": 313}}
{"text": "udio, which provides access to a library of pre-configured model templates. These templates enable users to build on pre-existing architectures that are optimized for specific tasks or domains. This approach eliminates the need to design custom models from scratch, which reduces the time and expertise that are required to initiate fine-tuning projects. \n\n66 Simplify Your AI Journey: Unleashing the Power of AI with IBM watsonx.ai/SM590000Custom FMs: For organizations with unique requirements, watsonx.ai also supports the \nimport of custom FMs if they have fewer th an 20 billion parameters . This approach opens \nthe possibility of automatically fine-tuning tons of available models on Hugging Face and \non watsonx.ai. This flexibility helps ensure that the pla tform can accommodate a wide \nrange of use cases and industries. \n/SM590000Monitoring and optimization: Throughout the fine-tuning process, watsonx.ai provides \nrobust tools for monitoring and optimization.  Real-time performance tra", "metadata": {"source": "sg248574.pdf", "chunk_index": 174, "total_chunks": 313}}
{"text": "ocess, watsonx.ai provides \nrobust tools for monitoring and optimization.  Real-time performance tracking enables \nusers to assess key metrics, such as validat ion loss and gradient stability, which helps \nensure that the model improves as expect ed. The platform also employs advanced \nearly-stopping mechanisms to prevent overfitting  by halting training when further iterations \nwould yield diminishing returns. These features  enhance the efficiency of the process and \nimprove the quality of the final model. \nFigure 5-5 shows the watsonx.ai fine-tuning process.\nFigure 5-5   Prompt fine-t uning pipeline process overview\nIn conclusion, watsonx.ai revolutionizes the traditionally complex and resource-intensive \nprocess of fine-tuning LLMs by introducing a seamlessly automated, highly efficient, and \nscalable solution. By leveraging advanced tool s like the SFTTrainer, innovative techniques \nsuch as LoRA and QLoRA, and a robust Tuning Studio, watsonx.ai enables businesses to achieve unpara", "metadata": {"source": "sg248574.pdf", "chunk_index": 175, "total_chunks": 313}}
{"text": "\nsuch as LoRA and QLoRA, and a robust Tuning Studio, watsonx.ai enables businesses to achieve unparalleled levels of cu stomization and precision in thei r AI solutions. Its ability to \nmanage every aspect of the fine-tuning lifecycle (from data preparation and parameter optimization to resource allocation and model monitoring) removes significant technical barriers, which democratize access to AI specialization for organizations of all sizes. \nThis comprehensive platform empowers businesses to tailor FMs to their unique \ndomain-specific needs, whether in healthcare, fi nance, legal services, or other fields that \nrequire high precision. By doing so, the platform enhances the relevance and accuracy of AI applications and accelerates time-to-value while reducing the costs that are associated with traditional fine-tuning methods. watsonx.ai stands as a testament to IBM's commitment to innovation and accessibility by providing a robu st foundation for bu sinesses to unlock the \ntransforma", "metadata": {"source": "sg248574.pdf", "chunk_index": 176, "total_chunks": 313}}
{"text": "vation and accessibility by providing a robu st foundation for bu sinesses to unlock the \ntransformative potential of AI with confidence and ease.\n\n\nChapter 5. Advanced cap abilities of watsonx.ai 675.4  InstructLab\nInstructLab represents a groundbreaking shift in the way LLMs are fine-tuned by making the \nprocess more accessible, flexible, and efficient. At its core, InstructLab leverages a unique combination of community-driven input, synthetic data generation (SDG), and iterative training methodologies to refine LLMs in a way that dramatically lowers the barriers to entry for fine-tuning ta sks (see Figure 5-6). This process ma kes it simpler for developers and \nsubject matter experts (SMEs) to improve model outputs. It also accelerates the fine-tuning cycle and reduces the computational overhead that is traditionally associated with customizing models.\nFigure 5-6   The InstructLab large language  model development kit functions overview\nThe InstructLab approach to fine-tuning is he", "metadata": {"source": "sg248574.pdf", "chunk_index": 177, "total_chunks": 313}}
{"text": "rge language  model development kit functions overview\nThe InstructLab approach to fine-tuning is heavily grounded in the concept of \ntaxonomy-driven knowledge curation. Taxonomies , in this context, are structured frameworks \nof concepts and relationships that organize information into logical categories and subcategories. These taxonomies are built collaboratively by SMEs, and they serve as the foundation for the knowledge that is used to tune the model. For example, if a business wanted to fine-tune an LLM on customer support for a specific industry, an SME in that industry would work with a taxonomy that represents common questions, issues, and \nterminology that are relevant to the field. By formalizing domain knowledge in a taxonomy, InstructLab helps ensure that the model fine-tuning process is precise, efficient, and contextually relevant.\nWhat makes this approach powerful is that the knowledge that is curated in these taxonomies \nis used to generate synthetic data. Unlike tradi", "metadata": {"source": "sg248574.pdf", "chunk_index": 178, "total_chunks": 313}}
{"text": " the knowledge that is curated in these taxonomies \nis used to generate synthetic data. Unlike traditio nal fine-tuning methods that rely heavily on \nvast amounts of manually labeled training data, InstructLab uses SDG to produce the training examples that are needed to adjust model behavior. This task is accomplished by feeding the curated taxonomies into  the system (composed of Knowl edge and Skills taxo nomies), which \ncontains question-answer pairs and other types of data. \n\n\n68 Simplify Your AI Journey: Unleashing the Power of AI with IBM watsonx.aiAn example of Skills taxonomies is provided in  Figure 5-7, where the Skill that is defined here \nis made to make a model learn to better interpret particular tables.\nFigure 5-7   Skill Taxonomy example\nThis data generation process is not random: It follows predefined patterns based on the taxonomy\u2019s structure, which helps ensure that the synthetic examples are highly relevant to \nthe domain. This synthetic data serves as a proxy for r", "metadata": {"source": "sg248574.pdf", "chunk_index": 179, "total_chunks": 313}}
{"text": "e synthetic examples are highly relevant to \nthe domain. This synthetic data serves as a proxy for real-world data, which enables InstructLab to adapt to niche topics or specialized knowledge areas without requiring the collection of large-scale, expensive datasets. The synthetic data can also be customized and controlled by the SME, which means that they can influence the generation process to help ensure that the model is trained  on the most important or crit ical examples. The ability to \ngenerate synthetic training data directly fr om taxonomies is what makes InstructLab so \nefficient: It drastically reduces the need for large-scale manual data curation and opens. \nFurthermore, it solves the ever-existing problem of not having enough data for fine-tuning a model that is tailored for a particular business need in the generative AI (gen AI) era. \nThe InstructLab approach is built around iterative feedback and instruction training, which are \ntwo techniques that further streamline th", "metadata": {"source": "sg248574.pdf", "chunk_index": 180, "total_chunks": 313}}
{"text": "nd iterative feedback and instruction training, which are \ntwo techniques that further streamline the fine-tuning process. Instruction training involves providing LLMs with explicit in structions (similar to how humans learn new tasks) about how \nto generate responses based on the synthetic data. This process is highly flexible because the SMEs can continually tweak the instructions and the knowledge base based on the evolving needs of the model and the domain it is being trained on. This process uses a 2-phase approach with a replay that serves the pur pose of ensuring high diversity and quality \nin the synthetically generated in struction-tuning data set while ensuring training stability. It \nalso prevents catastrophic forgetting, which is a common situation that happens in the FM fine-tuning process when it is not well controlled. \nOnce the initial synthetic data is generated from the curated taxonomy, the InstructLab \nsystem trains the model by providing it with a series of questio", "metadata": {"source": "sg248574.pdf", "chunk_index": 181, "total_chunks": 313}}
{"text": " curated taxonomy, the InstructLab \nsystem trains the model by providing it with a series of questions and answers that align with the knowledge base. The process is iterative, which means that the model does not undergo a single round of training and then stop. Instead, as new feedback is gathered from the model\u2019s performance, the data is refined, and further training is conducted. This iterative feedback loop is crucial in guiding the model toward better understanding, more accurate outputs, and more aligned responses to specific use cases.\n\n\nChapter 5. Advanced cap abilities of watsonx.ai 69The power of iterative feedback lies in its ability to refine th e model's responses over time, \nwhich enhances its accuracy and applicability to real-world prob lems. SMEs can continuously \nassess the model\u2019s performance in relation to specific tasks or topics, and helps ensure that the model becomes progressively better at understanding the subtleties of the domain and generating more precise, ", "metadata": {"source": "sg248574.pdf", "chunk_index": 182, "total_chunks": 313}}
{"text": "mes progressively better at understanding the subtleties of the domain and generating more precise, cont extually relevant responses.\nAnother key feature of InstructLab is its model-neutral and open-source nature. Unlike \nproprietary fine-tuning solutions that are often tightly coupled with specific models or platforms, InstructLab enables users to contribute to the fine-tuning of various LLMs regardless of their underlying architecture. InstructLab is built on the premise that fine-tuning should be an open, community-driven process. It supports a wide range of open-source LLMs from repositories like Hugging Face, which enables users to choose the model that best suits their needs, and even enabling them to experiment with models from different frameworks. The open-source nature of InstructLab also means that users have full transparency into the fine-tuning process and the abilit y to modify it as needed. An yone from hobbyists to industry \nexperts can contribute to improving the syst", "metadata": {"source": "sg248574.pdf", "chunk_index": 183, "total_chunks": 313}}
{"text": "odify it as needed. An yone from hobbyists to industry \nexperts can contribute to improving the system, whether by adding new taxonomies, adjusting training data, or developing new  techniques for SDG. This approach makes \nInstructLab a true community-driven initiative that is always evolving based on the needs and contributions of its users.\nFigure 5-8 shows a community-driven InstructLab fine-tuning process example.\nFigure 5-8   Community-driven Inst ructLab fine-tuning process example\nUsing InstructLab involves several key steps, each of which is designed to make the process \nas efficient and accessible as possible:\n1. Users download a base model from a supported repository, such as Hugging Face, and \ninitialize the InstructLab co mmand-line interface (CLI). \n2. Once the environment is set up, the user creates a knowledge base, which is stored in a \nstructured directory that follows the taxonomy format. This knowledge base is populated with question-answer pairs, references to exter", "metadata": {"source": "sg248574.pdf", "chunk_index": 184, "total_chunks": 313}}
{"text": "he taxonomy format. This knowledge base is populated with question-answer pairs, references to external documents (for example, PDFs or markdown files), and metadata to describe the knowledge, such as the domain and relevant attributes. \n3. Now, you generate synthetic data based on the knowledge base. This synthetic data is \nused to train the model, with the InstructLab system automatically generating examples that adhere to the structure of the taxonomy. The SDG process is designed to produce high-quality training samples by following the patterns and relationships that are defined in the taxonomy, which reduces the time and cost of manual data creation and helps ensure that the model receives high-quality, domain-specific examples. \n\n\n70 Simplify Your AI Journey: Unleashing the Power of AI with IBM watsonx.ai4. Once the synthetic data is generated, the model is trained by using the InstructLab training \nframework. This training can be done on a local machine or in a cloud environment", "metadata": {"source": "sg248574.pdf", "chunk_index": 185, "total_chunks": 313}}
{"text": "tructLab training \nframework. This training can be done on a local machine or in a cloud environment, with the flexibility to use GPUs to accelerate the process. \n5. After training is complete, the model undergoes a testing phase to ensure that it performs \nas expected. InstructLab enables users to run tests that evaluate how well the model answers questions and generates responses, which help identify areas for further improvement. \n6. The final stage is deploying the trained model, which can be done through the InstructLab \nserving tools. Once the model is deployed, users can interact with it through the CLI or through an application interface, which e nables them to assess  how well it handles \nreal-world queries and performs in live environments.\nFigure 5-9 shows a high-level view of the InstructLab pipeline.\nFigure 5-9   High-level overview of the InstructLab pipeline\n5.4.1  Advantages of InstructLab\nThe InstructLab methodology provides numerous advantages over traditional fine-tu", "metadata": {"source": "sg248574.pdf", "chunk_index": 186, "total_chunks": 313}}
{"text": "ges of InstructLab\nThe InstructLab methodology provides numerous advantages over traditional fine-tuning \ntechniques:\n/SM590000Synthetic data generation (SDG):  Facing and solving an older pr oblem of data availability, \nInstructLab offers within its automatic capabilities a process to enhance, in cardinality and \nvariability, a training dataset fo r LLM fine-tuning by using SDG, which is integr ated into its \ncore. \n/SM590000Cost and complexity reduction: One of the most significant benefits of InstructLab is its \nability to drastically reduce the cost and comp lexity of fine-tuning. By relying on SDG \nrather than manually labeled datasets, InstructLab eliminates one of the most time-consuming and expensive aspects of model customization. \n/SM590000Agile development: The iterative feedback loops and the ability to work collaboratively with \nSMEs enable the fine-tuning process to be far more agile, with models refined and improved continuously based on real-time insights. \n\n\nChapter 5.", "metadata": {"source": "sg248574.pdf", "chunk_index": 187, "total_chunks": 313}}
{"text": "more agile, with models refined and improved continuously based on real-time insights. \n\n\nChapter 5. Advanced cap abilities of watsonx.ai 71/SM590000Flexible model selection and customization: InstructLab is model-neutral, which means \nthat users can select and fine-tune various LLMs based on their specific needs. Whether it is a general-purpose model like Granite or a more specialized compatible model that is found on Hugging Face for a particular domain, InstructLab enables users to adapt and improve the model that best fits their use case. \n/SM590000Broader audience participation: The open-sourc e nature and simplicity of the workflow in \nInstructLab make it possible for people without deep machine learning (ML) expertise to participate in model development and fine-tuning. This approach is a significant step toward democratizing AI and ensuring that more organizations, regardless of size or expertise, can harness the power of  LLMs for their specific needs.\nThe InstructLab innovati", "metadata": {"source": "sg248574.pdf", "chunk_index": 188, "total_chunks": 313}}
{"text": "size or expertise, can harness the power of  LLMs for their specific needs.\nThe InstructLab innovative approach to mo del fine-tuning (leveraging taxonomy-driven \nknowledge curation, SDG, and iterative training) marks a transformative shift in how LLMs can be customized and applied across a wide ra nge of domains. By reducing the barriers to \nentry, lowering computational costs, and enabling highly specialized, domain-specific training, InstructLab is positioning itself as a key enabler of accessible, efficient, and scalable AI development. This open-source, community-driv en initiative is paving the way for a new \ngeneration of AI practitioners to fine-tune and enhance LLMs without requiring extensive \ntechnical expertise, which expands the scope and impact of AI in real-world applications.\n5.4.2  How to use InstructLab\nInstructLab is a model-neutral, open-source AI proj ect that facilitates contributions to LLMs. It \nis a new community-based approach to build truly open-source LLMs. ", "metadata": {"source": "sg248574.pdf", "chunk_index": 189, "total_chunks": 313}}
{"text": "tates contributions to LLMs. It \nis a new community-based approach to build truly open-source LLMs. InstructLab uses a synthetic-data-based alignment tuning method to train LLMs. The InstructLab tuning method is driven by manually created taxonomies. In structLab provides a process for optimizing and \ntuning LLMs by collecting knowledge and skills as par t of a taxonomy tree.\nTo start the InstructLab process, ilab must be installed. You can download it from its official \nrepository .\nilab is a CLI tool that you can use to perform the following actions:\n/SM590000Download a pre-trained LLM.\n/SM590000Chat with the LLM.\n/SM590000Add new knowledge and skills to the pre-train ed LLM by adding in formation to the \ncompanion taxonomy repository.\nAfter you add kno wledge and skills to the taxonomy, yo u can perform the following actions:\n/SM590000Use ilab to generate new synthetic training data based on the changes in your local \ntaxonomy repository.\n/SM590000Retrain the LLM with the new traini", "metadata": {"source": "sg248574.pdf", "chunk_index": 190, "total_chunks": 313}}
{"text": "ased on the changes in your local \ntaxonomy repository.\n/SM590000Retrain the LLM with the new training data.\n/SM590000Chat with the retrained LLM to see the results.\n\n72 Simplify Your AI Journey: Unleashing the Power of AI with IBM watsonx.aiFigure 5-10 shows the ilab flow of commands, which show how to start processing data for \nsynthetic data generation and the fine-tuning process.\nFigure 5-10   The ilab flow of commands\nBefore you begin working with ilab, ensure that your system meets the following \nrequirements:\n/SM590000Operating system: Linux (tested on Fedora), or macOS with  Apple M1/M2/M3 chipsets.\n/SM590000Disk space: Minimum of 250 GB. 500 GB is recommended for complete workflows.\n/SM590000Python Version 3.10 or 3.11. At the time of writing, Python 3.12+ is unsupported due to \ndependency constraints.\n/SM590000C++ compiler: Ensure that a modern GCC version or equivale nt is installed.\nIf you use Python environment management tools, ensure that they build libraries that are \ni", "metadata": {"source": "sg248574.pdf", "chunk_index": 191, "total_chunks": 313}}
{"text": "talled.\nIf you use Python environment management tools, ensure that they build libraries that are \nimplemented in C by including flags during Python compilation. For example, when using \npyenv , you use the following string:\nPYTHON_CONFIGURE_OPTS=\"--enable-framework\" pyenv install 3.11.5\n\n\nChapter 5. Advanced cap abilities of watsonx.ai 73To install the required tool s, run the following command:\nsudo dnf install gcc gcc-c++ make git python3.11 python3.11-devel\nilab can be installed with various configurations, depending on your hardware and preferred \naccelerators. Different hardware setups often require specific steps to optimize performance and ensure compatibility with the chosen accelerators, such as  Apple Metal, AMD ROCm, or \nNVIDIA CUDA.\nIf a GPU is available, you can leverage more processing power by using the following \ncommands for initialization:\npython3.11 -m venv --upgrade-deps venv\nsource venv/bin/activatepip cache remove llama_cpp_pythonCMAKE_ARGS=\"-DGGML_CUDA=on -DGGML", "metadata": {"source": "sg248574.pdf", "chunk_index": 192, "total_chunks": 313}}
{"text": "deps venv\nsource venv/bin/activatepip cache remove llama_cpp_pythonCMAKE_ARGS=\"-DGGML_CUDA=on -DGGML_NATIVE=off\" pip install 'instructlab[cuda]'pip install vllm@git+https://github.com/opendatahub-io/vllm@v0.6.2\nAfter you install ilab, proceed with the first initialization by running the following command:\nIlab config init\nDuring initialization, ilab prompts you to perform specif ic tasks that influence how the \nenvironment is configured. By following these prompts, you can tailor ilab to meet your \nneeds by setting up essential components lik e the taxonomy repository, model paths, and \ntraining profiles. For example, selecting a training profile helps ens ure compatibility with your \nhardware, whether it uses CPUs or GPUs, to provide the best performance and resource optimization for your setup:\n1. Clone the taxonomy repository, either interactively or by specifying a path with the \n--taxonomy-path  flag.\n2. Specify the path to your model. By default, it uses a quantized Granite model", "metadata": {"source": "sg248574.pdf", "chunk_index": 193, "total_chunks": 313}}
{"text": "axonomy-path  flag.\n2. Specify the path to your model. By default, it uses a quantized Granite model .\n3. Select a training profile. For systems without dedicated GPUs, choose No Profile (CPU, \nApple Metal, AMD ROCm) .\nAfter initialization, the directories that are shown in Table 5-1 are created.\nTable 5-1   ilab directory overview and details\nDirectory Description\n~/.cache/instructlab/models/ Contains downloaded models.\n~/.local/share/instructlab/datasets/ Stores the dataset outputs that are \ngenerated during workflows.\n~/.local/share/instructlab/taxonomy/ Contains skill and knowledge data from the \ntaxonomy repository.\n~/.local/share/instructlab/checkpoint\ns/Contains model checkpoints from the \ntraining process.\n~/.config/instructlab/config.yaml The configuration file  that is generated \nduring initialization.\n\n74 Simplify Your AI Journey: Unleashing the Power of AI with IBM watsonx.aiAfter you install the InstructLab CLI on your syst em, start by downloading the base model that \nyou", "metadata": {"source": "sg248574.pdf", "chunk_index": 194, "total_chunks": 313}}
{"text": "After you install the InstructLab CLI on your syst em, start by downloading the base model that \nyou want to train. The foundation of using InstructLab effectively is access to its models. The ilab CLI simplifies this process by offering robu st integration with repositories like Hugging \nFace or OCI. It provides authentication mechanisms, such as token-based access for Hugging Face, and features like repository specification and download acceleration. These capabilities help ensure se cure and efficient downlo ads of pre-tr ained models.\nTo quickly get started, download compact pre-trained versions of the following models:\n/SM590000granite-7b-lab-GGUF\n/SM590000merlinite-7b-lab-GGUF\n/SM590000Mistral-7B-Instruct-v0.2-GGUF\nTo initiate the download of a m odel, can run the following command:\nilab model download \u2013repository <MODEL-ID>\nWhen this command runs, the ilab CLI interacts with the designated repositories to fetch the \nselected models. By default, the models are stored locally in t", "metadata": {"source": "sg248574.pdf", "chunk_index": 195, "total_chunks": 313}}
{"text": "esignated repositories to fetch the \nselected models. By default, the models are stored locally in the ~/.cache/instructlab/models/  directory, which helps ensure efficient reuse because the \ndownloaded models do not need to be fetched again for future operations unless explicitly removed or updated.\nYou can download a non-default LLM from Hugging Face. If a Hugging Face token is required, \ncan add it by running ilab model download \u2013repository <MODEL-ID> , but add the token after \nthe argument -hf-token .\nYou can use OCI-compliant repositories. To do so, log in to the registry and use the following \ncommand:\nilab model download -rp docker://<MODEL_ID> -rl latest\nOnce the models are downloaded, they can be served locally for inference. ilab supports \nserving both default and custom models if the system prerequisi tes are met. To serve models \nlocally, ensure that the system has sufficient hardware resources, which include at least 8 GB of RAM and, for GPU-accelerated serving, an  NVIDIA", "metadata": {"source": "sg248574.pdf", "chunk_index": 196, "total_chunks": 313}}
{"text": " hardware resources, which include at least 8 GB of RAM and, for GPU-accelerated serving, an  NVIDIA GPU with CUDA support. If multiple \nilab clients attempt to connect to the same server, the first client connects successfully, and \nthe others create temporary servers, which require more resources. To prevent conflicts, manage the connections.\nTo serve the model, run the following command, which provides a URL for API interaction:\nIlab model serve \u2013model-path <MODEL_PATH>\nIt is possible to interact with a served model directly within ilab by using the following \ncommand, with optional personalization of inference parameters, such as temperature:\nIlab model chat \u2013model <MODEL_PATH> [-temperature <VALUE>]\nNow, you can start personalizing the mo del by adding new skills and knowledge.\nTo train an open source  model with InstructLa b, create knowledge and skills in the taxonomy \ndirectory. When you initialized the ilab CLI, it automatically cloned the InstructLab taxonomy \nrepository , wh", "metadata": {"source": "sg248574.pdf", "chunk_index": 197, "total_chunks": 313}}
{"text": "When you initialized the ilab CLI, it automatically cloned the InstructLab taxonomy \nrepository , which is the source of truth for your model training.\nIn the context of skill contributions, the requi red content is smaller in volume compared to \nknowledge contributions. A complete skill addition to the taxonomy tree can be represented by a few lines in a qna.yaml  file (short for \u201cquestions and answers\u201d) and an attribution.txt  \nfile to cite sources. \n\nChapter 5. Advanced cap abilities of watsonx.ai 75To make a valid skills contribution,  the pull request must include a qna.yaml  file with key-value \nentries that contain at least five question-and-answer pairs and an attribution.txt  file that \nlists the sources that are used. The taxonomy structure serves multiple purposes: selecting the relevant subset for data generation, ensu ring interpretability for contributors and \nmaintainers, and forming part of the prompt for the LLM when generating synthetic samples.\nEach qna.yaml  file mu", "metadata": {"source": "sg248574.pdf", "chunk_index": 198, "total_chunks": 313}}
{"text": "and forming part of the prompt for the LLM when generating synthetic samples.\nEach qna.yaml  file must adhere to a standa rd structure with specific keys:\n/SM590000version : Must be set to 2 (required).\n/SM590000task_description : A description of the skill (required).\n/SM590000created_by : The GitHub username of the contributor (required).\n/SM590000seed_examples : A collection of key-value entries with at least five examples (required for \nnew files, although older files may contain fewer examples).\n/SM590000context : Provides relevant information for gr ounded skills, which guide the model\u2019s \nprocessing (not used  for ungrounded skills).\n/SM590000question : The model's input query (required).\n/SM590000answer : The expected response (required).\nThe taxonomy tree also categorizes skills as  either grounded (req uiring context) or \nungrounded (not requ iring context). For example,  a grounded skill might be \ngrounded/linguistics/grammar, wh ile an ungrounded skill might be \nlinguistics/", "metadata": {"source": "sg248574.pdf", "chunk_index": 199, "total_chunks": 313}}
{"text": "nded skill might be \ngrounded/linguistics/grammar, wh ile an ungrounded skill might be \nlinguistics/writing/poetry/haiku. The qna.yaml  file is always in the fi nal node of the taxonomy \npath. Importantly, there is a limit on the content length in question-answer pairs to ensure model compatibility; co ntributions should not exceed appr oximately 2,300 words for these \npairs. By adhering to these gui delines, contributors can maintain  consistency and utility within \nthe skill taxonomy framework\n.\nTo make the qna.yaml  files faster for humans to read, it is best practice to specify version  \nfirst, which is followed by task_description , then created_by , and finally seed_examples . In \nseed_examples , it is a best practice to specify context  first (if applicable), followed by question  \nand answer . \nExample 5-1 shows an example of a qna.yaml file.\nExample 5-1   A qna.yaml file\nversion: 2\ntask_description: <string>created_by: <string>seed_examples:  - question: <string>    answer: | ", "metadata": {"source": "sg248574.pdf", "chunk_index": 200, "total_chunks": 313}}
{"text": ": 2\ntask_description: <string>created_by: <string>seed_examples:  - question: <string>    answer: |      <multi-line string>  - context: |      <multi-line string>    question: <string>    answer: |      <multi-line string>  ...\nCreate an attribution.txt  file that includes the sources of your information, which can be \nself-authored sources.\n\n76 Simplify Your AI Journey: Unleashing the Power of AI with IBM watsonx.aiKnowledge contributions differ from skills by focusing on answering fa ctual, data-driven, or \nreference-based questions, which are often su pported by documents like textbooks, technical \nmanuals, encyclopedias, journals, or maga zines. Although knowle dge and skills share \nsimilarities in their taxonomy structures, kno wledge nodes include additional elements to \naccommodate their document-based nature.\nFor contributors that use InstructLab 0.21.0 or later, knowledge contributions can include PDF \nfiles as valid document types, but earlier versions accept only markdown f", "metadata": {"source": "sg248574.pdf", "chunk_index": 201, "total_chunks": 313}}
{"text": "ibutions can include PDF \nfiles as valid document types, but earlier versions accept only markdown formats. Each knowledge node in the taxonomy tree contains a qna.yaml  file that is simila r in structure to the \none that is used for skills, but with additional fields to support knowledge-specific attributes. Notably, all knowledge submissions must be in a Git repository, such as one hosted on GitHub, and the qna.yaml  file must reference this repository:\n/SM590000Submit the most current version of the document.\n/SM590000Contributions must be text-based. Images are ignored.\n/SM590000Avoid using tables in your markdown freeform contributions.\nThe qna.yaml  file for knowledge contributions must follow a specific format and include the \nfollowing fields:\n/SM590000version : The version of the qna.yaml  file format, which is set to 3.\n/SM590000created_by : The GitHub username of the contributor.\n/SM590000domain : The category of the knowledge.\n/SM590000seed_examples : A collection of key-va", "metadata": {"source": "sg248574.pdf", "chunk_index": 202, "total_chunks": 313}}
{"text": "or.\n/SM590000domain : The category of the knowledge.\n/SM590000seed_examples : A collection of key-value entries.\n/SM590000context : A chunk of information from the knowledge document. Each qna.yaml  file must \ninclude at least five context blocks, with a maximum of 500 words per block.\n/SM590000questions_and_answers : Holds the questions and answers based on the context. Each \ncontext block requires a minimum of three question-and-answer pairs, each with a maximum word count of 250 words.\n\u2013question : A question for the model.\n\u2013answer : The corresponding answer.\n/SM590000document_outline : An overview of the document being submitted.\n/SM590000document : The source document for the knowledge contribution.\n/SM590000repo: The URL of the repository that contains the knowledge files.\n/SM590000commit : The SHA of the commit in the repository for the knowledge files.\n/SM590000patterns : A list of glob patterns specifying the files in the repository. Patterns starting with \n*, such as *.md, mus", "metadata": {"source": "sg248574.pdf", "chunk_index": 203, "total_chunks": 313}}
{"text": "f glob patterns specifying the files in the repository. Patterns starting with \n*, such as *.md, must be quoted (\" *.md\") to comply with YAML rules.\nBy adhering to these guidelines, knowledge c ontributions maintain a structured, accessible \nformat that aligns with the taxonomy framework and supports efficient integration into the system.\n\nChapter 5. Advanced cap abilities of watsonx.ai 77When working with YAML files (f or both skills and knowledge), it is crucial to adhere to \nspecific formatting rules to help ensure correctness and avoid parser errors. Indentation and spacing play a role, and YAML requires \ntwo spaces for each level of indentation ( tabs must not \nbe used  under any circumstances). Also, avoid traili ng spaces at the end of lines because they \ncan lead to issues during processing. For entries in seed_examples , each example begins with \na - placed before the first field, such as question  or context . Subsequent keys within the \nsame example should not include the -.", "metadata": {"source": "sg248574.pdf", "chunk_index": 204, "total_chunks": 313}}
{"text": "d, such as question  or context . Subsequent keys within the \nsame example should not include the -. Pay attention to sp ecial characters like \" and ', which \nmust be escaped by using a backslash ( \\). To simplify handling these characters, YAML \nenables the use of the | character at the start of a value, which disables special character \ninterpretation and supports multi-line strings. For example, lines that start with | are followed \nby an indented block that contains the string 's content. To avoid unexpected YAML parser \nbehavior, it is a best practice to quote all values  by using double quotation marks ( \"). This \napproach prevents values such as Yes or No from being interpreted as Boolean types ( True or \nFalse ). For more information about managing multi-line strings and YAML nuances, see the \nyaml-multiline.info  file.\nNow, after creating a YAML file for skills and knowledge, as shown in Figure 5-7 on page 68, \nyou can validate your new data. Use the ilab taxonomy diff  comman", "metadata": {"source": "sg248574.pdf", "chunk_index": 205, "total_chunks": 313}}
{"text": " shown in Figure 5-7 on page 68, \nyou can validate your new data. Use the ilab taxonomy diff  command to help ensure that \nilab is registering your new knowledge or skills  and that your cont ributions are properly \nformatted. This command displays any new or modified YAML files within your taxonomy tree. You can also validate your entire taxonomy by performing a diff against an empty base by using the --taxonomy-base=empty  argument.\nAfter validation, it is possible to start the Synthetic Data Generation (SDG) pipeline. To \ngenerate a synthetic da taset based on newly a dded knowledge or skill sets in the taxonomy \nrepository, run the ilab data generate  command. Before proceeding, ensure the existing \nmodel to which you are adding skills or knowle dge is still running. Al ternatively, you can \ninitiate the serv er by using the ilab data generate  command by specifyi ng a fully qualified \nmodel path with the --mode l flag. At the time of writing, the full CLI pipelin e supports only \n", "metadata": {"source": "sg248574.pdf", "chunk_index": 206, "total_chunks": 313}}
{"text": "d \nmodel path with the --mode l flag. At the time of writing, the full CLI pipelin e supports only \nMixtral and Mistral Instruct Family models as the teacher model. For the simple pipeline, Merlinite 7b Lab is the only supported teacher model due to the specific model prompt templates that it uses. There is  a plan to expand compatibility in  the future, and on watsonx.ai \n(as described in Chapter 6 , \u201cArtificial intelligence  agents\u201d on page 87).\nTo start generation, run the following command:\nilab data generate [--pipeline full --gpus <NUM_OF_GPUS> --model <MODEL_PATH>\nOptionally, you can start SDG by using GPUs wh en they are available. You can specify the \nteacher model that is used (the default one for the ilab CLI is Merlinte-7B).\nAfter generation finished, the synthetic dataset consists of two files in the \n~/.local/share/instructlab/datasets  directory: \n/SM590000skills_train_msgs_*.jsonl\n/SM590000knowledge_train_msgs_*.jsonl\nYou can run the generate step against a different mo", "metadata": {"source": "sg248574.pdf", "chunk_index": 207, "total_chunks": 313}}
{"text": "s_*.jsonl\n/SM590000knowledge_train_msgs_*.jsonl\nYou can run the generate step against a different model through a compatible API, such as \nthe one that is created by the ilab model serve or any remote or locally hosted LLM (through \nollama, LM Studio, or others). Run the following command:\nilab data generate --endpoint-url http://localhost:8000/v1\nNow that the curated dataset for a fine-tuning is ready, the fine-tuning process can be started.\n\n78 Simplify Your AI Journey: Unleashing the Power of AI with IBM watsonx.aiThe InstructLab model train has three pipelines: simple , full, and accelerated . The default \nis full.\n/SM590000simple  uses an SFTTrainer on Linux and MLX on MacOS. This type of training takes \nroughly an hour and produces the lowest fidelity model but should indicate whether your data is being picked up by the training process.\n/SM590000full uses a custom training loop and data proc essing functions for the Granite family of \nmodels. This loop is optimized for CPU and M", "metadata": {"source": "sg248574.pdf", "chunk_index": 208, "total_chunks": 313}}
{"text": "d data proc essing functions for the Granite family of \nmodels. This loop is optimized for CPU and MPS function. Use --pipeline=full  with \n--device=cpu  (Linux) or - -device=mps  (MacOS). You can also use --device=cpu  on a \nMacOS machine. However, MPS is optimized for better performance on these systems.\n/SM590000accelerated  uses the instructlab-training  library, which suppor ts GPU-accelerated \nand distributed training. The full loop and data processing functions are either pulled directly from or based on of the work in this library.\nTo limit training time, you can adjust the num_epoch  parameter in the config.yaml  file. The \nmaximum number of epochs for running the InstructLab end-to-end workkflow is 10.\nThe following command shows how to start the automatic fine-tuning process with the \npreviously generated dataset. Furthermore, it can specify more than the pipeline, such as the \ndevice that you want the model to be trained on (CPU, MPS, or GPU).\nIlab model train [--pipeline <", "metadata": {"source": "sg248574.pdf", "chunk_index": 209, "total_chunks": 313}}
{"text": " \ndevice that you want the model to be trained on (CPU, MPS, or GPU).\nIlab model train [--pipeline <PIPE_ID> --device <DEVICE_ID> --data-path \n<DATA_PATH>]\nThis training step can potentially take from several minutes to several hours to complete, \nwhich depends on the available computing resources.\nAfter the fine-tuning pipeline completes, it is possible to verify the quality of the new model \nand whether the genera ted dataset with the defined skills and k nowledge produced good \nresults. To thoroughly test and evaluate a newly trained model by using InstructLab, first run a series of commands that are designed to assess the performance and accuracy of the model after training. The testing process involves using the ilab model test  command to obtain \noutput from the model before and after the traini ng process. With this output, you can see how \nwell the model performs based on its previous state and after it has undergone the enhancements from the training process. The results from ", "metadata": {"source": "sg248574.pdf", "chunk_index": 210, "total_chunks": 313}}
{"text": "vious state and after it has undergone the enhancements from the training process. The results from this test show the effectiveness of your training and provide insight into areas where further improvement might be needed.\nWhen the model is tested, you can use the ilab model evaluate  command to run the model \nthrough a set of predefined benchmarks to evaluate its performance across various categories. At the time of writing, there are four primary benchmarks that are supported by InstructLab: \n/SM590000Multitask Language Understanding (MMLU)\n/SM590000MMLUBranch\n/SM590000MTBench\n/SM590000MTBenchBranch. \nThese benchmarks assess different aspects of a model's capabilities, su ch as its knowledge \nand skills: \n/SM590000MMLU evaluates the model\u2019s general knowledge on a wide range of topics. \n/SM590000MMLUBranch compares the model\u2019s performance to the performance of a base model to \nidentify improvemen ts in knowledge. \n/SM590000MTBench evaluates how well the model applies its knowledge in", "metadata": {"source": "sg248574.pdf", "chunk_index": 211, "total_chunks": 313}}
{"text": " improvemen ts in knowledge. \n/SM590000MTBench evaluates how well the model applies its knowledge in multi-turn conversations.\n/SM590000MTBenchBranch assesses improvements or r egressions in specific skill areas when \ncompared to a base model. \n\nChapter 5. Advanced cap abilities of watsonx.ai 79For each benchmark, the evaluation generates detailed reports, which show scores and \nidentify areas where the model performs well and areas that need further work. For example, the MMLU report provides a score for various s ubjects, such as abstract algebra, anatomy, \nand business ethics, which indicate how the model performs in each area. A typical output for MMLU looks like a series of subject categories with a score 0.0 - 1.0, with higher scores indicating better performance in the respective topics. \nRunning MMLUBranch involves evaluating your model's contributions compared to a base \nmodel. The evaluation outputs a score for both the base model and the newly trained model, along with a rep", "metadata": {"source": "sg248574.pdf", "chunk_index": 212, "total_chunks": 313}}
{"text": "The evaluation outputs a score for both the base model and the newly trained model, along with a report on the improvements or regressions that are observed. For example, you might see that the model improved in one area, like \u201ctonsils,\u201d from a score of 0.74 to 0.78, which indicates that your  training enhanced the model\u2019s ab ility in that particular knowledge \ndomain. \nMTBench and MTBenchBranch follow a similar structure, but they focus on testing the \nmodel\u2019s skills rather th an just knowledge. MTBench evaluate s the model's ability to perform in \nmulti-turn dialogs, which provide a score for each turn in the conversation, such as turn one and turn two. MTBenchBranch compares your model\u2019s skill performance to  a base model, \nwhich provides a detailed breakdown of areas wh ere your model improved or regressed, and \nhighlighting any skills that sh owed no significan t change. This deta iled feedback helps \npinpoint specific areas where more fine-tuni ng might be necessary to enhance th", "metadata": {"source": "sg248574.pdf", "chunk_index": 213, "total_chunks": 313}}
{"text": "led feedback helps \npinpoint specific areas where more fine-tuni ng might be necessary to enhance the model's \nabilities. For each benchmark, it is important to help ensure that  the model that is evaluated is \nin a supported format, either safetensors or GGUF. Using models directly from Hugging Face without downloading them is not supported.\nAlso, while using models for MMLU and MMLUBranch evaluations, GGUF models are not \nsupported at the time of writing. When running MTBench and MTBenchBranch, it is a best practice to use the \nPrometheus-8x7b-v2.0  model as the judge model, but you can use a \ndifferent judge model. You can download the Prometheus model by running the ilab model \ndownload  command for local use in these evaluations.\nThe entire process of running these evaluations can take from several minutes to several \nhours, which depend on the size of the model and the dataset that is used. Be prepared to allocate enough time for the evaluations to complete, especially wh en work", "metadata": {"source": "sg248574.pdf", "chunk_index": 214, "total_chunks": 313}}
{"text": " is used. Be prepared to allocate enough time for the evaluations to complete, especially wh en working with large \ndatasets or multiple training epochs. The results from these evaluations provide a \ncomprehensive view of the mode l's strengths and weak nesses, which offer valuable insights \nto guide further refinement and optimization of the model.\nAfter the process ends and the results are good enough for the specified use case, a new \nfine-tuned model with new synthetic data in GGUF format is available in the ilab specified \nfolder location in a GGUF format. Apart from the usage on ilab, it is possible to deploy it on \nhyperscalers such as watsonx.ai run time by using the Bring Your Own Model (BYOM) function, which fully enables a true, at-scale, enterprise-level fine-tuning process of FMs.\n5.4.3  InstructLab on watsonx.ai Software-as-a-Service\nAt the time of writing, Inst ructLab has demonstr ated its usability pr imarily through the ilab \nCLI. This method enables users to interact", "metadata": {"source": "sg248574.pdf", "chunk_index": 215, "total_chunks": 313}}
{"text": " demonstr ated its usability pr imarily through the ilab \nCLI. This method enables users to interact with InstructLab features and functions in a straightforward and efficient manner. However, the development team is working on integrating InstructLa b with watsonx.ai. This upcoming integration will enh ance the user \nexperience by providing a dedicated user interf ace (UI). This UI will streamline the entire \nprocess, which will make it mo re accessible and intuitive for users who might not be \ncomfortable with CLI operations. This development is expected to open new possibilities for a \nbroader range of user by facilitating simpler access to powerful InstructLab tools and features.\n\n80 Simplify Your AI Journey: Unleashing the Power of AI with IBM watsonx.aiFigure 5-11 shows the interface for tuning a generative LLM by using InstructLab. This \ninterface is designed to provide users with an intuitive platform for refining language models \nto meet specific needs and requ irements. It al", "metadata": {"source": "sg248574.pdf", "chunk_index": 216, "total_chunks": 313}}
{"text": " an intuitive platform for refining language models \nto meet specific needs and requ irements. It also illustrates the starting point of the overall \nprocess: the addition of  skills and knowledge. \nFigure 5-11   Tuning Studio interface\nUsers begin by selecting the FM , and then proceed to integrat e various skills and knowledge \nareas into the model. The interface guides users through detailed steps, which include specifying configurations. Throughout this process, users can monitor their progress and make necessary adjustments to ensure that the model's performance aligns with outcomes.\nMoreover, InstructLab offers advanced features such as feedback, performance metrics, and \ntroubleshooting tools to enhance the tuning ex perience. This comprehensive approach helps \ncreate an accurate and efficient LLM, with continuous improvement and adaptation to evolving linguistic patterns and user needs.\nFigure 5-12 on page 81 illustrates a detailed tax onomy tree of skill and knowledge files th", "metadata": {"source": "sg248574.pdf", "chunk_index": 217, "total_chunks": 313}}
{"text": " needs.\nFigure 5-12 on page 81 illustrates a detailed tax onomy tree of skill and knowledge files that \nare managed within Tuning Studio on watsonx.ai for InstructLab. The UI shows a comprehensive and organized view of the hier archical structure of  skills and knowledge \nareas. Each node in the taxo nomy tree represents a distinct  category, which facilitates \nnavigation and access to specific training data.\n\n\nChapter 5. Advanced cap abilities of watsonx.ai 81Figure 5-12   Taxonomy tree of skill and knowle dge files that are managed in Tuning Studio on \nwatsonx.ai for InstructLab\nOne of the key functions of this UI is its abilit y to visualize and mainta in version history for \neach training run, which includes the train ed models, the associated skills and knowledge \ntaxonomy, grounding data, and the generated synthetic data. By tracking the evolution of these elements over time, users can effectively monitor the progression and improvements that are made with each iteration. This ve", "metadata": {"source": "sg248574.pdf", "chunk_index": 218, "total_chunks": 313}}
{"text": " can effectively monitor the progression and improvements that are made with each iteration. This version control mechanism is essential for helping ensure the reproducibility and relia bility of model training processe s. Also, it will be possible to \nadd knowledge and ingest multiple data formats, such as PDFs, docx, HTML, MD, and more.\nThe Tuning Studio capability to  handle such a vast array of data types and their versions \nenables meticulous fine-tuning and enhances the overall model development lifecycle. Through this meticulous documentation and ma nagement, users can draw insights from past \ntraining runs, identify best practices, and apply learned lessons to future projects.\n\n\n82 Simplify Your AI Journey: Unleashing the Power of AI with IBM watsonx.aiFigure 5-13 shows the progress map during the tuning phase of InstructLab on watsonx.ai.\nFigure 5-13   Progress map during the tu ning phase of InstructLab on watsonx.ai\nBefore commencing the SDG and fine-tuning process, conduct ", "metadata": {"source": "sg248574.pdf", "chunk_index": 219, "total_chunks": 313}}
{"text": " ning phase of InstructLab on watsonx.ai\nBefore commencing the SDG and fine-tuning process, conduct a peer review of the submitted \nskills and knowledge files. This  review involves project mem bers and SMEs to help ensure \ncomprehensive assessment and validation. If any modifications are identified as necessary during this review phase, new branches can be created within the version control system to incorporate these changes without disrupting the main development line.\nAfter you incorporate the feedback and necessary adjustments, the fine-tuning process \ncommences. This step involves leveraging pre-trained models and adjusting them to specific requirements by training on customized data sets. The goal is to enhance the model's \nperformance in targeted areas to help ensure that it meets the specif ications and accuracy \nlevels.\nOn successful fine-tuning, the newly optimized model can be exported in the GGUF format, \nwhich is a versatile and widely supported format  for deploying quan", "metadata": {"source": "sg248574.pdf", "chunk_index": 220, "total_chunks": 313}}
{"text": "e exported in the GGUF format, \nwhich is a versatile and widely supported format  for deploying quantized FMs. Alternatively, \nthe model can be directly deployed onto the watsonx.ai run time environment. This deployment establishes a seamless large language model operations (LLMOps) pipeline within watsonx.ai for InstructLab, which enables automated monitoring, maintenance, and iterative improvement of the model.\nBy integrating these processes within the watsonx.ai ecosystem, you help ensure continuous \ndelivery and operational efficiency of AI solutions that align with best practices in modern ML workflows.\nThe fine-tuning process that is shown in Fi gure 5-14 on page 83 shows the intricate and \nmethodical approach that is adopted by InstructLab within the watsonx.ai framework. This process is characterized by a 2-phase, fine-tuning methodology that is augmented with a replay buffer, which helps ensure enhanced performance and accuracy of the models.\n\n\nChapter 5. Advanced cap abilitie", "metadata": {"source": "sg248574.pdf", "chunk_index": 221, "total_chunks": 313}}
{"text": "ich helps ensure enhanced performance and accuracy of the models.\n\n\nChapter 5. Advanced cap abilities of watsonx.ai 83Figure 5-14   InstructLab fine-tuning process with  real-time performance on the 2-phase fine-tuning \nprocess with replay buffer\nIn the initial phase, the pre-trained models undergo a rigorous training regimen by using \ntargeted datasets that are pertinent to the specif ic knowledge areas that are identified within \nthe taxonomy tree. This phase focuses on adapting the general-purpose models to the specialized requirements of the InstructLab projects, which hone their performance to meet the specifications. The second pha se uses the skills and continues  catastrophic forgetting by \nusing a dedicated replay buffer while fi ne-tuning the skills in  the second phase. \nThe replay buffer mechanism plays a crucial role in this fine-tuning process. By systematically \nstoring and replaying past experiences (training data and model states) during the training sessions, the buff", "metadata": {"source": "sg248574.pdf", "chunk_index": 222, "total_chunks": 313}}
{"text": "d replaying past experiences (training data and model states) during the training sessions, the buffer helps ensure that the models continuously learn and adapt from the previous run. This approach mitigates catastroph ic forgetting and reinforces learning from \nhigh-value data points, which improves th e models' robustness and generalization \ncapabilities. Figure 5-14 encapsu lates a holistic and dynamic ap proach to model fine-tuning \nwithin the watsonx.ai ecosystem, which highlight s the interplay of ad vanced methodologies \nand real-time performance monitoring to achieve superior gen AI solutions.\nInstructLab will be available on watonx.ai as Software-as-a-Serv ice (SaaS), and it will be an \nimportant addition for gen AI on  an enterprise level. It will ena ble a pool of resources to \nfine-tune and improve generative LLMs.\n\n\n84 Simplify Your AI Journey: Unleashing the Power of AI with IBM watsonx.ai5.4.4  InstructLab use case examples\nIntroducing InstructLab on watsonx.ai heralds a", "metadata": {"source": "sg248574.pdf", "chunk_index": 223, "total_chunks": 313}}
{"text": "h IBM watsonx.ai5.4.4  InstructLab use case examples\nIntroducing InstructLab on watsonx.ai heralds a new era of advancements in gen AI, \nparticularly in the realm of enterprise-level ap plications. This innovative platform integrates \nseamlessly within the watsonx.ai ecosystem , which enables a dynamic and robust \nenvironment for the fine-tuning and deployment of LLMs. As an SaaS offering, InstructLab provides an unparalleled suite of tools and methodologies to optimize model performance through a meticulously structured 2-phase, fine-tuning process.\nThe InstructLab capabilities ar e impactful across many use cases, and they empower \norganizations to tailor AI solutions to their unique requirements. By leveraging the advanced features of Instru ctLab, users can achieve superior accura cy, efficiency, and scalability in their \nAI-driven initiatives. \nHere are some of the first prominent examples of use cases where InstructLab has \ndemonstrated significant improvements in its early life:", "metadata": {"source": "sg248574.pdf", "chunk_index": 224, "total_chunks": 313}}
{"text": "xamples of use cases where InstructLab has \ndemonstrated significant improvements in its early life:\n/SM590000Emergency medical services use case: A large hospital is looking to automate the \nprocessing of emergency medical records to  improve the efficiency and accuracy of \ncritical tasks. The system should be capable of completing the following tasks:\n\u2013 Case classification: Assigning priority le vels such as green (low urgency), orange \n(medium urgency), or red (high urgency) flags to cases based on their severity.\n\u2013 Peer medical review recommendations: Identifying cases that might require further \nreview by a medical peer to help ensu re proper oversight and decision-making.\n\u2013 Clinical compliance and guideline deviation: Detecting discrepancies  in medical reports \ncompared to established clinical guidelines, which enhance compliance and quality assurance.\n\u2013 Knowledge: The system will rely  on hospital compliance da ta, which includes clinical \nguidelines and historical patient reco", "metadata": {"source": "sg248574.pdf", "chunk_index": 225, "total_chunks": 313}}
{"text": " rely  on hospital compliance da ta, which includes clinical \nguidelines and historical patient records to perform its tasks.\n\u2013 Skill requirements:\n\u0081 Case classification to prio ritize emergency scenarios.\n\u0081 Identifying deviations from clinical guide lines to help ensure regulatory compliance.\n/SM590000Call transcript processing use case: A large North American telecommunications \ncompany requires an automated system to process and summarize incoming customer support call transcripts. The system must extract and organize information based on a predefined set of 80 questions. Examples include \u201cDid the customer want to upgrade their plan?\u201d or \u201cDid the customer report bandwidth issues?\u201d\n\u2013 Knowledge: The primar y data source will be call transcripts, which contain varied \nhuman expressions and conversational styles.\n\u2013 Skill requirements: Interpreting and anal yzing natural languag e, which includes \nunderstanding diverse writing styles and linguistic nuances to extract relevant insights fr", "metadata": {"source": "sg248574.pdf", "chunk_index": 226, "total_chunks": 313}}
{"text": "ncludes \nunderstanding diverse writing styles and linguistic nuances to extract relevant insights from conversations.\n\nChapter 5. Advanced cap abilities of watsonx.ai 85/SM590000Personalized retail recommendations use case: A retailer aims to deploy a personalized \nrecommendation engine that suggests in-stock products that are tailored to a user\u2019s dietary preferences, which include offering recommendations based on food allergies, nutritional goals, or ingredient restrictions.\n\u2013 Knowledge: The engine must use detailed product nutritional information and inventory \ndata to ensure accurate and timely recommendations.\n\u2013 Skill requirements:\n\u0081 Classification of ingredients and their alignment with dietary preferences.\u0081 Recommending products that match user profiles while considering inventory \navailability.\n\u2013 Agent capabilities:\n\u0081 Understanding and analyzing inventory data in real time.\u0081 Interpreting customer preferences and purchase history to generate meaningful \nsuggestions.\n/SM590000Int", "metadata": {"source": "sg248574.pdf", "chunk_index": 227, "total_chunks": 313}}
{"text": "rpreting customer preferences and purchase history to generate meaningful \nsuggestions.\n/SM590000Intelligent auto claims processi ng use case: An insurance prov ider requires a solution to \nanalyze images of auto accidents and sugges t insurance coverage recommendations that \nare based on the claimant's active policy. The system should improve the speed and accuracy of claims processing.\n\u2013 Knowledge: The system needs access to policy details, which include terms, coverage \nlimits, and exclusions.\n\u2013 Skill requirements:\n\u0081 Classification of accident severity by analyzing damage in submitted images.\n\u0081 Matching severity with appropriate coverage based on the policy.\n\u2013 Agent capabilities:\n\u0081 Accessing and analyzing driver history to help ensure an accurate policy \napplication.\n\u0081 Interpreting active insurance policies to provide recommendations that are aligned \nwith coverage terms.\n\n86 Simplify Your AI Journey: Unleashing the Power of AI with IBM watsonx.ai\n\n\u00a9 Copyright IBM Corp. 2025. 87Chap", "metadata": {"source": "sg248574.pdf", "chunk_index": 228, "total_chunks": 313}}
{"text": " Your AI Journey: Unleashing the Power of AI with IBM watsonx.ai\n\n\u00a9 Copyright IBM Corp. 2025. 87Chapter 6. Artificial intelligence agents\nArtificial intelligence (AI) agents will soon become  pivotal in modern co mputing by serving as \nautonomous entities that can perceive their environment, reason about their goals, and \nperform actions to achieve wanted outcomes. These agents will be central to many AI \nsystems, from personal assistants and autono mous vehicles to advanced simulations and \ndecision-making tools. The vers atility and capability of AI agen ts arise from their ability to \noperate independently while adapting to dynamic and often unpredictable environments. They combine advanced algorithms with AI and generative AI (gen AI) models, which enable \nthem to make intelligent decisions, ad apt to changes , and optimize outcomes. \nThis chapter delves into the intricacies of AI agents by exploring their fundamental \ncharacteristics, the motivation behind their development, and t", "metadata": {"source": "sg248574.pdf", "chunk_index": 229, "total_chunks": 313}}
{"text": "ents by exploring their fundamental \ncharacteristics, the motivation behind their development, and their applications across various domains. Through a detailed ex ploration, readers will understa nd why AI agents represent a \nparadigm shift in how computational systems interact with and influence their surroundings.\nThe following topics are described in this chapter:\n/SM5900006.1, \u201cWhat makes an AI agent\u201d on page 88\n/SM5900006.2, \u201cWhy AI agents are needed\u201d on page 94\n/SM5900006.3, \u201cMultiple AI agents\u201d on page 95\n/SM5900006.4, \u201cAI agents on watsonx.ai\u201d on page 100\n/SM5900006.5, \u201cAI agents use case examples\u201d on page 1076\n\n88 Simplify Your AI Journey: Unleashing the Power of AI with IBM watsonx.ai6.1  What makes an AI agent\nAn AI agent  can be formally defined as a computational  entity that is equipped with sensors to \nperceive its environment and use its actuators to interact with it. The core of an agent lies in its ability to reason and dec ide, which is driven by algorithms that ena", "metadata": {"source": "sg248574.pdf", "chunk_index": 230, "total_chunks": 313}}
{"text": "e core of an agent lies in its ability to reason and dec ide, which is driven by algorithms that enable it to  analyze inputs, \npredict outcomes, and choose actions that are aligned with specif ic objectives. Unlike \ntraditional software systems, which operate on predefined instructions, AI agents exhibit autonomy and flexibility with dynam ic execution flows, which en able them to handle complex \nscenarios with minimal human intervention. This autonomy stems from their design \nprinciples, which often draw from cognitive sciences, game theory, and control systems, \nenabling agents to emulate human-like decision -making processes. Furthermore, each AI \nagent can be designed for differ ent levels of complexity and interaction. This adaptability \nmakes AI agents indispensable in fields such as robotics and natural language processing (NLP), where complex interactions with dynamic environments are required.\nFigure 6-1 shows a schematic view of an AI agent.\nFigure 6-1   Schematic view of an", "metadata": {"source": "sg248574.pdf", "chunk_index": 231, "total_chunks": 313}}
{"text": "ts are required.\nFigure 6-1 shows a schematic view of an AI agent.\nFigure 6-1   Schematic view of an AI agent\nAgents, in the context of AI, can be conceptualized as sophisticated orchestrators of \nintelligence that can address intricate and multi-faceted problems. They achieve these goals by leveraging the reas oning capabilities of large languag e models (LLMs), formulating \ndetailed plans to resolve challenges, and running these plans by using a diverse set of tools. \nAn agent operates as a cohesive system, and its architecture can typically be broken down into four key modules:\n/SM590000The agent core\n/SM590000Search and memory modules\n/SM590000Planning modules\n/SM590000Tools\nEach of these components plays a critical role in ensuring th e agent's function s, adaptability, \nand effectiveness.\nThe \nagent core  stands as the central coordination hub of the agent. It is often described as \nthe \u201cdecision-making nucleus\u201d due to its pivotal role in governing the agent's logic, behavior, an", "metadata": {"source": "sg248574.pdf", "chunk_index": 232, "total_chunks": 313}}
{"text": " \nthe \u201cdecision-making nucleus\u201d due to its pivotal role in governing the agent's logic, behavior, and overall strategy. This module is responsible for synthesizing inputs, determining appropriate actions, and managing the interactions between other components. \n\n\nChapter 6. Artificial intelligence agents 89To design a robust and efficient agent core, you must define several foundation aspects that \nserve as the blueprint for the agent\u2019s behavior: \n/SM590000The general goals of the agent must be es tablished. These goals act as the guiding \nprinciples that dictate the agent\u2019s actions  and responses, which help ensure that its \noperations align with the overarching objectives that it is designed to achieve. Without clear goals, the agent risks becoming unfocused or inefficient. \n/SM590000Another critical aspect of the agent core is the explicit definition of the tools that are \navailable for execution, which involves cr eating a comprehensive \u201cuser manual\u201d that \ncounts and describes all ", "metadata": {"source": "sg248574.pdf", "chunk_index": 233, "total_chunks": 313}}
{"text": "or execution, which involves cr eating a comprehensive \u201cuser manual\u201d that \ncounts and describes all tools at  the agent's disposal. Each t ool\u2019s capabilities, limitations, \nand specific use cases should be outlined to enable the agent to allocate resources effectively and run tasks with precision. \n/SM590000Furthermore, the a gent core must provide detailed guidance about t he utilization of \nplanning modules. These modules are instrumental in enabling the agent to adapt dynamically to varying scenarios by selecting the most suitable planning strategy based on the context. This adaptability is key to ensuring th e agent\u2019s effectiv eness in complex \nand unpredictable environments.\nMemory integration  is another cornerstone  of the agent core. The memory system is \ndesigned to maintain and use relevant information from prior interactions or external research, which enhances the agent\u2019s ability to g enerate accurate and context-aware \nresponses. This integration requires dynamic managemen", "metadata": {"source": "sg248574.pdf", "chunk_index": 234, "total_chunks": 313}}
{"text": "lity to g enerate accurate and context-aware \nresponses. This integration requires dynamic management of memory items to help ensure that only the most pertinent data is referenced during inference. Also, an optional persona definition can be incorporated into the agent core to influence the agent\u2019s tone, preferences, and behavioral nuances. By defining a persona, the agent can be tailored to exhibit specific \ncharacteristics that align with its intended use case or audience, adding a layer of uniqueness to its interactions. \nMemory modules  are integral to the agent\u2019s ability to maintain contextual \nawareness and continuity. These modules are responsible for storing and managing information that supports the agent\u2019s operations. Memory can be categorized into two main types:\n/SM590000Short-term memory\nShort-term memory focuses on capturing the agent\u2019s immediate actions, thoughts, and \nobservations during ongoing interactions, which include data that is retrieved from vector searches, o", "metadata": {"source": "sg248574.pdf", "chunk_index": 235, "total_chunks": 313}}
{"text": "servations during ongoing interactions, which include data that is retrieved from vector searches, outputs from API calls, and results from database queries. Short-term memory \nis essential for helping ensure that the agent can respond effectively to the immediate \ncontext of a user\u2019s query.\n/SM590000Long-term memory\nIn contrast,  long-term memory serves as a repository for information that is accumulated \nover extended periods, which include summariz ed logs of prior interactions, personal \ndetails and preferences of the user, and other contextual information that might influence the agent\u2019s behavior. Long-term memory enables the agent to maintain a consistent and personalized approach in its interactions, which enhance user satisfaction and engagement. For example, in a conversational agent, long-term memory enables the retention of user preferences and past conversations, which create a more seamless and intuitive experience.\nWhen solving intricate problems, agents that are powered ", "metadata": {"source": "sg248574.pdf", "chunk_index": 236, "total_chunks": 313}}
{"text": " a more seamless and intuitive experience.\nWhen solving intricate problems, agents that are powered by LLMs are adept at navigating \ncomplexity by employing a combination of advanced methodologies that resembles planning an execution flow. One such methodology is \ntask and question decomposition . This approach \ninvolves breaking down compound queries into smaller, more manageable sub-questions that can be addressed sequentially. \n\n90 Simplify Your AI Journey: Unleashing the Power of AI with IBM watsonx.aiFor example, to answer the question, \u201cWill the te mperature tomorrow be higher or lower than \nthe historical average?\u201d the agent must decomp ose it into subquestions such as identifying \nthe location, determining the forecasted temperature for the specified location, and retrieving the historical average temperature for comp arison. By addressing each sub-question \nindividually, the agent can construct a comprehensive and accurate response. \nAnother essential technique is the usage of", "metadata": {"source": "sg248574.pdf", "chunk_index": 237, "total_chunks": 313}}
{"text": "nt can construct a comprehensive and accurate response. \nAnother essential technique is the usage of \nreflection and critique frameworks . These \nmethodologies, which include well-established prompting strategies such as ReAct , \nReflexion , Chain of Thought , and Graph of Thought , are designed to enhance the reasoning \ncapabilities of the agent. By  incorporating elements of evidence-based reasoning and \niterative self-critique, these frameworks enable the agent to refine its execution plans and improve the quality of its responses. Reflection  techniques enable the agent to evaluate the \nplausibility and coherence of its answers, which help  ensures that its outputs meet high \nstandards of reliab ility and relevance.\nClassification and the impl ementation of guardrails  are extra mechanisms that enhance the \nagent\u2019s decision-making process. By classifyi ng questions and queries, the agent can filter \nsearch results, identify relevant sub-agents, or even deny a response if necessary.", "metadata": {"source": "sg248574.pdf", "chunk_index": 238, "total_chunks": 313}}
{"text": "gent can filter \nsearch results, identify relevant sub-agents, or even deny a response if necessary. Guardrails, which serve as a specialized form of classification , act as safeguards to help ensure that the \nagent\u2019s outputs adhere to predefined ethical and operational guidelines. These mechanisms are valuable in scenarios where precision, safety, and compliance are paramount.\nThe \ntools  that are employed by an agent are another critical aspect of its function. These tools \nare executable workflows that enable the agent to perform specific tasks. Analogous to specialized third-pa rty APIs, tools provide the agent with targeted capabilities that extend its \nproblem-solving abilities. Exam ples of tools include Retrie val-Augmented Generation (RAG) \npipelines for generating context-aware answers, code interpreters for handling complex programming tasks,  and APIs for retrieving information from the internet. Also, utility APIs \nsuch as weather services or instant messaging platforms ca", "metadata": {"source": "sg248574.pdf", "chunk_index": 239, "total_chunks": 313}}
{"text": "on from the internet. Also, utility APIs \nsuch as weather services or instant messaging platforms can be integrated to address domain-specific needs. The versatility and ef fectiveness of an agent are enhanced by its \nability to leverage these specialized tools.\nGoing one step forward, agents that rely solely on text inputs face inher ent limitations in their \nability to interact with and ana lyze diverse data formats. \nMulti-modal agents  address this \nlimitation by incorporating the ability to process and reason ov er various input types, which \ninclude images, audio files, an d structured datasets. This capability expands the range of \napplications for agents, which enable them to ta ckle tasks that require visual analysis, speech \nprocessing, or combined reasoning across multiple modalities. For example, a multi-modal agent can analyze an image to extract relevant features, process an accompanying audio file for contextual information, and synthesize this  data with text-based inpu", "metadata": {"source": "sg248574.pdf", "chunk_index": 240, "total_chunks": 313}}
{"text": "n accompanying audio file for contextual information, and synthesize this  data with text-based inputs to deliver a \ncomprehensive solution.\nBy following the main core modules of an AI agent and through thoughtful design and \ncontinuous refinement, agents are poised to become indispensable tools in the ever-expanding landscape of AI.\nAn AI agent, as illustrated in Fi gure 6-2 on page 91, consists of a centralized planning system \nthat is supported by a general-purpose generative LLM. This LLM serves as the core orchestrator, which can devise a structured pl an of actions to address user queries. Its \ndecision-making process is enhanced by a memory module, which maintains contextual information and is continuously updated based on past actions and outcomes, which help ensure adaptive and dynamic responses.\n\nChapter 6. Artificial intelligence agents 91Figure 6-2   High-level view at the core of an AI agent\nThe planning system interacts with an I/O communication layer to run the planned a", "metadata": {"source": "sg248574.pdf", "chunk_index": 241, "total_chunks": 313}}
{"text": "re of an AI agent\nThe planning system interacts with an I/O communication layer to run the planned actions \neffectively. This layer acts as a bridge between the LLM and an extensive Tool Library, which enables the agent to pe rform specialized tasks beyond its intrinsic capabilities. The tools \ninclude functions such as code execution, do cument retrieval (RAG), calculations, weather \nqueries, time and location services, and AI and gen AI models, among others. The module of communication is a crucial part of an agent because it sets the formatting of the I/O communication in a standardized way to enable fast and transparent invocation of tools and output comprehension.\nThe LLM at the core of this system is typically a large foundation model (FM) that is optimized \nfor high performance across diverse benchmar ks and tasks. For example, in the context of \nthe IBM watsonx.ai platform, this  role can be fulfilled by models  such as Mistral Large, Llama \n3.3 70B, or Llama 3.1 405B, which ar", "metadata": {"source": "sg248574.pdf", "chunk_index": 242, "total_chunks": 313}}
{"text": " role can be fulfilled by models  such as Mistral Large, Llama \n3.3 70B, or Llama 3.1 405B, which are know n for their robust capab ilities in generative \nreasoning and planning.\nBehind the scenes, an agent has its own calle d system prompt, which is the usual system \nprompt that can be set for any generative LLM. It describes in detail the main task for which a generative LLM should adhere to. The scheme behind the main prompt solution is shown in Figure 6-3.\nFigure 6-3   Logical prompt schema definition for agents\n\n\n92 Simplify Your AI Journey: Unleashing the Power of AI with IBM watsonx.aiThis system prompt is a structured set of instructions that encapsulates the core task, and \ndefines the role of the LLM, the expected output schema, and the instructions that the model should follow.\nAs shown in Figure 6-3 on page 91, the system prompt integrates multiple critical elements:\n/SM590000Memory: Provides contextual data or historical  interactions that the LLM can leverage to \nmaintain", "metadata": {"source": "sg248574.pdf", "chunk_index": 243, "total_chunks": 313}}
{"text": "0Memory: Provides contextual data or historical  interactions that the LLM can leverage to \nmaintain continuity and relevance in responses. This approach helps ensure that the agent adapts dynamically to ongoing tasks or user needs.\n/SM590000Role definition: Specifies the persona or role that the agent assumes (for example, a \ncustomer support assistant, a data scientist, or a creative writer), and aligns the behavior and tone of the LLM with the intended use case. \nExample 6-1 shows an example of a role prompt definition:\nExample 6-1   Defining a role for the agent\n#Role\nAs a helpful assistant, your role is to provide users with actionable insights from their data files.\n/SM590000Instructions: Detailed gu idelines about how the LLM should process inputs, interpret user \nqueries, and generate outputs. These instructions help ensure that the model stays on task and adheres to the wanted operational framework.\nExample 6-2 show an example of the instruction prompt definition.\nExample 6-2 ", "metadata": {"source": "sg248574.pdf", "chunk_index": 244, "total_chunks": 313}}
{"text": "perational framework.\nExample 6-2 show an example of the instruction prompt definition.\nExample 6-2   Outline instructions for the agent\n# Instructions\nThe user can see only the Final Answer. All answers must be provided there. Functions must be used to retrieve factual or historical information to answer the message. If the user suggests using a function that is not available, answer that the function is not available.\n/SM590000Output schema: A predefined structure that dictates how the LLM should format its \nresponses, which may include JSON formats, bullet points, or other data representations \nthat are required by downstream tools or workflows. This prompt is important for the \noverall communication and interaction in the multiple steps in an agentic execution flow.\nExample 6-3 shows an example of the output schema prompt definition.\nExample 6-3   Defining the output schema that the agent should follow\n#Output schema (also known as the agent\u2019s control logic)\nYou communicate only in", "metadata": {"source": "sg248574.pdf", "chunk_index": 245, "total_chunks": 313}}
{"text": "agent should follow\n#Output schema (also known as the agent\u2019s control logic)\nYou communicate only in instruction lines. The format is: \"Instruction: expected output\". Only use these instruction lines and must not enter empty lines or anything else between instruction lines. Skip the instruction lines Function Name, Function Input, Function Caption, and Function Output if no function calling is required. Message: User's message. You never use this instruction line. Thought: A single-line step-by-step plan of how to answer the user's message. You can use the available functions that are defined above. This instruction line must be immediately followed by Function Name if one of the available functions that are defined above needs to be called, or by Final Answer. Do not provide the answer here. Function Name: Name of the function. This instruction line must be immediately followed by Function Input. Function Input: Function parameters. An empty object is a valid parameter. \n\nChapter 6. A", "metadata": {"source": "sg248574.pdf", "chunk_index": 246, "total_chunks": 313}}
{"text": "ion Input. Function Input: Function parameters. An empty object is a valid parameter. \n\nChapter 6. Artificial intelligence agents 93Function Output: Output of the function in JSON format. Thought: Continue your \nthinking process. Final Answer: Answer the user or ask for more information or clarification. It must always be preceded by Thought.\nAlso, the agent can enhance its functions with tools, which ex tend the LLM's capabilities by \nintegrating external APIs or specialized modules. Each tool includes the following items:\n/SM590000A tool description: An explanation of its purpose and function.\n/SM590000A tool schema: Specifications for how the LLM should interact with the tool, which includes \ninput and output formats.\nExample 6-4 shows the example parsed output after a certain user request regarding an \nexplanation of a certain dataset file occurs.\nExample 6-4   Agent output example\nThought: The user wants to know what the file \"CSV- bill of materials.csv\" is about. I can use the Py", "metadata": {"source": "sg248574.pdf", "chunk_index": 247, "total_chunks": 313}}
{"text": "hought: The user wants to know what the file \"CSV- bill of materials.csv\" is about. I can use the Python tool to read the file and provide a summary. Function Name: Python Function Input: {\"language\":\"python\",\"code\":\"import pandas as pd\\n\\ndf = pd.read_csv('CSV-billmaterials.csv')\\nprint(df.head()\",\"inputFiles\":{\"file_670d56abb912d7771371652e\":\"CSV- bill of materials.csv\"}} Function Output: The code ran successfully. Standard output: \u2018\u2019\u2019QUANTITY ... PART 0 3700 ... 144EC8-14101-20 1 5500 ... 096EUF-T4101D20 2 45000 ... 004ZTF-41Z01M20 3 4334 ... NaN 4 1564 ... NaN \n[5 rows x 4 columns] \u2018\u2019\u2019\nBy combining these components, the system prompt orchestrates the interaction between the \nLLM and external resources, which help ensure consistency, precision, and task alignment. \nThis modular approach enables AI agents to handle complex workflows and adapt to diverse applications.\nThis standard agent architecture can generate and run plans, and iteratively refine its \napproach by leveraging feedba", "metadata": {"source": "sg248574.pdf", "chunk_index": 248, "total_chunks": 313}}
{"text": "t architecture can generate and run plans, and iteratively refine its \napproach by leveraging feedback and memory updates. The modular design of agents, which is supported by a versatile Tool  Library, enables sca lability and adaptabilit y for a wide range of \nuse cases, and with the usage of agents on watsonx.ai, the scaling to enterprise-grade solutions is once again possible.\n\n94 Simplify Your AI Journey: Unleashing the Power of AI with IBM watsonx.ai6.2  Why AI agents are needed\nThe necessity for AI agents stems from the growing complexity of tasks and environments \nthat surpass the capabilit ies of conventional software systems.  Traditional systems often falter \nin scenarios requiring adaptive, context-aware de cision-making, especially when dealing with \nvast datasets, uncertain outcomes, and real-time constraints. In domains like logistics, healthcare, and finance, where decision-making must balance multiple variables simultaneously, the utility of AI agents becomes evid ent. ", "metadata": {"source": "sg248574.pdf", "chunk_index": 249, "total_chunks": 313}}
{"text": "n-making must balance multiple variables simultaneously, the utility of AI agents becomes evid ent. These agents excel in scenarios \ndemanding real-time responses, such as aut onomous vehicles navigating dynamic traffic \nconditions or virtual assistants managing multifaceted user requests. \nBeyond efficiency, AI agents also bring about significant cost savings by automating repetitive \ntasks, reducing human error, and improving o perational accuracy. Thei r ability to adapt from \nexperience by using a memory module and to adapt to novel situations is crucial in addressing problems where predefined solutions are inadequate. For example, reinforcement learning (RL) techniques enable AI agents to optimize behavior over time, which refines their \ndecision-making capabilities with minimal hum an input. By acting as adaptive problem \nsolvers, AI agents provide a bridge between theoretical AI research and practical, real-world enterprise-grade applications.\nFigure 6-4 shows the gen AI journey", "metadata": {"source": "sg248574.pdf", "chunk_index": 250, "total_chunks": 313}}
{"text": "esearch and practical, real-world enterprise-grade applications.\nFigure 6-4 shows the gen AI journey for AI agents.\nFigure 6-4   Generative AI journey for AI agents\nAgents that are powered by LLMs represent the next frontier in driving productivity gains for \nenterprises. As businesses increasingly rely on AI to streamline operations and elevate \ncustomer experiences, agents offer a revolutionary step forward by automating complex, multi-step tasks that previously required human intervention. Unlike traditional LLMs, which excel at handling FAQs or supporting nuanced informational queries through RAG approaches, agents bring advanced capabilities to orches trate and run high-value workflows. \nThis ability to handle complex sc enarios such as planning a marketing campaign, optimizing \nsupply chain logistics, or conducting sophisticated data analysis, positions agents as essential tools for transforming enterprise productivity.\n\n\nChapter 6. Artificial intelligence agents 95The true poten", "metadata": {"source": "sg248574.pdf", "chunk_index": 251, "total_chunks": 313}}
{"text": "r transforming enterprise productivity.\n\n\nChapter 6. Artificial intelligence agents 95The true potential of agents lies in their ca pacity to integrate seam lessly with existing \nsystems, tools, and data sources, which enable th em to act as intelligent  intermediaries that \nconnect disparate workflows. For enterprises, this approach means automating entire business processes rather than isolated tasks. For example, an agent can retrieve customer data, analyze purchasing patterns, generate  personalized recommendations, and trigger \nactions like sending tailored offers or updating customer relationship management systems. By eliminating manual handoffs and streamlining processes, agents enable employees to focus on strategic decision-making rather than repetitive or time-consuming tasks.\nFrom a business perspective, agents are the key to unlocking the next wave of productivity \ngains. They enhance operational efficiency, reduce costs, and drive faster time-to-market for critical initia", "metadata": {"source": "sg248574.pdf", "chunk_index": 252, "total_chunks": 313}}
{"text": "ey enhance operational efficiency, reduce costs, and drive faster time-to-market for critical initiatives. Moreover, they enable businesses to scale their efforts without proportionally increasing resources, which are vital in today\u2019s competitive and resource-constrained environments. Imagine an agent that can plan, run, and monitor an entire ad campaign or a product launch task in hours, which typically require weeks of human effort. This scalability im proves efficiency, and it  creates opport unities for innovation because \nteams can redirect their focus to higher-value, creative, and strategic activities. In this context, agents are a technological enhancement and a strategic imperative for the modern enterprise. They represent a shift from reactive to proactive operations, which enable businesses to anticipate needs, respond faster to  market dynamics, and drive growth in ways \npreviously unimaginable. Enterp rises that adopt agent s will lead the charge in this new era of \nproduc", "metadata": {"source": "sg248574.pdf", "chunk_index": 253, "total_chunks": 313}}
{"text": "iously unimaginable. Enterp rises that adopt agent s will lead the charge in this new era of \nproductivity, and set the benchmark for operational excellence and innovation in their industries.\n6.3  Multiple AI agents\nWhen you extend the concept of individual agents in software systems, you get multi-agent systems (MASs), which consist of multiple AI en tities working collaboratively or competitively \nto solve complex problems within shared digital environments. These systems are transformative when augmented by gen AI capabilities because th ey enable agents to \nengage in more sophisticated tasks, such as content generation, dynamic interaction with users, or collaborative reasoning. In a software-based MAS, each agent operates autonomously while adhering to predefined pr otocols for communication and collaboration. \nThis autonomy enables agents to handle tasks like distributed resource management, \nadaptive problem-solving, and even creative endea vors, such as generating ideas, plans", "metadata": {"source": "sg248574.pdf", "chunk_index": 254, "total_chunks": 313}}
{"text": "management, \nadaptive problem-solving, and even creative endea vors, such as generating ideas, plans, or \npersonalized user experiences. Gen AI further amplifies their function by enabling natural language generation, image synthesis, and decision-making support, which enhances the agents' ability to interpre t, reason, and produce outputs in real time. \nA key challenge in software-based MASs, particular ly ones that leverage gen AI, is achieving \neffective inter-agent communication and collaboration. Protocols that are based on message-passing, such as JSON over RESTful APIs or advanced graph-based communication models, help ensure that agents can share knowledge, negotiate responsibilities, and resolve conf licts. Generative AI enhances these interactions by enabling \ncontext-aware dialog and summa rization capabilities, which make inter-ag ent exchanges \nmore natural and efficient. More over, coordination strategies within such systems are pivotal. \nIn leader-followe r setups, gener", "metadata": {"source": "sg248574.pdf", "chunk_index": 255, "total_chunks": 313}}
{"text": "re over, coordination strategies within such systems are pivotal. \nIn leader-followe r setups, generative agent s with advanced reasonin g capabilities may take \non supervisory roles to craft high-level plans or  synthesize insights for the collective. Fully \ndistributed MASs enable agents to collaborate dynamically by relying on peer-to-peer negotiations or RL-based decision policies to achieve shared objectives. For example, in a \ncollaborative creative task such as automated marketing content generation, different agents in the system might specialize in headline creat ion, visual asset gener ation, and audience \nsentiment analysis. Together, these agents leverage gen AI to deliver cohesive, high-quality outputs that surpass the capab ilities of indivi dual components.\n\n96 Simplify Your AI Journey: Unleashing the Power of AI with IBM watsonx.aiThe integration of a MAS with gen AI promises to unlock solutions for some of the most \nintricate software challenges, such as distri buted k", "metadata": {"source": "sg248574.pdf", "chunk_index": 256, "total_chunks": 313}}
{"text": "ises to unlock solutions for some of the most \nintricate software challenges, such as distri buted knowledge synthesis, large-scale content \npersonalization, and dynamic adaptation to user behaviors. As these systems continue to evolve, they are poised to redefine how software systems interact, collaborate, and solve problems, which pave the way for a new era of  intelligent, cooperativ e, and gen AI-driven \napplications.\nThe decentralized nature of a MAS is critical in these addressed applications, which help \nscalability, robust ness, and fault tolerance. For example, a generative MAS that is deployed in \ncustomer support can assign tasks dynamically across agents, with some agents generating empathetic responses, other agents crafting visually appealing solutions, and yet other \nagents analyzing sentiment data in real time. This division of labor enables the system to manage workloads efficiently, respond quickly to changes, and help ensure seamless service continuity even if indivi", "metadata": {"source": "sg248574.pdf", "chunk_index": 257, "total_chunks": 313}}
{"text": " efficiently, respond quickly to changes, and help ensure seamless service continuity even if individual agents face disruptions. \nBeing decentralized is one of the key advantag es of a MAS. Unlike centralized systems where \na single entity controls decision-making and system-wide operations, MASs are designed to \noperate without a single point of failure. If one agent fails or is compromised, the rest of the system can continue to function, which makes it highly resilie nt. This decent ralized approach \nalso allows MASs to scale efficiently because more agents can be added to the system without disrupting its overall performance. Furthermore, because the agents are distributed, they can operate in diverse environments, which include real-time scenarios, where traditional centralized systems might strugg le. The power of a MAS lies in  this collective intelligence, \nwhere the sum of  the parts is greater than th e individual agents' abilities.\nAs MASs continue to evolve, they are poise", "metadata": {"source": "sg248574.pdf", "chunk_index": 258, "total_chunks": 313}}
{"text": " parts is greater than th e individual agents' abilities.\nAs MASs continue to evolve, they are poised to unlock solutions for some of the most intricate \nchallenges in fields such as distributed computing, environmental monitoring, and autonomous exploration. For example, in distributed computing, a MAS can optimize resource usage across a network of machines , which enable more efficient computation and \ndata processing. In environmental monitoring,  you can use a MAS to deploy a network of \nsensors that autonomously gather and process data, which provides real-time insights into environmental conditions. In autonomous exploration, a MAS can enable a fleet of robotic vehicles or drones to work together to explor e unknown terrains, share information, and adapt \nto changes in the environment. \nA notable development in the realm of MASs is the advent of multi-agent orchestration \nframeworks. These frameworks provide a unified platform for coordinating conversations among multiple agents", "metadata": {"source": "sg248574.pdf", "chunk_index": 259, "total_chunks": 313}}
{"text": "ks. These frameworks provide a unified platform for coordinating conversations among multiple agents, serving as a high-level abstraction for using FMs. By integrating LLMs, tools, and human inputs, various framew orks enable the seamless orchestration of \nagent interactions in a way that enhances the capabilities of individual agents. These \nframeworks typically feature highly capable, customizable, and conversational agents, which \ncan collaborate through automa ted agent chats, which improv e their collective ability to \nhandle complex tasks. This integration enables MASs to function more efficiently by leveraging the power of language models, tools, and human expertise in a coordinated manner. As a result, MAS framew orks offer an exciting potenti al for creating more intelligent \nand adaptive systems that can address a wide range of challenges in both industrial and research contexts.\nThe ongoing evolution of MASs promises to push the boundaries of what is possible in \nautonomous ", "metadata": {"source": "sg248574.pdf", "chunk_index": 260, "total_chunks": 313}}
{"text": "s.\nThe ongoing evolution of MASs promises to push the boundaries of what is possible in \nautonomous systems by enabling new capabilit ies and driving innovation across various \nindustries. As researchers continue to explore the potential of these systems, new frameworks, coordination strategies, and interaction protocols continue to emerge, further enhancing the power and flexibility of MASs in tackling the most co mplex and large-scale \nproblems.\n\nChapter 6. Artificial intelligence agents 97The architectural diagram in Figure 6-5 outlines a sophisticated MAS framework that is \ndesigned to integrate diverse functions such as planning, memory management, \ncommunication, and task orchestr ation. The system employs a mo dular design that facilitates \nscalability, adaptability, and in teroperability, which caters to complex problem-solving \nscenarios across various domains. Let us delve into each component and their interplay within the architecture.\nFigure 6-5   High-level view of a multi", "metadata": {"source": "sg248574.pdf", "chunk_index": 261, "total_chunks": 313}}
{"text": " each component and their interplay within the architecture.\nFigure 6-5   High-level view of a multi-agent syst em architecture\nA MAS that is enhanced by gen AI represents a sophisticated and transformative paradigm in \nAI, where multiple autonomous agents collaborate or interact within a shared environment to achieve complex goals. These systems are built to harness the synergy of diverse agent capabilities by leveraging the powe rful reasoning, creativity, and  contextual un derstanding of \nLLMs to tackle problems beyond the scope of any single agent. Figure 6-5 lays out a comprehensive blueprint for such a system. Now, we will see a detailed, expert-level \nexplanation of its various interconnected components and their interplay.\nAt the heart of this MAS architecture lies the concept of the agent, which operates as an \nautonomous unit that is equipped with distinct roles, behaviors, and tools. Each agent is imbued with a profile or persona that defines its domain expertise, operation", "metadata": {"source": "sg248574.pdf", "chunk_index": 262, "total_chunks": 313}}
{"text": "d tools. Each agent is imbued with a profile or persona that defines its domain expertise, operational boundaries, and response style. For example, an agent might  function as a scientific researcher that is \nskilled in computational chemistry or as a cust omer service representative with expertise in \nnatural language understanding and resolution st rategies. This persona is not static because \nit evolves in response to feedback and enviro nmental changes, which help ensure that the \nagent remains relevant and effective in dynamic settings.\nCentral to an agent\u2019s operation is its belief state, which is an internal model that encapsulates \nits understanding of the world, its knowledge of tasks at hand, and its memory of past interactions. This belief state is dynamic and constantly updated through observations, actions, and communications with other agents or external systems. The belief state also integrates inputs from memory. Memory is bifurcated into long-term and short-term storage", "metadata": {"source": "sg248574.pdf", "chunk_index": 263, "total_chunks": 313}}
{"text": "state also integrates inputs from memory. Memory is bifurcated into long-term and short-term storage, each serving distinct roles. Short-term memory  retains ephemeral inform ation that is crucial \nfor immediate task execution and contextual reasoning. For example, an agent might use short-term memory to temporarily store user input or intermediate results of calculations. In contrast, long-term memory preserves knowledge that is accumulated over time, such as procedural expertise, domain-specific facts, or  historical interactions. The integration of \nmemory with the agent\u2019s belief state helps ensure that decisions are informed by both the immediate context and historical knowledge. This dual-layered memory structure enhances the system\u2019s ability to handle co mplex, multi-step tasks that r equire contextual continuity and \nlong-term planning.\n\n\n98 Simplify Your AI Journey: Unleashing the Power of AI with IBM watsonx.aiDriving the agent\u2019s reasonin g and interaction is its policy , a fr", "metadata": {"source": "sg248574.pdf", "chunk_index": 264, "total_chunks": 313}}
{"text": "e Power of AI with IBM watsonx.aiDriving the agent\u2019s reasonin g and interaction is its policy , a framework of decision-making \nrules and algorithms that govern how the agent interprets inputs, prioritizes tasks, and generates outputs. Policies can be simple, predefined heuristics or sophisticated, dynamically updated models that are informed by machine learning (ML) techniques, such as RL. These policies are operationalized through the agent\u2019s LLM core, which is the generative engine that processes natural language inputs, synthesizes insights, generates context-aware responses, and even creates novel solutions to problems. The LLM also serves as the agent\u2019s interface to interpret ambiguous or unstructured information, which effectively bridges the gap between human language and computational logic.\nAgents in this system are equipped with advanc ed communication c apabilities that are \ndefined through a structured I/O schema that enables them to interact with other agents, external to", "metadata": {"source": "sg248574.pdf", "chunk_index": 265, "total_chunks": 313}}
{"text": "defined through a structured I/O schema that enables them to interact with other agents, external tools, and the environment. Communication is about exchanging messages, negotiating shared understandings, aligning goals, and ensuring coordinated action. To accomplish these tasks, agents can rely on tools that are integrated within the system. These tools extend the agent\u2019s functio nal repertoire and in clude utilities like API access for external \ndata retrieval, calculators for mathematical computations, code interpreters for debugging and running programs, and multimodal models for handling complex data types, such as images or video. \nFor domain-specific applications, tools like chemistry simulators or Robotic Process \nAutomation (RPA) frameworks can be deployed, which enable agents to specialize in tasks that range from molecular modeling to workflow optimization. These tools are seamlessly integrated into the agent\u2019s workflow, which enables it to run specialized tasks without requ", "metadata": {"source": "sg248574.pdf", "chunk_index": 266, "total_chunks": 313}}
{"text": "mlessly integrated into the agent\u2019s workflow, which enables it to run specialized tasks without requiring extra human intervention. \nThere is no defined limit or minimum requirement regarding the number of tools that are \navailable to a set of agents: it is something dependent on the specific use cases that are addressed. What is proposed here is just a pot ential set of tools that might be useful for \nvarious potential use cases in a specific set of industries. In a MAS, a set of tools might contain hundreds of tools, depending on what is the goal of the system.\nAt a higher level, the MAS orchestrates the activi ties of these agents to help ensure that they \nwork collaboratively toward shar ed objectives. This orchestration is managed by several \ncritical components. \nThe first is the goal and task decomposition me chanism, which takes high-level goals and \nbreaks them into smaller, ma nageable tasks and subtasks. Fo r example, if the system\u2019s goal \nis to generate a comprehensive mark", "metadata": {"source": "sg248574.pdf", "chunk_index": 267, "total_chunks": 313}}
{"text": "nageable tasks and subtasks. Fo r example, if the system\u2019s goal \nis to generate a comprehensive market analys is, this task might be decomposed into tasks \nlike gathering data, analyzing trends, and generating a summary report, with each task that is further divided into specific steps like querying databases or visualizing data. \nTo enable task execution, the system relies on a planner that assigns tasks to the most \nsuitable agents based on th eir profiles, curr ent workloads, and skillsets. The \nplanner  plays a \npivotal role in the MAS by orchestrating the decomposition of high-level goals into granular tasks and subtasks. The planning  process leverages the agent\u2019s  policy and LLM to identify \nthe optimal sequence of actions that are required to achieve the outcome. The planner also monitors progress, adapting task sequences or agent roles as needed to accommodate changing conditions or unexpected challenges. For example, if one agent encounters a bottleneck in data retrieval, the", "metadata": {"source": "sg248574.pdf", "chunk_index": 268, "total_chunks": 313}}
{"text": "s or unexpected challenges. For example, if one agent encounters a bottleneck in data retrieval, the planner can reassign related tasks to another agent with overlapping capabilities. \n\nChapter 6. Artificial intelligence agents 99For critical use cases, th e architecture in corporates the ability to receive human feedback  \nduring the execution of the plan to help ensure that automation in high-stakes scenarios remains governable and aligned with human oversight. By enabling human intervention, the system can address unforeseen complexities, validate decisions, and maintain control over critical operations.\nTask decomposition ensures that even complex ob jectives are approached methodically, with \nsubtasks delegated to the appropriate agents or tools.\nCollaboration within the MAS is further enhanced through sophisticated communication \npatterns, which define how agents interact and share information. The architecture supports multiple \ncommunication patterns :\n/SM590000Layered communic", "metadata": {"source": "sg248574.pdf", "chunk_index": 269, "total_chunks": 313}}
{"text": " information. The architecture supports multiple \ncommunication patterns :\n/SM590000Layered communication: Hierarchical interactions where agents operate at different levels \nof abstraction by passing information up or down the chain.\n/SM590000Decentralized communication: Peer-to-peer exchanges among agents to help ensure \nflexibility and redu ce bottlenecks.\n/SM590000Centralized communication: A hub-and-spoke model where a central coordinator \nmanages all interactions.\n/SM590000Shared message pool: A collaborative mechanism where agents exchange messages \nthrough a shared repository.\nHybrid patterns, such as shared message pools or global workspaces, enable agents to post \nintermediate results or disco veries to a common repository , which enables asynchronous \ncollaboration and emergent problem-solving. The blackboard pattern  or global workspace \nserves as a central knowledge-sharing hub within the MAS. Agents use this shared repository to post updates, intermediate calculations, or", "metadata": {"source": "sg248574.pdf", "chunk_index": 270, "total_chunks": 313}}
{"text": "hub within the MAS. Agents use this shared repository to post updates, intermediate calculations, or unresolved queries, which create a collaborative environment where other agents ca n contribute insights or take over pending \ntasks. For example, an agent working on a data analysis task might upload partial results to the blackboard, which another agent can use to generate visualizations or summaries. \nThe MAS is supported by  an agents and skills repository, wh ich is a centralized directory that \ncatalogs the capabilities, expert ise, and tools that are associ ated with each agent. This \nrepository enables dynamic discovery and allocati on of agents for specific tasks, which helps \nensure that the system can scale and adapt to  diverse challenges. It also facilitates the \nincorporation of new skills or agents so th at the system can evolve as new tools or \nrequirements emerge.\nThe architecture helps ensure that the output that is generated by the system is coherent, \ncontextually re", "metadata": {"source": "sg248574.pdf", "chunk_index": 271, "total_chunks": 313}}
{"text": "hitecture helps ensure that the output that is generated by the system is coherent, \ncontextually relevant, and correctly formatted. The \nI/O schema  governs the structure of inputs \nand outputs by standardizing interactions across agents, tools, and external systems. This schema helps ensure compatibilit y and consistency regardless of the task or domain. The \nsystem\u2019s communication module also plays a role in tailoring outputs to the intended audience. For example, technical results might be presented in a concise, data-rich format for domain experts, but layperson-oriented outputs would emphasize clarity and simplicity. \n\n100 Simplify Your AI Journey: Unleashing the Power of AI with IBM watsonx.aiDespite its sophisticated design, the MAS must handle potential errors that can arise during \nexecution:\n/SM590000Failed API calls to tools: A tool might be te mporarily unavailable or malfunction, which can \nlead to incomplete or erroneous task execution. Human feedback can help decide whe", "metadata": {"source": "sg248574.pdf", "chunk_index": 272, "total_chunks": 313}}
{"text": "ction, which can \nlead to incomplete or erroneous task execution. Human feedback can help decide whether to retry the tool, use an alternative tool, or modify the task parameters.\n/SM590000Infinite loops: Erroneous task decomposition or planning might result in a loop where the \nsystem repeatedly runs the same actions without progress. Human intervention can identify and correct the root cause to prevent resource wastage.\n/SM590000Rogue paths or wrong tool selection or input: The system might choose an inappropriate \ntool or misinterpret input data, which can lead to incorrect outputs. Human feedback can help realign the system\u2019s actions to help ensure that the task remains on track.\nBy integrating human feedback into the loop, particularly for infinite loops or rogue paths, the \nMAS can maintain a high degree  of reliability and robustness by implementin g a fail-safe \ntechnique on human-in-the-loop interaction after deviant agents\u2019 behavior is detected by the overall orchestration sy", "metadata": {"source": "sg248574.pdf", "chunk_index": 273, "total_chunks": 313}}
{"text": "n-in-the-loop interaction after deviant agents\u2019 behavior is detected by the overall orchestration system. This hybrid approach of automation with human oversight is especially critical in high-stakes domains wh ere errors can have significant consequences.\nThe MAS operates within an environment, such as the external world or a digital context \nwhere tasks are performed and results are applied. Agents interact with the environment by observing its state, acting to modify it, and processing feedback to refine their belief states and policies. The environment is also where the whole MAS runs, and it is possible to have environments that are composed of multiple locations, such as cloud environments, virtual machines (VMs) and containers, or further proprietary software.\n6.4  AI agents on watsonx.ai \nIBM watsonx.ai enhances the development of an enterprise-grade agentic technology stack (Figure 6-6) by providing powerful  tools, models, and middleware  capabilities th at are tailored \nfor ", "metadata": {"source": "sg248574.pdf", "chunk_index": 274, "total_chunks": 313}}
{"text": "ure 6-6) by providing powerful  tools, models, and middleware  capabilities th at are tailored \nfor scalable, intelligent, and  adaptive operations. \nFigure 6-6   Enterprise agentic tech stack\n\n\nChapter 6. Artificial intelligence agents 101At the foundation level, watsonx.ai delivers robust LLMs optimized for specific enterprise use \ncases to enable agents to interpret and act on complex queries with high accuracy and relevance. These LLMs seamlessly integrate in to the Agentic Framework, which serves as \nthe operational backbone for orchestrating tasks, planning workflows, and retaining memory for context-driven decision-making. \nIBM watsonx.ai also supports the Agentic Service Deployment & Operation Platform, which \noffers a streamlined way to de ploy and manage agentic services while  ensuring reliability, \nscalability, and security at an enterprise level. To ensure en terprise-grade observability and \nmonitoring, watsonx.ai incorporat es observability mechanisms that  provide real-", "metadata": {"source": "sg248574.pdf", "chunk_index": 275, "total_chunks": 313}}
{"text": "observability and \nmonitoring, watsonx.ai incorporat es observability mechanisms that  provide real-time insights \ninto agent performance, operational health , and user interactions. These mechanisms \nfacilitate continuous optimizati on and help ensure t hat agentic services  align with business \ngoals. By bridging models, middleware, and applications, watsonx.ai creates a cohesive and modular enterprise tech stack that can address the evolving demands of modern businesses with precision, adaptab ility, and innovation.\nwatsonx.ai agents are a transformative innovation in the domain of AI. These agents are \ndesigned to provid e businesses with unparalle led capabilities in automa ting tasks, processes, \nand decision-making. Through a blend of inte rfaces, cutting-edge technologies, and robust \nintegration options, watsonx.ai enables the dev elopment, deployment, and optimization of \nintelligent agents that cater to a diverse range of enterprise needs.\nAt the core of watsonx.ai's agent i", "metadata": {"source": "sg248574.pdf", "chunk_index": 276, "total_chunks": 313}}
{"text": "ligent agents that cater to a diverse range of enterprise needs.\nAt the core of watsonx.ai's agent ic capabilities is the Agent Build er (Figure 6-7), which is an \nintuitive and powerful tool that accelerates the development lifecycle. The visual interface of the Agent Builder enables developers to construct agents with ease, which reduces the complexity that is typically associated with designing and managing such systems. Agents \nwithin watsonx.ai are defined through natural language instructions, and they can be equipped with various tools to expand their fu nctions. These tools act as modular building \nblocks to enable developers to create sophisticated workflows that are tailored to specific requirements.\nFigure 6-7   Agent Builder view on the watsonx.ai UI\n\n\n102 Simplify Your AI Journey: Unleashing the Power of AI with IBM watsonx.aiOne of the standout features of the Agent Builder is its seamless integration with multiple \nagent frameworks. In addition to IBM proprietary technol", "metadata": {"source": "sg248574.pdf", "chunk_index": 277, "total_chunks": 313}}
{"text": " is its seamless integration with multiple \nagent frameworks. In addition to IBM proprietary technologies, developers can also leverage popular open-source fr ameworks like LangChain and LangGr aph. This flexib ility helps ensure \nthat businesses can use the best tools and methodologies that are available in the ecosystem, and adapt them to their unique operational need s. The ability to integrate \nopen-source solutions with IBM advanced technologies provides a level of customization and extensibility that is critical for modern  enterprises, as shown in Figure 6-8.\nFigure 6-8   Overview of customiz ations on watsonx.ai Agent Builder\nTesting and debugging are essential components of the agent development process, and \nwatsonx.ai Agent Builder excels in this area. Real-time te sting capabilities enable developers \nto identify and resolve issues as they arise,  which minimizes downtime  and iteration cycles. \nThis feature is complemented by the \u201cone-clic k\u201d deployment mechanism,  which s", "metadata": {"source": "sg248574.pdf", "chunk_index": 278, "total_chunks": 313}}
{"text": "d iteration cycles. \nThis feature is complemented by the \u201cone-clic k\u201d deployment mechanism,  which simplifies the \nprocess of making agents operational. Once developed, agents can be deployed as watsonx.ai AI services, which effectively turn them into API endpoints that can be accessed by various applications and systems. This streamlined workflow reduces time-to-market and helps ensure that agents can be quickly integrated into enterprise operations.\nTo further enhance the functions of agents, wats onx.ai offers an extensive Tool Library of \nenterprise-ready tools that are designed to a ugment the capabilities of agents. The tools are \ndivided into the following categories:\n/SM590000Web Search\n/SM590000Document Search (RAG)\n/SM590000Code Execution\n/SM590000Data Connectors\n/SM590000Custom Tool Builder\nFor example, the Web Search tool empowers age nts to perform real-time internet searches, \nwhich provide them with up-to-date information to enhance their decision-making and responses. T", "metadata": {"source": "sg248574.pdf", "chunk_index": 279, "total_chunks": 313}}
{"text": "s, \nwhich provide them with up-to-date information to enhance their decision-making and responses. The ability to access  fast and relevant search results helps ensure that agents \nremain informed and capable of handling dynamic queries.\n\n\nChapter 6. Artificial intelligence agents 103Another critical component of the Tool Library is the Document Search function, which uses \nRAG. This tool enables agents to efficiently index and retrieve documents from an organization\u2019s knowledge base, which helps ensure that they can deliver accurate and context-aware responses. By leveraging RAG, agents can access vast amounts of information and distill it into  actionable insights, which makes them invaluable for \nknowledge-intensive tasks. \nThe Tool Library also includes a Code Execution feature, which enables agents to run Python \ncode in real time. This capability opens up a wide range of possibilit ies, from performing \ncomplex calculations to automati ng repetitive tasks. By integrat ing this fe", "metadata": {"source": "sg248574.pdf", "chunk_index": 280, "total_chunks": 313}}
{"text": " ies, from performing \ncomplex calculations to automati ng repetitive tasks. By integrat ing this feature, agents can \noperate as dynamic problem solvers that can adapt to various scenarios. \nData accessibility is another co rnerstone of the watsonx.ai a gentic framework. With Data \nConnectors, agents can seamlessly interact with enterprise databases and data warehouses, which grant them access to critical organizatio nal data. This tool helps ensure that agents \noperate with a comprehensive understanding of the business context, which enables more informed and effective decision-making. \nThe Tool Library supports the creation of custom tools so that organizations can extend the \nfunctions of their agents by integrating them with external services and unique enterprise systems. This level of customizat ion helps ensure that agents can meet the specific demands \nof any organization.\nDeployment is a critical phase in the lifecycle of any AI system, and watsonx.ai provides a \nrobust, fram", "metadata": {"source": "sg248574.pdf", "chunk_index": 281, "total_chunks": 313}}
{"text": "yment is a critical phase in the lifecycle of any AI system, and watsonx.ai provides a \nrobust, framework-neutral solution for deploying agents. The deployment process is scalable, secure, and highly available, which helps ensure that agents can meet the demands of enterprise-scale operations. Whether an organiza tion requires a single agent for a specific \ntask or a fleet of agents to ha ndle complex workflows, the wa tsonx.ai deployment capabilities \ncan handle the challenge. Once deployed, th e performance and reliabilit y of agents must be \nmonitored to ensure that they operate as intended. watsonx.ai includes comprehensive \nmonitoring tools that track key performance in dicators (KPIs) and analyze logs. These tools \nprovide valuable insights into agent behavior, wh ich enable developers and administrators to \nidentify areas for improvement and help ensure that agents deliver optimal results. \nwatsonx.ai emphasizes transparency  and explainability, which are crucial for building tr", "metadata": {"source": "sg248574.pdf", "chunk_index": 282, "total_chunks": 313}}
{"text": " results. \nwatsonx.ai emphasizes transparency  and explainability, which are crucial for building trust in \nAI systems. By offering detailed explanations of agent decisions and actions, the platform \nhelps organizations maintain compliance with regulatory requirements and ethical standards.\nLooking to the future, watsonx.ai is poised to introduce the Flows Engine, which is a \nlightweight agentic framework and tool-building pl atform that will fu rther enhance the \ncapabilities of the platform. The Flows Engine will enable developers to rapidly build custom \ntools and integrate them with en terprise IT systems, which will provide unparalleled flexibility. \nThis framework is designed to facilitate reason ing and complex decision-making, which will \nmake agents more effect ive in handling intricat e tasks. Also, the Flows Engine will include a \nchat UI widget that can be easily inte grated into thir d-party applications, which will enable \nseamless AI-mediated interactions.\n\n104 Simplify ", "metadata": {"source": "sg248574.pdf", "chunk_index": 283, "total_chunks": 313}}
{"text": "into thir d-party applications, which will enable \nseamless AI-mediated interactions.\n\n104 Simplify Your AI Journey: Unleashing the Power of AI with IBM watsonx.aiComplementing watsonx.ai is IBM watsonx Orchestrate, which is a platform that focuses on \nstarting AI assistants and agents for business processes and task automation (Figure 6-9). By combining the capab ilities of watsonx.ai and watsonx Orchestrate, organizations can \nachieve end-to-end automation to streamline operations and drive efficiency across their \nworkflows. This synergy highlights IBM\u2019s commitment to providing comprehensive AI solutions that address the divers e needs of modern enterprises.\nFigure 6-9   Overview of watsonx  Orchestrate for Agents capabilities\nThe integration of watsonx Orchestrate and watsonx.ai offers an advanced, enterprise-grade \nframework that enhances agentic support by uniting robust autom ation, intelligent workflows, \nand conversational AI capabilitie s. watsonx Orchestrate function s as a ", "metadata": {"source": "sg248574.pdf", "chunk_index": 284, "total_chunks": 313}}
{"text": "n, intelligent workflows, \nand conversational AI capabilitie s. watsonx Orchestrate function s as a supervisory agent that \nleverages LLMs to coordinate interactions ac ross customers, employees, subject matter \nexperts (SMEs), and applications. By employin g Skills Studio, watsonx Orchestrate enables \nthe discovery, creation, and management of gen AI and digital automations by combining tasks, workflows, and skills to drive seamless operational efficiency. Skills and automations \ncan be trained and published in to a comprehensive skills catalo g, which includes prebuilt \nintegrations with enterprise so lutions such as SAP, Salesfor ce, and ServiceNow, to help \nensure compatibility wit h diverse enterprise systems. Si multaneously, watsonx.ai powers \nintelligent AI assistants, enabling conversational experiences that feature advanced functions like slot filling, LLM rout ing, disambiguation, and digression s. This combinat ion helps ensure \npersonalized and context-aware interactions. ", "metadata": {"source": "sg248574.pdf", "chunk_index": 285, "total_chunks": 313}}
{"text": "ion, and digression s. This combinat ion helps ensure \npersonalized and context-aware interactions. Together, watsonx Orchestrate and watsonx.ai establish a scalable ecosystem to enable enterprises to simplify complex processes, reduce operational bottlenecks, and deliver intuitive, guided experiences that align AI-driven solutions with business objectives in a dyna mic, flexible, and secure manner.\nBecause of these agentic frameworks on watsonx.ai that are combined with watsonx \nOrchestrate, you can use advanced assistants that can perform many types of tasks.\nFigure 6-10 on page 105 provides a comprehens ive depiction of Assistants with Agents on \nwatsonx, which shows the integration of wats onx.ai and watsonx Orchestrate to enable \nsophisticated AI-driven solutions for enterprise workflows.\n\n\nChapter 6. Artificial intelligence agents 105Figure 6-10   Assistant with Agents that use wats onx.ai and watsonx Orchestr ate for agentic use cases\nAt the core of this design is the concept of", "metadata": {"source": "sg248574.pdf", "chunk_index": 286, "total_chunks": 313}}
{"text": "s onx.ai and watsonx Orchestr ate for agentic use cases\nAt the core of this design is the concept of a unified, intelligent a ssistant framework that \ncombines modularity, scalabilit y, and precision to deliver seamless experiences across \ndiverse use cases and tasks. Each component in Figure 6-10 plays a critical role in orchestrating complex interactions between users, agents, tools, and workflows, which create a robust and adaptable ecosystem for AI-powered operations. \nAt the top of the architecture is the Unified As sistant, which serves as the single, user-facing \ninterface. This layer is designed to provide a consistent and coherent interaction experience \nby simplifying user engagement and abstracting the complexities of the underlying system. The Unified Assistant is supported by the Supervisory AI Meta-Agent, which is a central coordinator that facilitates all workflows and he lps ensure that user requests ar e processed \naccurately and efficiently. The meta-agent acts as the", "metadata": {"source": "sg248574.pdf", "chunk_index": 287, "total_chunks": 313}}
{"text": "lps ensure that user requests ar e processed \naccurately and efficiently. The meta-agent acts as the brain of the system by orchestrating the activities of multiple subordi nate agents and tools to  fulfill user intents.  Its responsibilities \ninclude routing tasks to the appropriate agents, resolving ambiguities in user input, starting the necessary tools, reasoning through multi-step problems, and planning actions to achieve outcomes. These capabilities are made possible by the integratio n of LLMs that  are powered \nby watsonx.ai, which provides the advanced natural language understanding, contextual awareness, and reasoning ab ilities that are needed for high-quality interactions.\n\n\n106 Simplify Your AI Journey: Unleashing the Power of AI with IBM watsonx.aiBeneath the Supervisory AI Meta-Agent lies a network of specialized assistants that are \nlabeled as Assistant 1, Assistant 2, and so on, which represents a modular and scalable approach to task execution. Each assistant is tailo", "metadata": {"source": "sg248574.pdf", "chunk_index": 288, "total_chunks": 313}}
{"text": "d so on, which represents a modular and scalable approach to task execution. Each assistant is tailored to handle specific domains or functions, \nand they operate autonomously while contributing to the overall system. These assistants are designed to run actions independently, and they leverage the power of LLMs for NLP, multi-turn conversations, and decision-making.  This autonomy enables them to reduce \nmanual intervention so that organizations can achieve higher levels of efficiency and \nproductivity. The assistants also facilitate user  interactions by maintaining context, \nunderstanding intent, and responding dy namically to evolving requirements. \nA defining feature of this architecture is its reliance on tool calling, which forms the backbone \nof the system\u2019s operational fl exibility and extensibility. Figu re 6-10 on page 105 emphasizes \nthe integration of various categories of tools that the agents can call to complete tasks. These tools include fixed flows for handling repeti", "metadata": {"source": "sg248574.pdf", "chunk_index": 289, "total_chunks": 313}}
{"text": "ools that the agents can call to complete tasks. These tools include fixed flows for handling repetitive and standardized operations; knowledge repositories for answering questions and providing insights; APIs for interacting with external systems; business automation modules for streamlining enterprise processes; and multi-agent frameworks for coordinating complex tasks that require collaboration among several AI agents. The usage of LLM-based tool calling helps ensure that the system can adapt to various workflows, which enables interoperability with existing IT infrastructures and third-party applicat ions. watsonx.ai enhances th is capability through its extensive Tool Library, \nwhich includes features such as RAG for knowledge discovery; real-time Python code execution for computational tasks; and seamless data connectors for integrating with enterprise databases and services. Custom tools can also be developed and incorporated, which enable organizations to tailor the system to t", "metadata": {"source": "sg248574.pdf", "chunk_index": 290, "total_chunks": 313}}
{"text": "m tools can also be developed and incorporated, which enable organizations to tailor the system to their unique needs and challenges.\nThe bottom part of Figure 6-10 on page 105 im plicitly connects to watsonx Orchestrate, \nwhich is the IBM platform for deploying and managing AI-driven workflows. By leveraging \nwatsonx Orchestrate, this archit ecture gains enterprise-grade ca pabilities for task automation, \ngovernance, and monitoring. This integration enables organizations to deploy AI assistants quickly and securely, with the ab ility to scale the system as the number of tasks , agents, and \nintegrations grows. Security and compliance ar e also ensured, which addresses the stringent \nrequirements of enterprise environments. The orchestration layer further optimizes performance by streamlining the deployment and management of agents, which minimizes operational overhead while maximizing system reliability.\nThe overall interaction flow in Figure 6-10 on page 105 begins with the user eng", "metadata": {"source": "sg248574.pdf", "chunk_index": 291, "total_chunks": 313}}
{"text": "system reliability.\nThe overall interaction flow in Figure 6-10 on page 105 begins with the user engaging with the \nUnified Assistant. The user\u2019s input is processed by the Supervisory AI Meta-Agent, which applies its routing, reasoning, and tool-calling capabilities to determine the be st course of \naction. Then, tasks are delegated to the appropriate assistants, which run them autonomously by using the integrated tools and workflows. The outputs and actions from these assistants are aggregated by the meta-agent and presented to the user, which helps ensure a cohesive and intuitive experience. This flow highlight s the system\u2019s ability to handle \ndiverse and complex tasks while maintaining a si mple interface.\nIn conclusion, watsonx.ai agents represent a revolutionary approach to enterprise AI by \noffering a powerful combination of flexibility, function, and scala bility. From the intuitive Agent \nBuilder to the expansive Tool Library and fo rthcoming innovations like the Flows Engine,", "metadata": {"source": "sg248574.pdf", "chunk_index": 292, "total_chunks": 313}}
{"text": "ive Agent \nBuilder to the expansive Tool Library and fo rthcoming innovations like the Flows Engine, \nwatsonx.ai empowers businesses to create intelligent agents that drive productivity and \ninnovation. By leveraging th ese advanced capabilit ies, organizations can harness the full \npotential of AI to achieve their strategic goals and maintain a competitive edge in an increasingly digital world.\n\nChapter 6. Artificial intelligence agents 1076.5  AI agents use case examples\nAI agents are redefining the landscape of business operations and service delivery by \nunlocking unprecedented efficiencies and enabling more personalized, data-driven decision-making. Across  industries, these inte lligent systems ha ve found applications in \nareas such as customer service and support, sales and marketing automation, operational efficiency, financial advisory, healthcare, and supply chain management. \nThe following sections provide a detailed exploration of select use cases, and highlight their \nimp", "metadata": {"source": "sg248574.pdf", "chunk_index": 293, "total_chunks": 313}}
{"text": "\nThe following sections provide a detailed exploration of select use cases, and highlight their \nimpact and capabilities.\nCustomer service and support agents AI agents\nAI agents are revolutionizing customer service by offering continuous assistance. By using \ntools like watsonx.ai Web Search and Document Search (powered by RAG), these agents provide timely and accurate responses to customer inquiries. By leveraging NLP and ML, they can understand context, resolve issues, and e scalate complex cases to human agents when \nnecessary. For example, chatbots that are built by using watsonx.ai Agent Builder can be deployed as API endpoints to handle FAQs, help with troubleshooting, and manage order tracking. These agents help ensure instant support while reducing operational costs, improving customer satisfaction, and fostering loyalty.\nSales and marketing automation\nAI agents are indispensable tools in sales and marketing, where personalization and timely interactions drive success. Powered ", "metadata": {"source": "sg248574.pdf", "chunk_index": 294, "total_chunks": 313}}
{"text": " tools in sales and marketing, where personalization and timely interactions drive success. Powered by watsonx.ai Data Connectors, agents can analyze customer behavior, qualify leads, and deliver tailored recommendations. By automating follow-ups and dynamically adjusting strategies  by using real-time insights, these agents \nenhance engagement and drive conversions. For example, e-commerce platforms can use watsonx.ai agents to suggest personalized items, send promotional offers, and re-engage customers who abandon carts. Such integrations help businesses maximize revenue potential while delivering highly customized customer experiences.\nOperational efficiency and process automation\nAutomating repetitive and rout ine tasks is a hallmark of AI a gents, and watsonx.ai provides \nthe tools to optimize these processes. By using the Code Execution capa bility, agents can run \nPython scripts in real time to process data, verify documents, or automate workflows. Beyond task automation, these ", "metadata": {"source": "sg248574.pdf", "chunk_index": 295, "total_chunks": 313}}
{"text": "n real time to process data, verify documents, or automate workflows. Beyond task automation, these agents can monitor work flows, identify bottle necks, and recommend \nimprovements. For example, administrative tasks like employee onboarding can be fully automated with watsonx.ai by processing documentation, setting up accounts, and scheduling orientation sessions, which free employees to focus on more strategic responsibilities.\nHealthcare assistants and patient care\nIn healthcare, AI agents improve patient care an d operational efficiency by acting as virtual \nassistants. By integrating with watsonx.a Tool Library and leveraging custom tools, these agents can manage schedules, send medication reminders, and provide basic medical guidance. For example, telemedicine platforms can deploy agents to conduct preliminary symptom checks, monitor health metrics such as heart rate or blood pressure, and alert providers to abnormalities. These capabilities reduce the workload on healthcare staf", "metadata": {"source": "sg248574.pdf", "chunk_index": 296, "total_chunks": 313}}
{"text": "ure, and alert providers to abnormalities. These capabilities reduce the workload on healthcare staff while ensuring proactive and timely patient care, which enhances outcomes and satisfaction.\n\n108 Simplify Your AI Journey: Unleashing the Power of AI with IBM watsonx.aiSupply chain and logistics optimization\nAI agents are transforming supply chain management by combining real-time data with \npredictive analytics. Tools like watsonx.ai Data Connectors enable agents to forecast demand, manage inventory, and plan delivery routes effectively. Logistics companies can leverage these capabilities to analyze historical  patterns, predict future needs, and maintain \noptimal stock levels. Also, AI-driven route optimization, when informed by traffic and weather data, helps ensure timely deliveries and reduces costs. With watsonx.ai, organizations can build scalable, secure agents that streamline supply chain operations, which enhance both \nefficiency and customer satisfaction.\n\n\u00a9 Copyright IBM C", "metadata": {"source": "sg248574.pdf", "chunk_index": 297, "total_chunks": 313}}
{"text": "upply chain operations, which enhance both \nefficiency and customer satisfaction.\n\n\u00a9 Copyright IBM Corp. 2025. 109Chapter 7. Use cases\nThis chapter describes two separate use cases and shows what problems IBM watsox.ai \ntools can solve. It also describes a framework that outlines how companies who are trying to \nprepare for the future are thinking about use cases of the future to keep ahead of the curve.\nThe following topics are described in this chapter:\n/SM5900007.1, \u201cUsing RAG to aid a medical school admissions office\u201d on page 110\n/SM5900007.2, \u201cEmbedding workflow automation to streamline recommendations\u201d on page 1117\n\n110 Simplify Your AI Journey: Unleashing the Power of AI with IBM watsonx.ai7.1  Using RAG to aid a medi cal school admissions office\nAs a quick refresher, Retrieval-Augmented Generation (RAG) is a technique that combines \ninformation retrieval and language model generation to provide precise and contextually relevant responses to user queries. It works by first retri", "metadata": {"source": "sg248574.pdf", "chunk_index": 298, "total_chunks": 313}}
{"text": "tion to provide precise and contextually relevant responses to user queries. It works by first retrieving relevant documents or \npassages from a large corpus of documents by using a retrieval step, and then feeds these passages along with the original query into a large language model (LLM) to generate a response.\nRAG is one of the most commonly used techniques  that are used in production AI workloads. \nIt is used in various ways, such as in question-answering systems, chatbots, and digital workers. One powerful tool that can be used in these systems is a summary of ingested documents. This section describes how a lead ing medical school in th e US turned to the \nwatsonx.ai platform to enable it to accomplish its goals.\n7.1.1  The challenge\nA leading medical school in the US decides to offer tuition-free education to its admitted students. They anticipated a surge in applications. To help manage the expected increase in applications, the institution turned to wats onx.ai. They hoped t", "metadata": {"source": "sg248574.pdf", "chunk_index": 299, "total_chunks": 313}}
{"text": "lp manage the expected increase in applications, the institution turned to wats onx.ai. They hoped that IBM could provide a \ntechnology solution to help the admissions committee efficiently process and review the incoming applications. \n7.1.2  The solution\nWorking with the medical school, the IBM team developed an innovative solution by using watsonx.ai to generate one-page abstracts that summarized the incoming 50 - 70-page applications. The incoming applications included essays, with each application containing 5 - 8 essays that varied from several paragraphs to several pages. The IBM granite-13b-chat-v2 model within the watsonx.ai platform was used to generate a 1 - 2 paragraph summary of each of the essays, which was included with the application abstracts.\nFigure 7-1 shows the watsonx.ai workflow that accomplished this task.\nFigure 7-1   watsonx.ai workflow example\n\n\nChapter 7. Use cases 1117.1.3  Special considerations\nFrom the start of this project, both IBM and the medical scho", "metadata": {"source": "sg248574.pdf", "chunk_index": 300, "total_chunks": 313}}
{"text": "cases 1117.1.3  Special considerations\nFrom the start of this project, both IBM and the medical school recognized the importance of \ndeveloping a solution that met the institution's needs and aligned with IBM AI Ethics. The usage of AI in the admissions process raised important ethical considerations, such as helping ensure fairness , transparency, and acc ountability. The goal was to create a system \nthat would augment human decision-making rather than replace it, and provide the admissions committee with the tools that they  needed to make informed decisions.\nThe project incorporated a range of both technical and non-technical guardrails to address AI \nethics considerations throughout the project lifecycle:\n/SM590000Augmenting human decision making: The solution was designed to support human \ndecision-makers, and not replace them. The AI-powered pipeline generated summaries and identified key information, but all decisions remained in the hands of humans.\n/SM590000Education and train", "metadata": {"source": "sg248574.pdf", "chunk_index": 301, "total_chunks": 313}}
{"text": "ied key information, but all decisions remained in the hands of humans.\n/SM590000Education and training: The IBM team provided ongoing education and training on AI to \nboth technical and business users to help ensure that everyone that was involved in the project understood the ca pabilities and limitations  of the technology.\n/SM590000Thresholds and AI notices: The team im plemented technical guardrails by using \nwatsonx.governance to detect and prevent potential biases or errors in the system.\n/SM590000Feedback mechanism: The IBM team establishe d a continuous feedback loop with the \nclient to refine and improve the solution over time.\nBy considering these guardrails from the beginning, the project was able to meet the \ninstitutions needs while aligning to their governance frameworks regarding fairness, transparency, and accountability. It also limited the school\u2019s risk exposure and reduced the \nlikelihood of having to redesign the system to incorporate new safeguards because decisio", "metadata": {"source": "sg248574.pdf", "chunk_index": 302, "total_chunks": 313}}
{"text": "duced the \nlikelihood of having to redesign the system to incorporate new safeguards because decision points were integrated from the start.\n7.2  Embedding workflow automation to streamline \nrecommendations\nThis use case describes at how workflow automation can lead to directly addressing the \nwants and needs of a financial institution, and act as a potential opportunity pipeline for the banks serving their customers.\n7.2.1  The challenge\nSmall local and regional banks, especially ones serving customers in more rural settings, \noften face different challenges than the large banks that service most of the total addressable market. Some of these challenges are self-e vident, such as having comparatively limited \naccess to capital, but other challenges are less apparent, such as an increased need to rely on low- and no-code solutions to maintain technological parity with the custom-built \napplications that are designed and managed by large centralized IT teams that are staffed by larger f", "metadata": {"source": "sg248574.pdf", "chunk_index": 303, "total_chunks": 313}}
{"text": "pplications that are designed and managed by large centralized IT teams that are staffed by larger finance institutions.\nFor one of these banks servicing rural clients in  the Midwest region of the US, they wanted to \naddress some of the market trends they read about in 5 banking customer experience trends \nto consider for 2024 , with a specific focus on providing customers with immediate service and \npersonalized recommendations. \n\n112 Simplify Your AI Journey: Unleashing the Power of AI with IBM watsonx.aiIn these rural settings, it is often difficult fo r a bank\u2019s customer base to travel to the nearest \nbranch, and at specific times of the year, the journey takes time away from their responsibilities at farms, ranche s, and processing centers, whic h directly impacts their annual \nincome. \n7.2.2  The solution\nBy leveraging a collection of tools, this regional bank was able to build a solution that incorporated three IBM tools to reduce friction with its users while leveraging largel", "metadata": {"source": "sg248574.pdf", "chunk_index": 304, "total_chunks": 313}}
{"text": "solution that incorporated three IBM tools to reduce friction with its users while leveraging largely pre-built skills and solutions. The soluti on centered on a watsonx Orc hestrate business automation \napplication that takes in loan applications and responds to the loan applicant with near-real-time approval or rejection notices based on thresholds that are set by the bank.\nFigure 7-2 shows the watsonx Orchestrate workflow that was used in this use case.\nFigure 7-2   watsonx Orchestrate workflow example\nCustomers connected to the bank through IBM watsonx Assistant, which leveraged an IBM \nLLM to initiate a natural language dialog with the client and collect various loan application documents, which included custom forms that are specific to this bank. These documents were passed from watsonx Assistant to watsonx Orchestrate, which called on several of its prebuilt skills, and custom skills  that were developed in the Skills Studio feature to access \nadditional services outside of th ", "metadata": {"source": "sg248574.pdf", "chunk_index": 305, "total_chunks": 313}}
{"text": "ills  that were developed in the Skills Studio feature to access \nadditional services outside of th e bank (such as credit reports). \nAfter running through a decision tree based on the inputs, the client received an approval or \nrejection notification. In either case, the notice was sent back to the applicant through a custom-generated response that was tailored by watsonx.ai and specific to that customer, with an explanation of the decision based on that customer\u2019s specific application. Furthermore, the bank leveraged its own client knowledge to augment the loan decision with additional offers or suggestions to the customer based on their specific customer profile. For those customers that applied for an automotive loan and had a mortgage and business account with the bank, the bank suggested that they sign up for a wealth management account that was serviced by the bank. For th ose customers who applied for a small business \nloan who did not have a checking or savings account that wa", "metadata": {"source": "sg248574.pdf", "chunk_index": 306, "total_chunks": 313}}
{"text": "tomers who applied for a small business \nloan who did not have a checking or savings account that was associated with the EIN on the application, the bank suggested that they open a full suite of business accounts with the loan. These examples pu lled on watsonx.ai gene rative capabilities to create personalized \nrecommendations based on individual customers rather than \u201cone-size-fits-all\u201d templates that are applied as a blanket policy to all applicatio ns. Holistically, this entire solution can be \nsummarized as an AI agent. \n\n\nChapter 7. Use cases 1137.2.3  Special considerations\nWith a smaller workforce to dedicate to this solution and limited previous AI experience, the \nbank leveraged existing tools to reduce the workload and expertise requirements on the bank\u2019s workforce. This approach was one of the key reasons IBM and the client focused on \nleveraging watsonx Orchestrate over designing a custom application that integrated AI tools \nthrough API calls. Instead of building a solut", "metadata": {"source": "sg248574.pdf", "chunk_index": 307, "total_chunks": 313}}
{"text": "igning a custom application that integrated AI tools \nthrough API calls. Instead of building a solution, the bank relied on built-in AI functions that automatically combined pre- packaged skills dynamically  and in-context based on \norganizational knowledge and prior interactions to help workers design the workflow of their application. Users prov ided natural language in puts to select and sequ ence the required skills \nfor a task, and watsonx Orchestrate connected them with the associated applications, tools, data, and historical details. This approach enabled the team to automate processes without needing highly specialized IT skills or ex pert knowledge of business processes and \napplications.\n\n114 Simplify Your AI Journey: Unleashing the Power of AI with IBM watsonx.ai\n\n\u00a9 Copyright IBM Corp. 2025.  115AI artificial intelligence\nAIaaS AI as a Service\nBYOM Bring Your Own Model\nCLI command-line interface\nCNN convolutional neural network\nDL deep learning\nDQN Deep Q-Network\nESG environ", "metadata": {"source": "sg248574.pdf", "chunk_index": 308, "total_chunks": 313}}
{"text": "mand-line interface\nCNN convolutional neural network\nDL deep learning\nDQN Deep Q-Network\nESG environmental, social, and \ngovernance\nFM foundation model\ngen AI Generative AI\nIBM International Business Machines \nCorporation\nKNN k-nearest neighbor\nKPI key performance indicator\nLLM large language model\nLLMOps large language model operations \nLoRA low-rank adaptation\nMAS multi-agent system\nMDP Markov decision processes\nML machine learning\nMLOps machine learning operations\nMMLU Massive Multitask Language \nUnderstanding\nNLP natural language processing\nPCA Principal Component Analysis\nQLoRA quantized low-rank adaptation\nRAG Retrieval-Augmented Generation\nRL reinforcement learning\nRNN recurrent neural network\nRPA Robotic Process Automation\nSaaS Software-as-a-Service\nSDG synthetic data generation\nSME subject matter expert\nUI user interfaceAbbreviations and acronyms\n\n116 Simplify Your AI Journey: Unleashing the Power of AI with IBM watsonx.ai\n\n\u00a9 Copyright IBM Corp. 2025. 117Related publications\nT", "metadata": {"source": "sg248574.pdf", "chunk_index": 309, "total_chunks": 313}}
{"text": "nleashing the Power of AI with IBM watsonx.ai\n\n\u00a9 Copyright IBM Corp. 2025. 117Related publications\nThe publications that are listed in this section are considered suitable for a more detailed \ndescription of the topics that are covered in this book.\nIBM Redbooks\nThe following IBM Redbooks publications provid e additional information about the topics in \nthis document. Some publications that are refere nced in this list might be available in softcopy \nonly. \n/SM590000Simplify Your AI Journey: Ensuring Trustworthy AI with IBM watsonx.governance , \nSG24-8573\n/SM590000Simplify Your AI Journey: Unleashing the Power of AI with IBM watsonx.data , SG24-8570\nYou can search for, view, download, or order these documents and other Redbooks, \nRedpapers, web docs, drafts, and addition al materials, at the following website: \nibm.com/redbooks\nOnline resources\nThese websites are also relevant as further information sources:\n/SM590000Code samples of common machine learning scenarios:\nhttps://github.com", "metadata": {"source": "sg248574.pdf", "chunk_index": 310, "total_chunks": 313}}
{"text": " information sources:\n/SM590000Code samples of common machine learning scenarios:\nhttps://github.com/IBM/watson-machine-learning-samples\n/SM590000Examples of using Instructlab and AI agents:\nhttps://github.com/IBM/watsonx-ai-platform-demos\n/SM590000IBM AI risk atlas\nhttps://www.ibm.com/docs/en/watsonx/w-and-w/2.1.x?topic=ai-risk-atlas\n/SM590000IBM watsonx documentation (Includes links to all watsonx products)\nhttps://www.ibm.com/docs/en/watsonx\n/SM590000IBM watsonx.governance product\nhttps://www.ibm.com/products/watsonx-governance\n/SM590000IBM watsonx product portfolio\nhttps://www.ibm.com/watsonx\n\n118 Simplify Your AI Journey: Unleashing the Power of AI with IBM watsonx.aiHelp from IBM\nIBM Support and downloads\nibm.com/support\nIBM Global Services\nibm.com/services\n\n(0.2\u201dspine)\n0.17\u201d<->0.473\u201d\n90<->249 pagesSimplify Your AI Journey: Unleashing the Power of AI with IBM watsonx.ai\n\n\n\n\n\nibm.com /redbooksPrinted in U.S.A .Back cover\nISBN 0738461989SG24-8574-00\n\u00ae\n\n", "metadata": {"source": "sg248574.pdf", "chunk_index": 311, "total_chunks": 313}}
{"text": "m /redbooksPrinted in U.S.A .Back cover\nISBN 0738461989SG24-8574-00\n\u00ae\n\n", "metadata": {"source": "sg248574.pdf", "chunk_index": 312, "total_chunks": 313}}

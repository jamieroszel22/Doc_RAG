{"text": "RedbooksFront cover\nIBM Hyper Protect Platform:\nApplying Data Protection and Confidentiality\nin a Hybrid Cloud Environment\nBill White\nRobbie AvillSandeep BattaAbhiram KulkarniTimo Ku\u00dfmaulStefan LiescheNicolas M\u00e4dingChristoph Schlameu\u00dfPeter Szmrecs\u00e1nyi\n\n\n\nIBM Redbooks\nApplying Data Protection and Confidentiality in a \nHybrid Cloud Environment\nFebruary 2024\nSG24-8555-00\n\n\u00a9 Copyright International Bu siness Machines Corp oration 2024. All rights reserved.\nNote to U.S. Government Users Restricted Rights -- Use, duplication or disclosure re stricted by GSA ADP Schedule\nContract with IBM Corp.First Edition (February 2024)\nThis edition applies to the IBM z15, IBM z16, IBM LinuxONE III, IBM LinuxONE 4, and IBM Hyper Protect \nPlatform Second Generation.Note: Before using this information and the product it supports, read the information in \u201cNotices\u201d on \npage ix.\n\n  iii\n\niv Applying Data Protection and Confidentiality in a Hybrid Cloud Environment\n\n\u00a9 Copyright IBM Corp. 2024. vContents\nNotices  ", "metadata": {"source": "sg248555.pdf", "chunk_index": 0, "total_chunks": 337}}
{"text": "n and Confidentiality in a Hybrid Cloud Environment\n\n\u00a9 Copyright IBM Corp. 2024. vContents\nNotices  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . vii\nTrademarks  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . viii\nPreface  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ix\nAuthors. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .x\nNow you can become a published author, too!  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . xi\nComments welcome. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . xii\nStay connected to IBM Redbooks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ", "metadata": {"source": "sg248555.pdf", "chunk_index": 1, "total_chunks": 337}}
{"text": " . xii\nStay connected to IBM Redbooks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . xii\nChapter 1.  A hybrid cloud with data security in mind . . . . . . . . . . . . . . . . . . . . . . . . . . . 1\n1.1  Identifying the threat . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  . . 2\n1.2  Beyond regulatory and standard frameworks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3\n1.3  Mitigating the threat. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  . . 4\n1.3.1  Technical assurance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4\n1.3.2  A Trusted Execution Environment for your application . . . . . . . . . . . . . . . . . . . . . . 5\n1.3.3  Reduced trust boundary and trusted computing base  . . . . . . . . . . . . . . . . . . . . . . 61.3.4  Controlling your application wi ", "metadata": {"source": "sg248555.pdf", "chunk_index": 2, "total_chunks": 337}}
{"text": "computing base  . . . . . . . . . . . . . . . . . . . . . . 61.3.4  Controlling your application wi th separation of duty . . . . . . . . . . . . . . . . . . . . . . . . 6\n1.3.5  Exclusive and full control over your cryptographic key . . . . . . . . . . . . . . . . . . . . . . 7\n1.3.6  Support for your application OCI images  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 71.3.7  Support for hybrid cloud . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7\n1.4  The solution explained  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  7\n1.4.1  The technology underlying the Hyper Protect Platform. . . . . . . . . . . . . . . . . . . . . . 81.4.2  Features of the Hyper Protect Platform. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10\n1.4.3  Cryptography and Hyper Protect Crypto Service . . . . . . . . . . . . . . . . . . . . . . . . . 13\n1.4.4  Hyper Protect Secure", "metadata": {"source": "sg248555.pdf", "chunk_index": 3, "total_chunks": 337}}
{"text": "tect Crypto Service . . . . . . . . . . . . . . . . . . . . . . . . . 13\n1.4.4  Hyper Protect Secure Build. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14\nChapter 2.  Understanding the solution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15\n2.1  IBM Hyper Protect services and a secure hybrid cloud. . . . . . . . . . . . . . . . . . . . . . . . . 16\n2.2  IBM Cloud Virtual Private Cloud . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18\n2.2.1  IBM Cloud virtual server instance on IBM LinuxONE . . . . . . . . . . . . . . . . . . . . . . 18\n2.3  Hyper Protect Virtual Server . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18\n2.3.1  Bootloader. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19\n2.3.2  Volume encryption  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ", "metadata": {"source": "sg248555.pdf", "chunk_index": 4, "total_chunks": 337}}
{"text": " . 19\n2.3.2  Volume encryption  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 192.3.3  Description of the contract  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20\n2.3.4  The attestation record . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21\n2.3.5  Logging . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  21\n2.3.6  Hyper Protect layer services . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21\n2.3.7  Hyper Protect Virtual Server for VPC . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22\n2.3.8  Hyper Protect Virtual Server for IBM LinuxONE and IBM Z . . . . . . . . . . . . . . . . . 232.3.9  Considerations when deploying workloads in HPVS instances  . . . . . . . . . . . . . . 23\n2.4  Hyper Protect Secure Build. . . . . . . . . . . . . ", "metadata": {"source": "sg248555.pdf", "chunk_index": 5, "total_chunks": 337}}
{"text": " instances  . . . . . . . . . . . . . . 23\n2.4  Hyper Protect Secure Build. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24\n2.5  Cryptographic agility is the key to SecDevOps . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25\n2.6  Hyper Protect Crypto Services . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25\n2.6.1  Accessing cryptographic services with HPCS. . . . . . . . . . . . . . . . . . . . . . . . . . . . 26\n2.7  Crypto Express Network API for Secure Execution Enclaves. . . . . . . . . . . . . . . . . . . . 28\n2.7.1  Security considerations. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29\n2.8  Storage and repositories in the cloud . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29\n2.8.1  Cloud object storage . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 292.8.2  Blo", "metadata": {"source": "sg248555.pdf", "chunk_index": 6, "total_chunks": 337}}
{"text": ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 292.8.2  Block storage  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30\n\nvi Applying Data Protection and Confidentiality in a Hybrid Cloud Environment2.8.3  File storage . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30\n2.8.4  On-premises storage  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30\n2.9  Common usages . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3 1\n2.9.1  Securely bring applications to hybrid cloud. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 312.9.2  Digital assets infrastructure. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 32\n2.9.3  Confidential AI. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .", "metadata": {"source": "sg248555.pdf", "chunk_index": 7, "total_chunks": 337}}
{"text": ". . . . . . . 32\n2.9.3  Confidential AI. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3 3\n2.9.4  Secure multi-party computation  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 342.9.5  Secure distributed cloud . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35\nChapter 3.  Making the infrastructure secure  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 37\n3.1  The contract  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  . . 38\n3.1.1  The workload section  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39\n3.1.2  The workload volumes subsection . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 463.1.3  The env section. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ", "metadata": {"source": "sg248555.pdf", "chunk_index": 8, "total_chunks": 337}}
{"text": ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 47\n3.2  Contract encryption . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  49\n3.3  Contract certificates  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 53\n3.4  Attestation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  . . . 54\n3.5  Logging for HPVS instances . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 56\n3.6  Encrypting data volumes. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 63\nChapter 4.  Application development in a trusted environment  . . . . . . . . . . . . . . . . . . 65\n4.1  Securing the application lifecycle  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 66\n4.1.1  Develo", "metadata": {"source": "sg248555.pdf", "chunk_index": 9, "total_chunks": 337}}
{"text": "  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 66\n4.1.1  Development. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 67\n4.1.2  Test . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 67\n4.1.3  Build  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 67\n4.1.4  Release. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  68\n4.1.5  Deployment. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 68\n4.1.6  Update  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  68\n4.1.7  Application and service development . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 69\n4.1.8  Wo", "metadata": {"source": "sg248555.pdf", "chunk_index": 10, "total_chunks": 337}}
{"text": "service development . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 69\n4.1.8  Working with the log . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 69\n4.1.9  Deployment automation - Terraform . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 70\n4.2  Build container image by using Hyper Protect Secure Build. . . . . . . . . . . . . . . . . . . . . 71\n4.2.1  Determine readiness. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 71\n4.2.2  Install the secure build CLI . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 72\n4.2.3  Create client and server certificates for secure build  . . . . . . . . . . . . . . . . . . . . . . 72\n4.2.4  Prepare user_data.yaml . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 734.2.5  Create the Hyper Protect Secure Build instance. . . . . . . . . . . . . . . . . ", "metadata": {"source": "sg248555.pdf", "chunk_index": 11, "total_chunks": 337}}
{"text": " . . . . . 734.2.5  Create the Hyper Protect Secure Build instance. . . . . . . . . . . . . . . . . . . . . . . . . . 74\n4.2.6  Configure the HPSB client with the HPVS IP address . . . . . . . . . . . . . . . . . . . . . 75\n4.3  Zero knowledge proofs: TLS server certificates and wrapped secrets . . . . . . . . . . . . . 78\n4.3.1  Passing secrets into a secure HPVS  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 78\n4.3.2  Certificate benefits  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 78\n4.3.3  Importing server certificate from contract . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 794.3.4  Random number generation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 80\n4.3.5  Reverse proxy. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 83\n4.3.6  Basic web server (nginx) hardening . . . . . . . . . . . . . . . . .", "metadata": {"source": "sg248555.pdf", "chunk_index": 12, "total_chunks": 337}}
{"text": ". . . . . . . . . . . 83\n4.3.6  Basic web server (nginx) hardening . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 844.3.7  Offloading NGINX TLS to HPCS. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 85\n4.4  Trust in-depth based on boot flow attestation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 85\n4.5  Data storage . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  . . 87\n4.5.1  Encrypting block storage. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 87\n4.5.2  Encryption state  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 88\n4.5.3  Upgrade, backup, and disaster recovery  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 914.5.4  High Availability. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9 1\n4.", "metadata": {"source": "sg248555.pdf", "chunk_index": 13, "total_chunks": 337}}
{"text": ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9 1\n4.6  Securing cloud native services . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 92\n\n Contents vii4.6.1  Confidential cluster . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 92\n4.6.2  Confidential containers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 93\n4.6.3  Confidential service platform. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 94\n4.7  Secure supply chain with SLSA  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 95\n4.7.1  Jenkins . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 96\n4.7.2  Source-to-image (S2I). . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 96\n4.7.3  GitHub", "metadata": {"source": "sg248555.pdf", "chunk_index": 14, "total_chunks": 337}}
{"text": ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 96\n4.7.3  GitHub Actions  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 97\nAppendix A.  Client contract setup sample files . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 99\nSample YAML file with literal scalars . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 100\nSample YAML file with double-quoted scalars. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 101\nSample script for certificate or key files . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 103\nAppendix B.  Creating a Hyper Protect Virtual Server for VPC  . . . . . . . . . . . . . . . . . . 107\nUsing the IBM Cloud VPC UI . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 108\nAppendix C.  Additional ex amples for HPSB and HPVS  . . . . . . . . . . . . . . ", "metadata": {"source": "sg248555.pdf", "chunk_index": 15, "total_chunks": 337}}
{"text": " . . . . . . . 108\nAppendix C.  Additional ex amples for HPSB and HPVS  . . . . . . . . . . . . . . . . . . . . . . . 115\nHyper Protect Secure Build log  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 116\nHow to verify disk (volume) encryption with HPL13000I  . . . . . . . . . . . . . . . . . . . . . . . . . . 118\nAppendix D.  Encryption keys explained . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 121\nWhat is a master key (MK). . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 122\nWhat are data encryption keys (DEKs)  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 122\nWhat are key encryption keys (KEKs) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 123\nUsing and protecting keys . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 123How encryption keys are created ", "metadata": {"source": "sg248555.pdf", "chunk_index": 16, "total_chunks": 337}}
{"text": " . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 123How encryption keys are created using GREP11  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 124\n\nviii Applying Data Protection and Confidenti ality in a Hybrid Cloud Environment\n\n\u00a9 Copyright IBM Corp. 2024. ixNotices\nThis information was developed for prod ucts and services offered in the US . This material might be available \nfrom IBM in other languages. However, you may be required  to own a copy of the product or product version in \nthat language in order to access it. \nIBM may not offer the products, services, or features di scussed in this document in other countries. Consult \nyour local IBM representative for information on the produc ts and services currently available in your area. Any \nreference to an IBM product, program, or service is not intended to state or imply that only that IBM product, \nprogram, or service may be used. Any functionally equi valent product, program, or service that does", "metadata": {"source": "sg248555.pdf", "chunk_index": 17, "total_chunks": 337}}
{"text": "program, or service may be used. Any functionally equi valent product, program, or service that does not \ninfringe any IBM intellectual property right may be used instead. However, it is t he user\u2019s responsibility to \nevaluate and verify the operation of any non-IBM product, program, or service. \nIBM may have patents or pending patent applications covering subject matter described in this document. The \nfurnishing of this document does not grant you any license to these patents. You can send license inquiries, in \nwriting, to:\nIBM Director of Licensing, IBM Corporation, North Castle Drive, MD-NC119, Armonk, NY 10504-1785, US \nINTERNATIONAL BUSINESS MACHINES CORPORATIO N PROVIDES THIS PUBLICATION \u201cAS IS\u201d \nWITHOUT WARRANTY OF ANY KIND, EITHER EXPRESS OR IMPLIED, INCLUDING, BUT NOT LIMITED \nTO, THE IMPLIED WARRANTIES OF NON-INFR INGEMENT, MERCHANTABILITY OR FITNESS FOR A \nPARTICULAR PURPOSE. Some jurisdictions do not allow disclaimer of express or implied warranties in \ncertain transactio", "metadata": {"source": "sg248555.pdf", "chunk_index": 18, "total_chunks": 337}}
{"text": ". Some jurisdictions do not allow disclaimer of express or implied warranties in \ncertain transactions, therefore, this statement may not apply to you. \nThis information could include technical inaccuracies or  typographical errors. Changes are periodically made \nto the information herein; th ese changes will be incorporated  in new editions of the publication. IBM may make \nimprovements and/or changes in the product(s) and/or the program(s) described in this publication at any time \nwithout notice. \nAny references in this information to non-IBM websites are provided for convenience only and do not in any \nmanner serve as an endorsement of those websites. The materials at those websites are not part of the \nmaterials for this IBM product and use of those websites is at your own risk. \nIBM may use or distribute any of the information you provide in any way it believes appropriate without \nincurring any obligation to you. \nThe performance data and c lient examples cited are presented fo ", "metadata": {"source": "sg248555.pdf", "chunk_index": 19, "total_chunks": 337}}
{"text": "\nincurring any obligation to you. \nThe performance data and c lient examples cited are presented fo r illustrative purposes only. Actual \nperformance results may vary depending on specific configurations and operating conditions. \nInformation concerning non-IBM products was obtained from the suppliers of those products, their published \nannouncements or other publicly available sources. IBM has not tested those products and cannot confirm the \naccuracy of performance, co mpatibility or any other clai ms related to non-IBM pr oducts. Questions on the \ncapabilities of non-IBM products should be addr essed to the suppliers of those products. \nStatements regarding IBM\u2019s future direction or intent are subject to change or withdrawal without notice, and \nrepresent goals and objectives only. \nThis information contains exam ples of data and reports used in daily business operations. To illustrate them \nas completely as possible, the exam ples include the names of individual s, companies, brand", "metadata": {"source": "sg248555.pdf", "chunk_index": 20, "total_chunks": 337}}
{"text": "e them \nas completely as possible, the exam ples include the names of individual s, companies, brands, and products. \nAll of these names are fictitious and any similarity to  actual people or business enterprises is entirely \ncoincidental. \nCOPYRIGHT LICENSE:\nThis information contai ns sample application prog rams in source language, which illustrate programming \ntechniques on various operating platforms. You may co py, modify, and distribute these sample programs in \nany form without payment to IBM, for the purposes of developing, using, marketing or distributing application programs conforming to the application programming interface for the operating platform for which the sample \nprograms are written. These examples have not been th oroughly tested under all conditions. IBM, therefore, \ncannot guarantee or im ply reliability, serviceability, or function of  these programs. The sample programs are \nprovided \u201cAS IS\u201d, without warranty of any kind. IBM sha ll not be liable for any dama", "metadata": {"source": "sg248555.pdf", "chunk_index": 21, "total_chunks": 337}}
{"text": " programs are \nprovided \u201cAS IS\u201d, without warranty of any kind. IBM sha ll not be liable for any damages arising out of your use \nof the sample programs. \n\nx Applying Data Protection and Confidentiality in a Hybrid Cloud EnvironmentTrademarks\nIBM, the IBM logo, and ibm.com are trademarks or regi stered trademarks of International Business Machines \nCorporation, registered in many jurisdictions worldwide. Other product and service names might be trademarks of IBM or other companies. A current list of IBM trademarks is available on the web at \u201cCopyright \nand trademark information\u201d at https://www.ibm.com/legal/copytrade.shtml  \nThe following terms are trademarks or registered trademarks of International Business Machines Corporation, \nand might also be trademarks or registered trademarks in other countries. \nIBM\u00ae\nIBM Cloud\u00ae\nIBM Research\u00ae\nIBM Security\u00aeIBM Watson\u00aeIBM Z\u00ae\nIBM z16\u2122\nRedbooks\u00ae\nRedbooks (logo) \u00aeX-Force\u00aez/Architecture\u00ae\nz/OS\u00ae\nz/VM\u00ae\nz16\u2122\nThe registered trademark Linux\u00ae is used pursua", "metadata": {"source": "sg248555.pdf", "chunk_index": 22, "total_chunks": 337}}
{"text": "ooks (logo) \u00aeX-Force\u00aez/Architecture\u00ae\nz/OS\u00ae\nz/VM\u00ae\nz16\u2122\nThe registered trademark Linux\u00ae is used pursuant to a sublicense from the Linux Foundation, the exclusive \nlicensee of Linus Torvalds, owner of  the mark on a worldwide basis.\nZowe is a trademark of the Linux Foundation.\nMicrosoft, Windows, and the Windows logo are trademarks of Microsoft Corporation in the United States, \nother countries, or both.\nRed Hat, OpenShift, are trademarks or registered trademarks of Red Hat, Inc. or its subsidiaries in the United \nStates and other countries.\nOther company, product, or service names may be trademarks or service marks of others. \n\n\n\u00a9 Copyright IBM Corp. 2024. xiPreface\nProtecting workloads and sensitive data throug hout their lifecycle is a great concern across \nall industries and organizations.  Increasing demands to accelerate hybrid cloud adoption and \nintegration are changing the way data is securely stored, processed, and accessed. \nIn addition, regulatory guidelines and st andards are", "metadata": {"source": "sg248555.pdf", "chunk_index": 23, "total_chunks": 337}}
{"text": " is securely stored, processed, and accessed. \nIn addition, regulatory guidelines and st andards are causing many businesses and \norganizations to implement zero trust policies and privacy enhancing techniques to restrict access to workloads as \nstate of least privilege  is established. A stat e of least privilege \nensures that no user or workload has any more access to data than is necessary. Confidentiality and integrity assurance for \ndata at rest  and data in transit  is typically provided \nthrough cryptography. Nevertheless, data in use  is generally unencr ypted while it is \nprocessed by the system, which can make data in use accessible to privileged users or workloads.\nIn the past, data owners relied upon operational assurance to control access to workloads \nand data. An operational  assurance approach en sures that a service pr ovider will not access \ncustomer workloads or data through specific operational procedures and measures. However, \nwith today's constant, unpredictable,", "metadata": {"source": "sg248555.pdf", "chunk_index": 24, "total_chunks": 337}}
{"text": "hrough specific operational procedures and measures. However, \nwith today's constant, unpredictable, and always changing cyberthreats, operational assurance is not enough. \nA more robust technical assurance approach that is hardware-based is needed. A Trusted \nExecution Environment (TEE) or confidential computing platform does just that. A TEE ensures that no one can access sensitive workloads and data while in use, not even the service provider. A TEE can also protect the CI/CD pipeline from bad actors, enforce supply chain protection, and provide code integrity through cryptographic proofs and encryption.\nThis IBM\u00ae Redbooks\u00ae publication outlines how to apply common concepts of data protection \nand confidentiality and make use of a privacy-enh ancing technology-based solution that can \nbe implemented in a hybrid cloud environment. It describes the TEE technologies that are offered with IBM Z\u00ae and IBM LinuxONE (such as  IBM Secure Execution for Linux), and how \nthe IBM Hyper Protect Pl", "metadata": {"source": "sg248555.pdf", "chunk_index": 25, "total_chunks": 337}}
{"text": "IBM Z\u00ae and IBM LinuxONE (such as  IBM Secure Execution for Linux), and how \nthe IBM Hyper Protect Platform uses them.\nThis publication discusses how the various IB M Hyper Protect services ensure zero trust \ndata-centric security and data privacy end-to-end. It al so illustrates the business value \nthrough specific use case scenarios, covering relevant aspects of workload creation and evidence collection for regulatory comp liance of software supply chains.\nThis IBM Redbooks publication is for Chief Information Security Officers (CISOs), IT \nmanagers, security architects, security admi nistrators, cloud application developers, and \nanyone who needs to plan, deploy, and manage da ta security and confidentiality in a hybrid \ncloud environment. The reader is expected to have a basic understanding of IT security and hybrid cloud concepts.\n\nxii Applying Data Protection and Confidentiality in a Hybrid Cloud EnvironmentAuthors\nThis book was produced by a  working at IBM Redbooks.\nBill White  ", "metadata": {"source": "sg248555.pdf", "chunk_index": 26, "total_chunks": 337}}
{"text": "a Hybrid Cloud EnvironmentAuthors\nThis book was produced by a  working at IBM Redbooks.\nBill White  is an IBM Redbooks Project Leader and Senior IT Infrastructure Specialist at IBM \nPoughkeepsie, New York.\nRobbie Avill  is a Solutions Architect with the IBM Z Client Acceleration Team for IBM Hyper \nProtect Services and IBM Cloud\u00ae  products. He has worked at IBM for 8 years since joining as \nthe first ever apprentice at the IBM Lab in the UK. Robbie has been involved in various projects over the years including IBM z/OS\u00ae Co nnect and IBM\u2019s Kubernetes service, as well \nas the Open Mainframe Projects, Galasa and Zowe.\nSandeep Batta  started his career as a z/OS Systems Programmer. He consulted Fortune \n100 clients in the NJ/NYC area, where he had a chance to work on game changing technologies that helped restore operations after disastrous events like 9/11. Sandeep created a \u201cself-service\u201d platform for developers in an IBM z/VM\u00ae farm, developed Cloud Deployment strategies, modernized fron", "metadata": {"source": "sg248555.pdf", "chunk_index": 27, "total_chunks": 337}}
{"text": "platform for developers in an IBM z/VM\u00ae farm, developed Cloud Deployment strategies, modernized front-end network architecture for IBM\u2019s internal infrastructure and developed offering management tools. Sandeep is currently a Lead Solutions Architect in the IBM Hyper Protect organization, where he works with clients in financial services, insurance, and digital asse ts sectors, to address their data-protection \nrequirements.\nAbhiram Kulkarni  is the Software Architect for IBM Hyper Protect at IBM India Systems \nDevelopment Lab, Bangalore. He received his Bachelor of Engineering degree at PESIT Engineering College, Bangalore. He has over 15 years of experience in Software development and joined IBM in 2013. In his recent roles, he has worked in various development projects across IBM Z. He has wo rked on projects that are related to Secure \nService Container, Secure Execution catering toward the clients that need zero trust architecture and Confidential Computing in hybrid cloud environm", "metadata": {"source": "sg248555.pdf", "chunk_index": 28, "total_chunks": 337}}
{"text": "rd the clients that need zero trust architecture and Confidential Computing in hybrid cloud environment. \nTimo Ku\u00dfmaul  is a Solution Architect and Master Inventor at the IBM Research\u00ae and \nDevelopment Lab in B\u00f6blingen, Germany. He holds a Dipl.-Inform. diploma in Computer Science from the University of  Stuttgart, Germany. Timo work s in the Hyper Protect Client \nAcceleration Team and has more than 25 years of experience in Software Development, application of AI and Search, Hybrid Cloud, Security and Confidential Computing. Timo is the author or coauthor of over 100 patents and multiple technical papers and books.\nStefan Liesche  is an IBM Distinguished Engineer wo rking with IBM Hybrid Cloud and Hyper \nProtect Services for IBM Z and IBM LinuxONE. His main focus is on security, transparency, and protection of data and services in flexible cloud environments. Stefan has worked in various areas as a technical leader within IBM, most recently as Chief Architect for IBM Cloud Hyper Prote", "metadata": {"source": "sg248555.pdf", "chunk_index": 29, "total_chunks": 337}}
{"text": "s areas as a technical leader within IBM, most recently as Chief Architect for IBM Cloud Hyper Protect Services and IBM Watson\u00ae Talent Portfolio. He designed and built AI driven \nsolutions that transform recruiting and career decisions within global organizations, that not only enhance quality of decisions, but also allow HR functions to enhance fairness and tackle biases. Stefan also an innovator within the E xceptional Web Experience products for several \nyears with a focus on open solutions and integration. He has 25 years of experience as a technical leader, collaborating with business partners and clients through joint projects, as well as within IBM's product development organization. \n\n Preface xiiiNicolas M\u00e4ding  is Principal Product Manager at the IBM Lab in B\u00f6blingen, Germany. He \nreceived his Dipl. Ing. Degree in Electrical and Information Technology at the Technical University of Chemnitz, German y. He joined IBM in 2001 and worked in various development \nand management pos", "metadata": {"source": "sg248555.pdf", "chunk_index": 30, "total_chunks": 337}}
{"text": "y of Chemnitz, German y. He joined IBM in 2001 and worked in various development \nand management positions in IBM Systems Hardware Developmen t. He joined the \nZ-as-a-Service organization as Release Manage r of the Hyper Protect Hosting Appliance in \n2018 and became product manager for the Secure Execution based offerings. In 2023, he was appointed as Principal Product Manager for the Hyper Protect Platform and Confidential \nComputing with Linux on Z. He is author or co-author of 12 patents and several technical papers.\nChristoph Schlameu\u00df  is a Software Architect at the IBM Research and Development Lab in \nB\u00f6blingen, Germany. He holds a Dipl.-Inf. diploma in Computer Software Engineering from the University of Stuttgart, Germany. Christoph works in the Hyper Protect Services Innovation Team and has over 12 years of experience in professional software development. Including seven years of experience in devel oping Confidential Computing products like \nSecure Service Container and IBM H", "metadata": {"source": "sg248555.pdf", "chunk_index": 31, "total_chunks": 337}}
{"text": "f experience in devel oping Confidential Computing products like \nSecure Service Container and IBM Hyper Protect. He is the author or co-author of two patents.\nPeter Szmrecs\u00e1nyi  is a Solution Architect at the IBM Lab in Markham, Canada. He received \nan Electrical and Electronic Master of Engine ering with Honours degree from The University \nof Birmingham in the United Kingdom. Peter has over 20 years of experience in the field of Information Technology. His areas of expertise include Hyper Protect Services (Confidential Computing on the IBM LinuxONE platform). Peter is the author or co-author of two patents.\nThanks to the following people for their contributions to this project:Divya K Konoor (IBM Senior Technical Staff Member, IBM Hyper Protect Services IaaS)\nIBM India\nRene Meyer (Principal IBM Cloud Technical Specialist)\nIBM Germany\nLouisa Muschal (Product Manager IBM Hyper Protect Services)\nIBM Germany\nBarry Silliman (Consulting IT Specialist)\nIBM USA\nNow you can become a published", "metadata": {"source": "sg248555.pdf", "chunk_index": 32, "total_chunks": 337}}
{"text": "rvices)\nIBM Germany\nBarry Silliman (Consulting IT Specialist)\nIBM USA\nNow you can become a published author, too!\nHere\u2019s an opportunity to  spotlight your skills , grow your career, and become a published \nauthor\u2014all at the same time! Join an IBM Redbooks residency project and help write a book in your area of expertise, while honing your experience using leading-edge technologies. Your efforts will help to increase pr oduct acceptance and customer satisfaction, as you expand \nyour network of technical contacts and relationships. Residencies run from two to six weeks in length, and you can participate either in person or as a remote resident working from your home base.\nFind out more about the residency program, browse the residency index, and apply online at:\nibm.com/redbooks/residencies.html\n\nxiv Applying Data Protection and Confidenti ality in a Hybrid Cloud EnvironmentComments welcome\nYour comments are important to us!\nWe want our books to be as helpful as possible . Send us your c", "metadata": {"source": "sg248555.pdf", "chunk_index": 33, "total_chunks": 337}}
{"text": "e\nYour comments are important to us!\nWe want our books to be as helpful as possible . Send us your comments about this book or \nother IBM Redbooks publications in one of the following ways:\n/SM590000Use the online Contact us  review Redbooks form found at:\nibm.com/redbooks\n/SM590000Send your comments in an email to:\nredbooks@us.ibm.com\n/SM590000Mail your comments to:\nIBM Corporation, IBM Redbooks\nDept. HYTD Mail Station P0992455 South RoadPoughkeepsie, NY 12601-5400\nStay connected to IBM Redbooks\n/SM590000Find us on LinkedIn:\nhttps://www.linkedin.com/groups/2130806\n/SM590000Explore new Redbooks publications, residencies, and workshops with the IBM Redbooks \nweekly newsletter:\nhttps://www.redbooks.ibm.com/subscribe\n/SM590000Stay current on recent Redbooks publications with RSS Feeds:\nhttps://www.redbooks.ibm.com/rss.html\n\n\u00a9 Copyright IBM Corp. 2024. 1Chapter 1. A hybrid cloud with data security \nin mind\nMoving workloads to a cloud infrastructure rais es critical questions about data sec", "metadata": {"source": "sg248555.pdf", "chunk_index": 34, "total_chunks": 337}}
{"text": "curity \nin mind\nMoving workloads to a cloud infrastructure rais es critical questions about data security and \ndata privacy. A workload running in a cloud infrastructure owned by  a service provider, \nmaintained by the provider\u2019s administrators, a nd shared with other tenants requires a novel \nand complete approach to protecting data and developing applications in a trusted environment. The data security concerns might even be prohibitive when you consider applications for a hybrid cloud infrastructure, more so if you cannot validate the trust of all parties. There might also be regulatory compliance to adhere to or business-specific needs for higher levels of data security controls that mandate protection at every stage of a digital interaction or data lifecycle. \nThis chapter discusses the threats, concerns, requirements, and the solution for a hybrid \ncloud infrastructure with data security in mind. The following topics are discussed:\n/SM5900001.1, \u201cIdentifying the threat\u201d on page 2", "metadata": {"source": "sg248555.pdf", "chunk_index": 35, "total_chunks": 337}}
{"text": "curity in mind. The following topics are discussed:\n/SM5900001.1, \u201cIdentifying the threat\u201d on page 2\n/SM5900001.2, \u201cBeyond regulatory and standard frameworks\u201d on page 3\n/SM5900001.3, \u201cMitigating the threat\u201d on page 4\n/SM5900001.4, \u201cThe solution explained\u201d on page 71\n\n2 Applying Data Protection and Confidentiality in a Hybrid Cloud Environment1.1  Identifying the threat\nAs cyberattacks continue to increase, the cost and reputation impacts of data breaches \nremain a top concern across all businesses and organizations1. To help understand how a \ncyberattack might threaten a system, application, or data, the well-known STRIDE threat \nmodel  can be used. This model conceptualizes the potential threats into six categories:\n1. Spoofing. An entity falsely identifies as another identity\n2. Tampering with data. The malicious modification of data3. Repudiation. An entity disputing its respon sibility, ownership or authorship of data, \nresources or operations\n4. Information disclosure. The exposur", "metadata": {"source": "sg248555.pdf", "chunk_index": 36, "total_chunks": 337}}
{"text": "ty, ownership or authorship of data, \nresources or operations\n4. Information disclosure. The exposure of information to unauthorized entities, this means to \nentities who are not supposed to have access\n5. Denial of service. An attack that tries to make a system or resource unavailable6. Elevation of privilege. An attack to get elevated privileges or privileged access to a system \nor resource \nAnother way to look at threats is the path that an attacker might use to gain access to a \nsystem, application, or data, referred to as an attack vector. There are many well-known attack vectors, some of which have been used to successfully attack applications and gain \naccess to sensitive data (reference IBM X-Force\u00ae Threat Intelligence Index 2023 ). Typically, \nan attack vector corresponds to one or more of the STRIDE threats.\nThere are also different threats, mechanisms, and implications for managing and ensuring \nconfidentiality, integrit y, and availability depen ding on the state of th e da", "metadata": {"source": "sg248555.pdf", "chunk_index": 37, "total_chunks": 337}}
{"text": "aging and ensuring \nconfidentiality, integrit y, and availability depen ding on the state of th e data. As shown in \nFigure 1-1, data is categorized in three distinct states:\n1. Data in persistent storage is \nat rest .\n2. Data traversing the network between a source and a destination is in transit , alternatively \ncalled data in motion or data in flight .\n3. Data being processed by a system is  in use . During processing, the data is typically stored \nin a non-persistent state in CPU cache or system memory.\nFigure 1-1   Data states\nToday, cryptography is commonly used for data at rest and data in transit to provide both data confidentiality for stopping unauthorized viewing and data integrity for preventing or detecting unauthorized changes.\nA well-established best practice is to protect data in transit by using cryptographic protocols \nlike Transport Layer Security (TLS)\n2. Such cryptographic protocols protect the confidentiality \nand integrity of the data in transit between endpoints", "metadata": {"source": "sg248555.pdf", "chunk_index": 38, "total_chunks": 337}}
{"text": "raphic protocols protect the confidentiality \nand integrity of the data in transit between endpoints in a public or private network.\n1  Reference: Cost of a Data Breach Report 2023\n2  Reference: HTTPS encryption on the web,  Google Transparency Report\n\n\nChapter 1. A hybrid cloud with data security in mind 3Data at rest should be stored in encrypted form only. IBM Cloud Object Storage  or volume \nencryption, such as Linux Unified Key Setup (LUKS), encrypts the data before writing to persistent storage and decrypts it for reading. Thus, an attacker cannot access the data at rest even with access to the physical storage device. \nHowever, data in use is generally unencrypted and easily accessible, as it is active data being \nprocessed by the system. For further discussion about protecting data in use, see 1.3, \u201cMitigating the threat\u201d on page 4.\n1.2  Beyond regulatory and standard frameworks\nIn addition to the concerns related to protecting data in use, data sovereignty3 states that data \ni", "metadata": {"source": "sg248555.pdf", "chunk_index": 39, "total_chunks": 337}}
{"text": "In addition to the concerns related to protecting data in use, data sovereignty3 states that data \nis bound to the laws and regulations of the country in which it is collected, stored, processed, and distributed and can be subject to data protection policies. Worldwide, there are many standards and regulations that are related to protecting data at rest and in transit. Although some of the standards specify the technologies required for compliance, encryption is applied to achieve compliance for most of them. \nA broad framework like a zero trust architecture  can also provide effective protection of an \norganization's data. It works by assuming every connection, endpoint, and domain are considered a threat. See Figure 1-2. The goal of a zero trust strategy is to eliminate implicit trust and to continuously validate every stage of a digital interaction.\nFigure 1-2   Zero trust framework threats\nCommon techniques for protection of data at rest and data in transit with a zero trust archit", "metadata": {"source": "sg248555.pdf", "chunk_index": 40, "total_chunks": 337}}
{"text": "hreats\nCommon techniques for protection of data at rest and data in transit with a zero trust architecture are defined by the National Institute of Standards and Technology (NIST).\n4 \nHowever, other than the regulatory and standard frameworks, other areas of concern are \nprovided in the following list:\n/SM590000Protecting sensitive data that is in use by app lications in a hybrid cloud infrastructure, even \nfrom privileged users\n3  Refers to the notion that a country or jurisdiction has the authority and right to govern and control the data \ngenerated within its borders. \n4  Reference:  NIST Special Publication 800- 207, Zero Trust Architecture\n\n\n4 Applying Data Protection and Confidentiality in a Hybrid Cloud Environment/SM590000Avoiding the need to trust potentially malicious  privileged users or potentially vulnerable \nand compromised infrastructure and intermediary components in a hybrid cloud environment\n/SM590000Achieving an air-gapped solution for applications and data from any ", "metadata": {"source": "sg248555.pdf", "chunk_index": 41, "total_chunks": 337}}
{"text": "brid cloud environment\n/SM590000Achieving an air-gapped solution for applications and data from any potential malicious \nactor\nIn other words, identify the technologies and techniques that can help with the following \nrequirements:\n/SM590000Reduce hybrid cloud migration risk\n/SM590000Secure sensitive data in use\n/SM590000Control applications a ccording to requirements\n/SM590000Ensure compliance with re gulatory requirements\n/SM590000Cause zero additional effort for consumers \n/SM590000Have zero impact on the functionality and av ailability of applications\n1.3  Mitigating the threat\nCyberthreats are constant, unpredictable, and always changing. Therefore, many businesses \nand organizations use the US Department of Commerce National Institute of Standards and \nTechnology (NIST) standards, guidelines, and recommendations as a baseline, then apply \nstronger policies and controls as needed or required. IBM also aligns with NIST guidelines and is committed to embedding security and privacy i", "metadata": {"source": "sg248555.pdf", "chunk_index": 42, "total_chunks": 337}}
{"text": " required. IBM also aligns with NIST guidelines and is committed to embedding security and privacy into the design of all products and services.\n5 \nA zero trust architecture can help prevent unauthorized access to data and services. \nHowever, in a hybrid cloud infrastructure, ac cess control policies or operations to ensure \nisolation of applications and data in use might not satisfy all business-specific requirements. \nIdeally, data security and isolation are impl emented in all layers of the hybrid cloud \ninfrastructure, creating an air-gapped environment.6\nThe properties and features that are required to prevent or mitigate cyberthreats include the following characteristics:\n/SM590000Technical assurance\n/SM590000A Trusted Execution Environment for your application\n/SM590000Reduced trust boundary and trusted computing base\n/SM590000Controlling your applicatio n with separation of duty\n/SM590000Exclusive and full control over your cryptographic key\n/SM590000Support for your applicatio", "metadata": {"source": "sg248555.pdf", "chunk_index": 43, "total_chunks": 337}}
{"text": "/SM590000Exclusive and full control over your cryptographic key\n/SM590000Support for your application OCI images\n/SM590000Support for hybrid cloud \n1.3.1  Technical assurance\n\u201cComputer security assurance is the degree of confidence one has that the security \nmeasures, both technical and operational, work as intended to protect the system and the information it processes.\u201d \n7\nTechnical assurance, or security assurance by  technical measures, can be distinguished from \noperational assurance, or security assurance by operational measures. Technical assurance \n5  Reference: IBM Security\u00ae and Privacy by Design (SPbD@IBM)\n6  An air-gapped environment has no direct connection to the inte rnet or to any other computer that is connected to \nthe internet.\n7  https://csrc.nist.rip/publications/nistpubs/800-12/800-12-html/chapter9.html\n\nChapter 1. A hybrid cloud with data security in mind 5is provided by the hardware, the firmware, and the software stack of a system and is included \nin the system ", "metadata": {"source": "sg248555.pdf", "chunk_index": 44, "total_chunks": 337}}
{"text": "ed by the hardware, the firmware, and the software stack of a system and is included \nin the system technically. In contrast, operational assuranc e addresses whether required \nprocedures and regulations are followed and are compliant to operational requirements.\nThe difference between technica l assurance and opera tional assurance is illustrated in \nFigure 1-3. Operational assurance ensures that service providers do not access client workloads. Technical assurance ensures that service providers cannot access client workloads.\nFigure 1-3   Technical assurance versus operational assurance\n1.3.2  A Trusted Execution Environment for your application\nA hardware-based Trusted Execution Environment (TEE) is an execution environment that provides hardware-based technical assurance of the following properties:\n/SM590000Data confidentiality. Unauthorized actors cannot  view data while it is in use within the TEE.\n/SM590000Data integrity. Unauthorized actors cannot ad d, remove, or alter data w", "metadata": {"source": "sg248555.pdf", "chunk_index": 45, "total_chunks": 337}}
{"text": "se within the TEE.\n/SM590000Data integrity. Unauthorized actors cannot ad d, remove, or alter data while it is in use \nwithin the TEE.\n/SM590000Code integrity. Unauthorized actors cannot add, remove, or alter code that is running in \nthe TEE. Examples of unauthorized actors: \n\u2013 other applications on the host system\u2013 the host operating system and hypervisor\u2013 other tenants of the host system\u2013 the cloud provider\u2013 privileged actors like system administrators\u2013 parties with physical access to the hardware\n/SM590000Code confidentiality. The TEE protects the code while in use from being viewed or \naccessed by unauthorized actors.\n/SM590000Programmability. The TEE can be programmed with arbitrary code.\n/SM590000Attestation. The process with which the TEE can provide evidence or measurements of its \norigin and current state. This evidence can be verified by another persona, for example the auditor persona, who can decide whether to trust the application running in the TEE or not. Typically, this", "metadata": {"source": "sg248555.pdf", "chunk_index": 46, "total_chunks": 337}}
{"text": " persona, who can decide whether to trust the application running in the TEE or not. Typically, this evidence is represented as  an attestation record. The contents of this \nrecord can be verified against workload and environment expectations. The attestation record is signed by a trusted key that is an chored in hardware that can be vouched for by \na trusted manufacturer. This signature provides assurance that the attestation record was \ncreated by the correct component and was not altered by an unauthorized entity.\nThe TEE provides code and data confidentiality and integrity. The TEE thus isolates your \napplication code and data from access and modification by unauthorized actors. The TEE isolates your application code and data from access and modification by other privileged or non-privileged actors, which includes potentially  malicious administrators, and other tenants.\n\n\n6 Applying Data Protection and Confidentiality in a Hybrid Cloud EnvironmentThis process must be technically a", "metadata": {"source": "sg248555.pdf", "chunk_index": 47, "total_chunks": 337}}
{"text": " Data Protection and Confidentiality in a Hybrid Cloud EnvironmentThis process must be technically assured by an implementation that is anchored in hardware. \nNo unauthorized entity is allowed to access or modify the code or the data of the application.\n1.3.3  Reduced trust boundary and trusted computing base \nYou can run your application in a TEE with technically assured isolation that you can remotely \nverify through attestation. Instead of trusting all the components and actors in your hybrid cloud infrastructure, you reduce the trust assumptions to the hardware-based implementation of the underlying TEE and the attestation protocol. In this scenario, components and actors can include those of your public cloud provider.\n1.3.4  Controlling your application with separation of duty\nThe infrastructure needs to ensure exclusive cont rol over your application and its properties is \nprovided to authorized personas only. This means that there is a process in place that ensures only you and", "metadata": {"source": "sg248555.pdf", "chunk_index": 48, "total_chunks": 337}}
{"text": "d to authorized personas only. This means that there is a process in place that ensures only you and authorized personas can control the application code, the properties of the runtime environment, an d how data at rest is protected,  such as controlling the seeds for \nvolume encryption. In addition, only you and authorized personas can control cryptographic keys and can pass secrets, such as cryptographic seeds for key derivation, to the application.\nSeparation of duty\nThe infrastructure needs to ensure separation of duty that allows multiple personas by defining different aspects and properties of your application. Also, a process needs to be defined to allow the different personas to cooperate securely. A persona must be able to define the properties and secrets of your application or its environment. Other personas must be prevented from accessing, modifying, or overwriting these properties and secrets. The infrastructure provides technical assurance of separation of duties and ena", "metadata": {"source": "sg248555.pdf", "chunk_index": 49, "total_chunks": 337}}
{"text": "perties and secrets. The infrastructure provides technical assurance of separation of duties and enables secure cooperation of the various personas.\nMultiple personas can securely pass secr ets to your application\nA persona must be able to pass secrets to the application in a secure way, which means the \nsecret must be protected from other personas, the hybrid cloud infrastructure, and other \nactors. \nFor example, secrets can comprise TLS certificate and keys, cryptographic keys, \ncryptographic seeds used for key derivation, seeds used for volume encryption, and so on.\nSeparation of duty allows a first persona, a Workload Provider, to define the Open Container \nInitiative (OCI)  image for the application that should be run in a confidential computing \nenvironment. A second persona, a Workload Deployer, can define the TLS certificate and key that should be used by the application. This way, both personas cooperate to setup the application in confidential computing. The separation of dut", "metadata": {"source": "sg248555.pdf", "chunk_index": 50, "total_chunks": 337}}
{"text": "y, both personas cooperate to setup the application in confidential computing. The separation of duty process ensures that the Workload Provider cannot access or tamper the TLS certificate and key, and the Workload Deployer cannot access or tamper the OCI image.\nIn addition, both personas can cooperate to define a cryptographic seed for LUKS based \nvolume encryption or another type of cryptographic encryption or signature. Here, the first Workload Provider persona defines a first part of the seed, and the Workload Deployer defines a second part of the seed. The separation of duty process ensures that the seed parts are provided to the secure enclave with out exposing them to the other persona by \nkeeping them confidential from each other. In the reference architecture both parts of the seed are combined in the TEE to create the LUKS encryption key. This means that the resulting combined seed never leaves the TEE. Each persona knows only one part of the \n\nChapter 1. A hybrid cloud with ", "metadata": {"source": "sg248555.pdf", "chunk_index": 51, "total_chunks": 337}}
{"text": "seed never leaves the TEE. Each persona knows only one part of the \n\nChapter 1. A hybrid cloud with data security in mind 7seed. Thus this process prevents individual pe rsonas from being able to re-create the LUKS \nencryption key and a ccess data at rest. \n1.3.5  Exclusive and full contro l over your cryptographic key\nA cloud hardware security module (HSM) must provide full and exclusive control over your \ncryptographic keys. Without such mechanisms, privileged actors in the hybrid cloud environment can use known attack vectors to gain access to your keys and cryptographic material. A malicious privileged actor might then tamper or misuse your keys and secrets, for example, by maliciously decrypting or signing sensitive data.\nNote that control over your crypto graphic keys must be technically \nassured  by using \nhardware-based mechanisms.\n1.3.6  Support for your application OCI images\nThe TEE must support common programming and deployment models, such as OCI images. The TEE does not r", "metadata": {"source": "sg248555.pdf", "chunk_index": 52, "total_chunks": 337}}
{"text": "he TEE must support common programming and deployment models, such as OCI images. The TEE does not require a specific programming model for your code. Also, it does not impose special limitations or requirements on your code. This means you can run your own \nOCI images in the TEE without code changes. The application developer does not need to learn a specific programming model. There is code comp atibility between the TEE and \nnon-confidential computing environments.\n1.3.7  Support for hybrid cloud\nThe infrastructure must support a hybrid cloud environment, comprising support for on-premises environments and provide confiden tial computing as a service in the cloud. \nIn addition, the infrastr ucture must not impose limits on sca lability of your application. This \nmeans, the infrastructure must scale with your performance and memory requirements.\n1.4  The solution explained\nConfidential computing8 can help enhance the zero-trust architecture by providing a trusted \nexecution environme", "metadata": {"source": "sg248555.pdf", "chunk_index": 53, "total_chunks": 337}}
{"text": " computing8 can help enhance the zero-trust architecture by providing a trusted \nexecution environment for applications, even in an untrusted environment. The hardware-based security mechanism that is offered by confidential computing enables the processing and storage of sensitive data in a safe enclave that is isolated from the host \nsystem and other potentially vulnerable components. \nThis isolation is technically assured. Hence, the hardware-based and firmware-based \nprotection mechanisms provide technical means  for ensuring that unauthorized actors are \nprevented from accessing your application and your data. The access is prevented even if an attacker overcomes the access control systems of the cloud provider or gains access to \nanother vulnerable component in the cloud infrastructure. Confidential computing adds a layer of data security on top of a zero trust architecture by providing technically assured isolation, sometimes called a \nvirtual air-gap , of applications in T EEs.", "metadata": {"source": "sg248555.pdf", "chunk_index": 54, "total_chunks": 337}}
{"text": "iding technically assured isolation, sometimes called a \nvirtual air-gap , of applications in T EEs. This virtual air-gap \nprevents malicious inside actors like authorized administrators from dumping the memory of \nyour application or directly accessing data of your application. The virtual air-gap prevents access to the file system or memory or your application.\n8  Confidential computing is the protection of data in us e by performing computation in a hardware-based, attested \nTEE. Reference: A Technical Analysis of Confidential Computing, a publication of the Confidential Computing \nConsortium, November, 2022.\n\n8 Applying Data Protection and Confidentiality in a Hybrid Cloud EnvironmentThe Hyper Protect Platform as the confidential computing solution can help solve the data \nprotection concerns in a hybrid cloud environment, an on-premises environment, and in an IBM Cloud-based SaaS model. \nThe solution consists of the following components:\n/SM590000A Trusted Execution Environment fo", "metadata": {"source": "sg248555.pdf", "chunk_index": 55, "total_chunks": 337}}
{"text": "del. \nThe solution consists of the following components:\n/SM590000A Trusted Execution Environment for containerized applications in hybrid cloud \nenvironments.\nIt is available as IBM Hyper Protect Virtual Server on IBM LinuxONE and IBM Z platforms \nfor on-premises environments or as IBM Hype r Protect Virtual Server for Virtual Private \nCloud (VPC) in IBM Cloud. \n/SM590000A hardware security module (HSM) such as IB M Hyper Protect Crypto Services in IBM \nCloud and IBM LinuxONE or IBM Z platform with Crypto Express features for on-premises use.\n/SM590000A component for secure CI/CD: IBM Hyper Protect Secure Build \nThe solution provides a set of secure processes and patterns that are explained in the \nsubsequent sections. Also, the components that make up the solution are discussed in more detail in Chapter 2, \u201cUnderstanding the solution\u201d on page 15.\n1.4.1  The technology underlying the Hyper Protect Platform\nModern data-serving systems must immediately scale up and scale out in size, pe", "metadata": {"source": "sg248555.pdf", "chunk_index": 56, "total_chunks": 337}}
{"text": "per Protect Platform\nModern data-serving systems must immediately scale up and scale out in size, performance, and features. Virtualization is a key technology  that enables a hardware system to achieve \nthis level of scaling performance and maintain dense packaging and optimal use of resources.\nVirtualization is one of the core strengths of the IBM LinuxONE and IBM Z platforms, with the \ngoal of maximizing usage of computing resources and lowing the overall cost and resource requirements for running critic al workloads for enterprises.\nThe embedded architecture and hardware with the IBM LinuxONE and IBM Z platforms is \ndesigned around the ability to pa rtition resources to  be used independently in distinct \nvirtualized environments. The resources include compute, memory, and I/O connectivity of \nboth storage and network.\nHypervisors are a core part of the virtualizatio n technology stack with the IBM LinuxONE and \nIBM Z platforms. They are designed to enable si multaneous execution o", "metadata": {"source": "sg248555.pdf", "chunk_index": 57, "total_chunks": 337}}
{"text": "ck with the IBM LinuxONE and \nIBM Z platforms. They are designed to enable si multaneous execution of multiple operating \nsystems and allocate the correct amount of virtualized resources. Hypervisors are necessary to securely run, manage, and isolate virtual servers or logical partitions on the IBM LinuxONE and IBM Z platforms. \nIBM Secure Execution for Linux\nThe IBM Hyper Protect Platform uses Secure Ex ecution for Linux. This is a hardware-based \nsecurity technology, which was introduced with the IBM Z and IBM LinuxONE platforms specifically for Kernel-based  Virtual Machine (KVM) guests\n9. It is designed to provide \nscalable isolation for individual workloads to help protect them from not only external attacks, but also insider threats. Secure Execution for Linux can help protect and isolate Linux workloads on-premises, or on IBM Z and IBM LinuxONE in hybrid cloud environments.\nSecure Execution for Linux isolates and protec ts KVM guests from hypervisor access. The \nhypervisor admin", "metadata": {"source": "sg248555.pdf", "chunk_index": 58, "total_chunks": 337}}
{"text": " Execution for Linux isolates and protec ts KVM guests from hypervisor access. The \nhypervisor administrator can manage guests and deploy workloads, but cannot view data. \n9  Virtual machines (VMs) are also referred to as guests or images.\n\nChapter 1. A hybrid cloud with data security in mind 9Multiple applications that are running in a logical partition (LPAR) under KVM have fully \nisolated environments.\nTo achieve this, the IBM LinuxONE and IBM Z firmware provides an ultravisor . The ultravisor \nis a trusted firmware component. It uses me mory-protection hardware, and the owner of a \ngiven KVM guest can securely pass secret information to the ultravisor by using the public host key.\nFigure 1-4 illustrates the Secure Execution for Linux environments  running in KVM guests in \nan IBM LinuxONE or IBM Z platform.\nFigure 1-4   Secure Execution for Linux environment\nFor more information, refer to IBM Secure Execution components .\nKernel-based virtual machines\nKernel-based virtual machine (", "metadata": {"source": "sg248555.pdf", "chunk_index": 59, "total_chunks": 337}}
{"text": "er to IBM Secure Execution components .\nKernel-based virtual machines\nKernel-based virtual machine (KVM) is a key software technology for IBM LinuxONE and \nIBM Z platforms. It is a Type 2 hypervisor10 that provides simple, cost-effective virtualization \ntechnology for Linux workloads. It allows sharing and managing of allocated resources and can coexist with other types of virtualization technologies that are simultaneously running in IBM LinuxONE or IBM Z.\nOne of the advantages of KVM vi rtualization is the familiar standa rd Linux user interfaces for \nopen source developers, which can help make adoption and integration easier with hybrid environments.\nTogether with Secure Execution for Linux, data and workloads that run in KVM guests are \nisolated and protected from being inspected or  modified from the moment the guest is built, \nthrough the boot process, and during workload execution.\n10  A Type 2 hypervisor runs as a software layer. It does not run directly on the un derlying hard", "metadata": {"source": "sg248555.pdf", "chunk_index": 60, "total_chunks": 337}}
{"text": ".\n10  A Type 2 hypervisor runs as a software layer. It does not run directly on the un derlying hardware, but rather like an \napplication in an OS, sharing and managing its al located resources with virtual machines.\n\n\n10 Applying Data Protection and Confidentiality in a Hybrid Cloud EnvironmentKVM on IBM LinuxONE and IBM Z is supported through the following Linux distribution \npartners:\n/SM590000Red Hat Enterprise Linux (RHEL)\n/SM590000SuSE Linux Enterprise Server\n/SM590000Canonical Ubuntu Server\nIsolation through IBM Proces sor Resource/Systems Manager\nThe IBM LinuxONE and IBM Z platforms have a unique implementation of its hypervisor at \nthe hardware and firmware level. It is part of the base system that fully virtualizes all system resources and runs without any extra software. This type 1 hypervisor\n11 runs directly on bare \nmetal. With it, multiple  isolated partitioned environments can be created on the same physical \nserver. These isolated environments are known as logical part", "metadata": {"source": "sg248555.pdf", "chunk_index": 61, "total_chunks": 337}}
{"text": "s can be created on the same physical \nserver. These isolated environments are known as logical partitions (LPARs). \nEAL 5+ isolation and cryptographic key protection \nIBM LinuxONE and IBM Z platforms feature EAL 5+ isolation. EAL5+ is a regulatory certification for logical partitions that verifies the separation of each partition to improve security.\n12 Therefore, you can run many virtual servers concurrently. The platforms can \nisolate and protect each LPAR, whether z/VM, z/OS, or KVM, as though they were running on physically separated servers.\nThe LPARs are isolated from each other, but VMs or containers within the same LPAR are not \nas isolated. Secure Execution for Linux is an IBM LinuxONE or IBM Z hardware capability. By \nusing Secure Execution for Linux, a KVM hypervisor can isolate virtual machines and containers from each other within an LPAR.\nA Processor Resource/Systems Manager-based LPAR is the only technology that is \ncommercially available to provid e this certified leve", "metadata": {"source": "sg248555.pdf", "chunk_index": 62, "total_chunks": 337}}
{"text": "er-based LPAR is the only technology that is \ncommercially available to provid e this certified level of isolat ion between logical partitions.\nIn addition, cryptographic key protection that is used by Secure Execution for Linux, is \nachieved by dedicated cryptographic coprocessors . The CP Assist for Cryptographic Function \n(CPACF) delivers cryptographic and hashing ca pabilities in support of key protection \noperations. The Crypto Express adapter is used to create the fortified data perimeter by using the IBM LinuxONE or IBM Z protected key in which the keys that are used in the encryption process are not visible to the applications and operating system.\nEach LPAR on an IBM LinuxONE or IBM Z platform has its own uniquely generated and \nassigned cryptographic keys that are held in a secure hardware area. This configuration provides a level of cryptographic isolation between secure environments that required by \nmany regulatory compliance frameworks.\n1.4.2  Features of the Hyper Protec", "metadata": {"source": "sg248555.pdf", "chunk_index": 63, "total_chunks": 337}}
{"text": "onments that required by \nmany regulatory compliance frameworks.\n1.4.2  Features of the Hyper Protect Platform\nThe features that are offered by the Hyper Protect Platform create the foundation for an end-to-end secure environment. This platform provides protection of code and data and supports a consistent developer experience.\nBring your container runtime\nFor OCI images, Hyper Protect Virtual Server (HPVS) provides  a trusted container runtime \nthat provides the benefits and  properties of a TEE. HPVS s upports any OCI images that are \nbuilt for IBM LinuxONE and IBM Z, which means images do not need to be adapted \n11  A type 1 hypervisor runs directly on the underlying computer's physical hardware, interacting directly with its CPU, \nmemory, and physical storage and network I/O.\n12  Reference to EAL 5+ isolation: \nhttps://www.bsi.bund.de/SharedDocs/Zertifikate_CC/CC/Serveranwendungen_Virtualisierung/1133.html\n\nChapter 1. A hybrid cloud with data security in mind 11specifically for HPV", "metadata": {"source": "sg248555.pdf", "chunk_index": 64, "total_chunks": 337}}
{"text": "rtualisierung/1133.html\n\nChapter 1. A hybrid cloud with data security in mind 11specifically for HPVS. The a pplication code does not need to be chan ged and doe s not need \nto adhere to a specific programming model. Yo u can run your existing application code and \nimages and on the Hyper Protect Platform.\nVirtual air-gap: memory protection and isolation\nThe IBM Hyper Protect Platform uses IBM Secure Execution for Linux to ensure data and \ncode confidentiality and integrity of the deployed application, including against privileged users and infrastructure components. \nSeparation of duty\nHPVS supports separation of duty  with predefined personas, as  described in Table 1-1. The \npredefined personas are based on least priv ilege and zero trust principles. There is no \nassumed trust for what is expected to be deployed.\nTable 1-1   Personas for the separation of duties\nPersona Description\nContainer Image Provider An application can consist of one or more container images. The Container Ima", "metadata": {"source": "sg248555.pdf", "chunk_index": 65, "total_chunks": 337}}
{"text": "ntainer Image Provider An application can consist of one or more container images. The Container Image \nProvider is responsible for building the images in a secure manner and according to best \npractices. This ensures that the images are valid and free fr om vulnerabilities. Logs and \nevidence of the build are retained for potential future use for auditing.\nWorkload Provider This can be the same persona as the Container Image Provider. Alternatively, the \nWorkload Provider is a separate persona, which can combine container images from \ndifferent sources or different Container Image Providers. The Workload Provider \npersona defines one or more containers to be deployed and defines certain properties \nof the application environment, such as  seeds used for data volume encryption. \nNo one else can change the container images or  redefine the application properties that \nare specified by the Workload Provider.For this purpose, the Workload Provider us es the workload section of the contrac", "metadata": {"source": "sg248555.pdf", "chunk_index": 66, "total_chunks": 337}}
{"text": " Workload Provider.For this purpose, the Workload Provider us es the workload section of the contract to \ndefine the container images and application properties in a secure manner. They can \nthen pass the encrypted contract section to  other personas without exposing the content \nof the workload contract section. \nWorkload section is described under \u201cContract mechanism\u201d on page 12.\nWorkload Deployer This persona is responsible for dep loying an HPVS instance for running the application \nin the hybrid cloud environment.\nThe Workload Provider provides the encrypt ed workload contract section to the \nWorkload Deployer. This allows the Workl oad Deployer to supplement the contract \nsection that is provided by the Workload  Provider with an additional environment \ncontract section that defines further proper ties of the application and its environment. \nSome of the properties include information such as defining where the logs should be \nsent to and seeds for data volume encryption.\nThe Wor", "metadata": {"source": "sg248555.pdf", "chunk_index": 67, "total_chunks": 337}}
{"text": "ion such as defining where the logs should be \nsent to and seeds for data volume encryption.\nThe Workload Deployer is responsible for the application deployment and application \navailability.\nThe following list describes some of th e aspects of the Workload Deployer :\n/SM590000It can control the networki ng, compute, and storage resources made available to \nthe application.\n/SM590000It can influence network traffic in and out of the application.\n/SM590000It cannot change the container images to be deployed\n/SM590000It cannot change the application properties that are defined by the Workload \nProvider.\nIf the Workload Provider and the Workload Deployer specify seeds for data volume \nencryption, both seeds are combined. This me ans that individual personas do not have \nenough information for decrypting encrypted data volumes.\n\n12 Applying Data Protection and Confidentiality in a Hybrid Cloud EnvironmentContract mechanism\nHPVS uses a contract mechanis m to enable the Wo rkload Provider an", "metadata": {"source": "sg248555.pdf", "chunk_index": 68, "total_chunks": 337}}
{"text": "ud EnvironmentContract mechanism\nHPVS uses a contract mechanis m to enable the Wo rkload Provider and the Workload \nDeployer personas to define the container images and the properties of the application and its environment in a secure way.  The contract is a document comprising multiple sections, \nwhich can be independently encrypted. The co ntract can be signed a nd is provided to HPVS \nduring deployment. During the initialization pr ocess of the HPVS instanc e, the Hyper Protect \nContainer Runtime (HPCR) decrypts the contract, verifies the contract signature, and creates the passphrase that is used for volume encryption based on the seeds that are contained in the contract. The container images are set up as defined in the contract according to the properties in the environment variables.\nThe contract has several sections, two of these are mandatory: \n/SM590000Workload (mandatory). This section contains th e definition of the application workload in \nthe form of a docker compose file", "metadata": {"source": "sg248555.pdf", "chunk_index": 69, "total_chunks": 337}}
{"text": "s section contains th e definition of the application workload in \nthe form of a docker compose file or a pod descriptor. It defines one or more container images, the container image registry where it resides, and the information and credentials that are required to download and validate the image.\nThe section can also comprise information about data volumes, the seed for deriving the \nvolume encryption passphrase , and environment variables.\n/SM590000env (mandatory). This section describes the environment for the application. It comprises \nseveral subsections to define information about logging, such as where the logs should be sent to; data volumes; another seed for deriving the volume encryption passphrase; environment variables; and optionally, the public part of the contract signing key.\n/SM590000attestationPublicKey (optional). This section pr ovides a public RSA key, which is used to \nencrypt the attestation document.\n/SM590000envWorkloadSignature (optional). This section contai", "metadata": {"source": "sg248555.pdf", "chunk_index": 70, "total_chunks": 337}}
{"text": " to \nencrypt the attestation document.\n/SM590000envWorkloadSignature (optional). This section contains the signature of the other sections \nof the contract, pinning to a specific workload part to the env part. An Auditor, a Workload Provider, or a Workload Deployer persona can choose to sign a contract before it is passed as input.\nOnly the Hyper Protect Platform can decrypt an  encrypted contract. Therefore, by using the \ncontract mechanism, the Workload Provider persona can define and encrypt the workload \nsection of the contract, then pass it to the Workload Deployer persona. This way, the \nWorkload Provider can hide the content of the workload section of the contract, such as the actual container images of the application, from the Workload Deployer, and allow the Workload Deployer to provision the HPVS instance for the application.Auditor The Auditor is the pers ona with respons ibility for veri fying the integrity of the HPVS \ninstance and the deployed application. Fo r example, ", "metadata": {"source": "sg248555.pdf", "chunk_index": 71, "total_chunks": 337}}
{"text": "lity for veri fying the integrity of the HPVS \ninstance and the deployed application. Fo r example, the auditor ensures that the \nexpected container image and application proper ties are used by the application. It does \nthis by obtaining and verifying a trusted attestation record. T he contents of this \nattestation record can be verified against the expected contract sections, comprising the \ncontainer image definition and the applicat ion properties. The Auditor, or possibly \nanother persona, like the Workload Provider or  Workload Deployer, can choose to sign \na contract before it is passed as input. A contract signature is an optional feature that \ncan be used with the contract. Contracts t hat are in plain text or encrypted can be \nsigned. \nInfrastructure/System admin This role includes the system or cloud administrator and support personas of the \ninfrastructure like a Site Reliability Engineer (SRE). This role has responsibility for the \nunderlying hardware and infrastructure, s", "metadata": {"source": "sg248555.pdf", "chunk_index": 72, "total_chunks": 337}}
{"text": "lity Engineer (SRE). This role has responsibility for the \nunderlying hardware and infrastructure, such as networks, but must not be able to \naccess confidential data or tamper with the application. Persona Description\n\nChapter 1. A hybrid cloud with data security in mind 13The Workload Deployer can define and encrypt the env section of the contract. The Workload \nDeployer then combines the workload and the env section, optionally adds the envWorkloadSignature and the attestationPublicKey sections, and then deploys the HPVS instance using the contract. As both sections of the contract are encrypted, no intermediate infrastructure component and no other party including privileged actors can view the contents of the contract. By adding the envWorkloadSignature, the contract can be protected against modification or tampering.\nAttestation\nThe HPVS instance provides an A ttestation Record that is secu rely generated and signed by \nthe HPCR during instance initialization. This Attestation Re", "metadata": {"source": "sg248555.pdf", "chunk_index": 73, "total_chunks": 337}}
{"text": "t is secu rely generated and signed by \nthe HPCR during instance initialization. This Attestation Record is made available to the \ncontainers in this HPVS instance. The signing key is published and can be validated to a 3rd-party certificate authority. Optionally, the Attestation Record can be encrypted by a public key that is defined by the Workload Deployer an d provided in the Contract. It is a best practice \nthat the Auditor provides the public key to the Workload Deployer and is part of the signature of the envWorkloadSignature of the contract. The encryption provides proof to the Auditor that no one can replay the attestation record. \nThe Attestation Record contains measurements of the original base image, the compressed \nroot filesystem, and the cloud initialization options, which include the contract of this HPVS instance. \nAttestation enables the Auditor to validate th e integrity of the HPVS in stance and th e integrity \nof the contract. The Auditor can compare the attestatio", "metadata": {"source": "sg248555.pdf", "chunk_index": 74, "total_chunks": 337}}
{"text": "ty of the HPVS in stance and th e integrity \nof the contract. The Auditor can compare the attestation record against the reference values specific for the HPCR. The Auditor can also compare the checksum of the user data element of the attestation record against the checksum of the expected contract. If this validation succeeds because the checksums are identical, then this proves that the HPVS instance uses the expected  contract. This means that the HPVS instance will run the expected \nenvironment and container images that are defined in the workload section of the contract.\nData volume encryption\nThe data volume that can be a ttached to an HPVS instance is protected by Li nux Unified Key \nSetup (LUKS) volume encryption. The LUKS passphrase is automatically derived from the seeds that are provided by the Workload Provider persona and the Workload Deployer persona. This means that the Workload Provider or the Workload Deployer individually cannot re-create the LUKS passphrase because t", "metadata": {"source": "sg248555.pdf", "chunk_index": 75, "total_chunks": 337}}
{"text": "rkload Provider or the Workload Deployer individually cannot re-create the LUKS passphrase because they know only their respective seed. Also, no other persona or party can re-create the LU KS passphrase because they do not know any \nof the seeds that are used for passphrase derivation.\n1.4.3  Cryptography and Hy per Protect Crypto Service\nA hardware security module (HSM) is a device or service that safeguards and manages \nsecrets, such as cryptographic keys, and pe rforms cryptographic functions such as key \ncreation, key derivation, encryption, decryption, and a signature. An HSM contains one or more cryptographic processors. A cloud HSM is  a cloud service that provides the same \nfunctions as a physical HSM.\nHyper Protect Crypto Services (HPCS) is a hybrid cloud key management service, which is \nbased on FIPS 140-2 Level 4 certified hardware on the IBM LinuxONE or IBM Z platform.\nHPCS supports various programming models like PKCS11 or GREP11. GREP11 is a \nstateless programming model", "metadata": {"source": "sg248555.pdf", "chunk_index": 76, "total_chunks": 337}}
{"text": " supports various programming models like PKCS11 or GREP11. GREP11 is a \nstateless programming model with which cryptographic functions are run in the HSM. Cryptographic material, such as keys, are created in the HSM but are stored outside of the HSM by the client application.\n\n14 Applying Data Protection and Confidentiality in a Hybrid Cloud EnvironmentAn application deployed to HPVS can use a stateless cryptographic API like GREP11 to \ncreate and use cryptographic keys. It can store the keys in the boundary of the HPVS instance on attached devices and use volume encryption and protection of memory and data in use.\nYou can use separation of duty that is enabled  by the contract concept and cloud HSMs to \ndesign and implement advanced cryptographic mechanisms for deriving keys from combined seeds. Combined seeds are a combination of different seeds owned by Workload Provider and Workload Deployer. \n1.4.4  Hyper Protect Secure Build\nThe application container images must be built in a st", "metadata": {"source": "sg248555.pdf", "chunk_index": 77, "total_chunks": 337}}
{"text": " Deployer. \n1.4.4  Hyper Protect Secure Build\nThe application container images must be built in a standardized, repeatable manner, and built by using secure components. The Container  Image Provider persona is responsible for \nfollowing state-of-the-art CI/CD processes and best practices.\nIn addition, the Container Im age Provider can use Hyper Pr otect Secure Build (HPSB) to \nbuild a trusted container ima ge within a secure enclave that  is provided by HPVS. The \nenclave is isolated such that developers can ac cess the container only by using a specific API \nand the cloud administrator cannot access the contents of the container. Therefore, the image that is built can be highly trusted. Specifically, the build server cryptographically signs the image, and a manifest, which is a collection of materials that are used during the build and which can be used for audits. Because the encl ave protects the signing keys, the signatures \ncan be used to verify whether the image and manifest are ", "metadata": {"source": "sg248555.pdf", "chunk_index": 78, "total_chunks": 337}}
{"text": "protects the signing keys, the signatures \ncan be used to verify whether the image and manifest are from the build server, and not elsewhere.\nIn summary, HPSB uses HPVS to protect the bu ild process, the build  results, the build \nevidence, and the signing keys for signing the images and the manifest against malicious privileged actors. This prevents potential ma licious insiders from inserting malware or \notherwise tampering with the application container images and from stealing the signing keys for container image signature.\nMore detailed descriptions of the components that make up the Hyper Protect Platform, as \nwell as some common use cases can be found in Chapter 2, \u201cUnderstanding the solution\u201d on page 15.\n\n\u00a9 Copyright IBM Corp. 2024. 15Chapter 2. Understanding the solution\nWith the integration of IBM Hyper Protect services and confidential computing, you can \nachieve end-to-end data and workload protection in a hybrid cloud environment. The IBM Hyper Protect Platform is a featur", "metadata": {"source": "sg248555.pdf", "chunk_index": 79, "total_chunks": 337}}
{"text": "ta and workload protection in a hybrid cloud environment. The IBM Hyper Protect Platform is a feature of IBM Li nuxONE and IBM Z that offers hardware-level \nsecurity and isolation for virtual servers. It not only protects data and workloads in production, but also allows you to securely build, deploy, and manage mission-critical applications in a \nhybrid cloud environment.\nThe hybrid cloud solution that is discussed in this chapter consists of trusted virtual servers \nand services that ensure your workloads and dat a are always secure, private, and protected \nfrom internal and external threats.\nThis chapter contains  the following topics:\n/SM5900002.1, \u201cIBM Hyper Protect services and a secure hybrid cloud\u201d on page 16\n/SM5900002.2, \u201cIBM Cloud Virtual Private Cloud\u201d on page 18\n/SM5900002.3, \u201cHyper Protect Virtual Server\u201d on page 18\n/SM5900002.4, \u201cHyper Protect Secure Build\u201d on page 24\n/SM5900002.5, \u201cCryptographic agility is th e key to SecDevOps\u201d on page 25\n/SM5900002.6, \u201cHyper Protect C", "metadata": {"source": "sg248555.pdf", "chunk_index": 80, "total_chunks": 337}}
{"text": "900002.5, \u201cCryptographic agility is th e key to SecDevOps\u201d on page 25\n/SM5900002.6, \u201cHyper Protect Crypto Services\u201d on page 25\n/SM5900002.7, \u201cCrypto Express Network API for Secure Execution Enclaves\u201d on page 28\n/SM5900002.8, \u201cStorage and repositories in the cloud\u201d on page 29\n/SM5900002.9, \u201cCommon usages\u201d on page 312\n\n16 Applying Data Protection and Confidentiality in a Hybrid Cloud Environment2.1  IBM Hyper Protect service s and a secure hybrid cloud\nIBM Hyper Protect services that are offered wit h IBM Cloud and the IBM Secure Execution for \nLinux1 on IBM Z and IBM LinuxONE platforms can provide a solution that isolates workloads \nand protects sensitive data throughout its lifecycle, regardless if its state is at rest, in transit, or in use.\nFigure 2-1 illustrates the compon ents of an example secure hybrid cloud solution. The \nsolution consists of a public cloud domain, repr esented by the IBM Cloud, and a private cloud \ndomain, represented by an on-premises cloud. Each cloud domain ", "metadata": {"source": "sg248555.pdf", "chunk_index": 81, "total_chunks": 337}}
{"text": " the IBM Cloud, and a private cloud \ndomain, represented by an on-premises cloud. Each cloud domain has multiple components that provide specific isolat ion and protection capabilities.\nFigure 2-1   Secure hybrid cloud solution example\nThe IBM Cloud Virtual Private Cloud (VPC) domain includes the following components:\n/SM590000Hyper Protect Secure Build. A trusted container image within a secure enclave that is \nprovided by Hyper Protect Virtual Server.\n/SM590000IBM Container Registry (ICR). A highly available, scalable, and encrypted private image \nregistry. A storage and distribution service with public or private images that are used to create containers. The ICR is hosted and managed by IBM.\n/SM590000Hyper Protect Crypto Services . A single-tenant key management service with which you \ncan create, import, rotate, and manage keys with standardized APIs.\n/SM590000IBM Cloud Object Storage (COS). A flexible storage for unstructured data, with additional \nservices like secure encryption", "metadata": {"source": "sg248555.pdf", "chunk_index": 82, "total_chunks": 337}}
{"text": "ge (COS). A flexible storage for unstructured data, with additional \nservices like secure encryption, backup and recovery, data archiving, and fast data transfer.\n1  IBM Secure Execution for Linux allows  you to create a confidential com puting environment that has encrypted \nLinux images running on a public, privat e, or hybrid cloud with data in-use protection. It requires feature codes \n0115 and 3863.\n\n\nChapter 2. Understanding the solution 17The IBM LinuxONE or IBM Z on-premises cloud domain includes the following components:\n/SM590000Hyper Protect Virtual Server. Deploy isol ated workloads, protected by IBM Secure \nExecution for Linux, which is also known as confidential computing or secure enclave. \n/SM590000Hyper Protect Container Runtime. Consists of  different components or services that use \ncertain sections in the  contract to ensure data protection. The HPCR has container \nruntime support, and the image is not SSH enabled. It is a locked-down image. \n/SM590000Block storage.", "metadata": {"source": "sg248555.pdf", "chunk_index": 83, "total_chunks": 337}}
{"text": "ntime support, and the image is not SSH enabled. It is a locked-down image. \n/SM590000Block storage. Allows for the creation of storage volumes to which Linux on IBM Z images \ncan connect. The storage volumes can be encrypted to protect data at rest. \n/SM590000Crypto Express adapters. Tamper sensing and responding FIPS 140-2 level 4 hardware \nsecurity modules (HSMs) that can perform advanced symmetric and asymmetric cryptographic operations and can securely store encryption keys.\n/SM590000Crypto Express Network API for Secure Execution Enclaves. Runs in an IBM Secure \nService Container LPAR and provides a REST API for application access to the Crypto Express adapters and domains.\nThe following Hyper Protect components can be deployed either on-premises or in IBM \nCloud:\n/SM590000Hyper Protect Virtual Server (HPVS)\n2\n/SM590000Hyper Protect Secure Build (HPSB)\n/SM590000IBM Container Registry (ICR)\nThere are advantages to using these components  on IBM Cloud. Because the infrastructure \na", "metadata": {"source": "sg248555.pdf", "chunk_index": 84, "total_chunks": 337}}
{"text": "ry (ICR)\nThere are advantages to using these components  on IBM Cloud. Because the infrastructure \nand management of IBM Cloud are the responsibility of IBM, no on -premises staff need to be \ntrained to operate these resources. On IBM Cloud, the resources are ready to be used. No resource provisioning or acquisition is necessa ry, and no time needs to be spent on design, \ninstall, and setup of the infrastructure.\nThere are also disadvantages to running these components on IBM Cloud. Thought must be \ngiven to the availability of these components, so  redundant internet links or direct links might \nbe needed. \nConsideration should also be given to where the developer staff resides or works. If the staff \nworks remotely, then IBM Cloud might be more suitable for H PSB and ICR as it can be more \neasily accessible to the development staff. \nIf the development staff is on-site, then an on-premises deployment might make more sense \nas it is more easily secured from outside tampering or access", "metadata": {"source": "sg248555.pdf", "chunk_index": 85, "total_chunks": 337}}
{"text": "ises deployment might make more sense \nas it is more easily secured from outside tampering or access violation and can be more readily available as there are no dependencies on external network links. \nThe services and components that make up the secure hybrid cloud solution are described in \nsubsequent sections.\n2  On-premises offerings include HPVS for IBM LinuxON E or IBM Z, and the IBM Cloud offering includes \nHPVS for VPC.Note:  HPSB has documentation for both IBM Cloud deployment  and on-premises \ndeployment .\n\n18 Applying Data Protection and Confidentiality in a Hybrid Cloud Environment2.2  IBM Cloud Virtual Private Cloud\nIBM Cloud Virtual Private Cloud (VPC) is a pu blic cloud offering with which you create a \nprivate cloud computing environment on a shared public cloud infrastructure. Bu using an IBM \nCloud VPC  you can define and control a highly res ilient virtual network that is logically \nisolated from all other public cloud tenants. Hence, creating a private, secure place", "metadata": {"source": "sg248555.pdf", "chunk_index": 86, "total_chunks": 337}}
{"text": " is logically \nisolated from all other public cloud tenants. Hence, creating a private, secure place on the public cloud.\nLike with any other public cloud offering, you can choose the required compute, storage, and \nnetworking resources to be prov isioned with maximum av ailability and scalability, plus various \ncost-effective options. \nIBM Cloud VPC is purpose-built with inherent security to meet regulatory compliance \nstandards, and multiple hardware and software solutions for IaaS, PaaS, and hybrid cloud needs. IBM Cloud VPC has a global network of multizone region s and availability zones for \nquick access, low-cost migration, low latency, and certified security. It supports hybrid or multicloud platforms.\nA VPC can be created in IBM Cloud by following the instructions in Creating and configuring a \nVPC. \n2.2.1  IBM Cloud virtual serv er instance on IBM LinuxONE\nA virtual server instance on IBM LinuxONE is an IBM Cloud VPC option that can be used to \nhelp migrate or recompile compo", "metadata": {"source": "sg248555.pdf", "chunk_index": 87, "total_chunks": 337}}
{"text": "ance on IBM LinuxONE is an IBM Cloud VPC option that can be used to \nhelp migrate or recompile components to the s390x instruction set architecture (ISA). This option can also be used to test container-based workloads and solutions before their deployment within an HPVS as de scribed in 2.3, \u201cH yper Protect Virtual  Server\u201d on page 18. \nAll this with security and compliance in mind.\nThe IBM Cloud Virtual Private Cloud (VPC) user interface (UI) can be used to create virtual \nserver instances with simple steps. For more information, see Virtual server for VPC .\nThe available s390x instance profiles  and s390x virtual server images  can be selected based \non your requirements. \n2.3  Hyper Protect Virtual Server\nAn HPVS takes advantage of IB M Secure Execution for Linux to create a se cure boundary \naround each workload, which ensures unauthorized users do not have access to the workload or data. Workloads are locked down by  individual, instance-level, secure enclaves. \nFigure 2-2 on page", "metadata": {"source": "sg248555.pdf", "chunk_index": 88, "total_chunks": 337}}
{"text": "data. Workloads are locked down by  individual, instance-level, secure enclaves. \nFigure 2-2 on page 19 illustrates the components that make up the Hyper Protect Platform. \nFor example, the Hyper Protect Container Runtime (HPCR) includes the Bootloader and Hyper Protect Services to validate the authenti city and trust of the workload. This section \nprovides an outline of the architectural components such as contracts with separation of duty, volume encryption, attestation, and Hyper Protect services.\n\nChapter 2. Understanding the solution 19Figure 2-2   Technical assurance - Hyper Protect Platform\n2.3.1  Bootloader\nThe bootloader is the first part of the Linux start-up process that brings up a KVM virtual \nmachine.\nThe bootloader is responsible for the following:\n/SM590000Setting up the LUKS encrypted boot partition.\n/SM590000Writing the Operating System into the boot partition.\n/SM590000Decrypting the user provided contract and placing a decrypted copy in a known file system \nlocation", "metadata": {"source": "sg248555.pdf", "chunk_index": 89, "total_chunks": 337}}
{"text": "0Decrypting the user provided contract and placing a decrypted copy in a known file system \nlocation to be processed by the other components after the boot completes. The bootloader destroys the private key after decryption. \n/SM590000Writing a cryptographically signed attest ation document of various checksums of \nimportant components.\nAll steps are done at every boot. That means that the root volume file system is not persistent \nacross reboots. All remote access such as SSH or login through a serial console are disabled by default.\n2.3.2  Volume encryption\nBoth the root vo lume and user data volumes in th e HPVS instance are automatically \nencrypted with Linux Unified Key Setup (LUKS) encryption. The root volume is re-created and encrypted during every boot, with the original content provided with the HPCR image. A passphrase for the root volume is not stored.\nUser data volume encryption is configured by using the\n seed that is provid ed in the workload \nand env sections of the cont", "metadata": {"source": "sg248555.pdf", "chunk_index": 90, "total_chunks": 337}}
{"text": "ion is configured by using the\n seed that is provid ed in the workload \nand env sections of the contract. During the HPVS instance initiation, the volumes are attached and encrypted by using the seed to create a LUKS passphrase. If the seed information or the user data volume is not configured, the HPVS instance fails to initiate.\n\n\n20 Applying Data Protection and Confidentiality in a Hybrid Cloud EnvironmentEach hour the volume encryption status check daemon examines the crypto headers of the \nroot volume and user data vo lumes that are attached to th e HPVS instance, and then writes \nthe information messages about volume encryption status into the log.\n2.3.3  Description of the contract\nThe implementation of the Hyper Protect Platform includes, in part, an encrypted secure execution image, the HPCR image. The contract is passed into an HPCR image as user data through the \ncloud-init  process3. To protect the contract from any type of intrusion, a public \nand private key pair4 is crea", "metadata": {"source": "sg248555.pdf", "chunk_index": 91, "total_chunks": 337}}
{"text": "rocess3. To protect the contract from any type of intrusion, a public \nand private key pair4 is created by an IBM internal bu ild pipeline for the HPCR image. This \nkey pair allows for the encryption of the contract sections. The public X509 certificate of the contract encryption public key is published by IBM and can be validated by any persona with the 3rd party certificate authority root key.\nEach persona, like the Workload Provider or the Workload Deployer can independently \nencrypt their contract section by using this contract en cryption public key. The contract \nencryption private key exists only inside the secure execution-encrypted HPCR image. This image can be decrypted by using only secure execution and keys that are rooted in hardware of an IBM LinuxONE or IBM Z platform. During  deployment of an HPVS instance, this key is \nused by the Bootloader component to decrypt the contract.\nContract enforcement withi n the HPCR image ensures the following conditions:\n/SM590000The con", "metadata": {"source": "sg248555.pdf", "chunk_index": 92, "total_chunks": 337}}
{"text": "ract.\nContract enforcement withi n the HPCR image ensures the following conditions:\n/SM590000The contract cannot be deployed outside of the HPCR image.\n/SM590000Secrets contained inside the contract cannot be retrieved outside the HPCR image.\n/SM590000Only containers that are spec ified by the Workload Provider  can run in the HPVS instance.\n/SM590000The Workload Provider and Workload Deployer can independently provide their section of \nthe contract, sharing only the contra ct section after it is encrypted.\n/SM590000User data volumes are encrypted based on the secret seeds that are contained in the \ncontract.\n/SM590000Data volumes can be reattached to a new H PVS instance if the same  secret seeds are \ndefined within the contracts.\nThis concept of contract enforcement allows the Workload Provider, the Workload Deployer, \nand the Auditor personas to cooperate and ensure confidentiality and integrity of the information: \n/SM590000The Workload Provider creates and encrypts the workload se", "metadata": {"source": "sg248555.pdf", "chunk_index": 93, "total_chunks": 337}}
{"text": "d integrity of the information: \n/SM590000The Workload Provider creates and encrypts the workload section and passes it securely \nto the Workload Deployer. \n/SM590000The Auditor creates the attestationPublicKey and passes it securely to the Workload \nDeployer.\n/SM590000The Workload Deployer creates the env section for the contract.\n/SM590000The Workload Deployer combines the \nenv workload  and attestationPublicKey  sections, \nand calculates and adds the signature across the env and workload sections.\n/SM590000The Workload Deployer provides the contract in its user data  section at provision time.\n3  This software package (cloud-init) autom ates the initialization of virtual server instances during system boot.\n4  A public key is part of the owner's digital certificate and is  available for anyone to use. However, a private key is \nprotected by and available only to the owner of the key.\n\nChapter 2. Understanding the solution 212.3.4  The attestation record\nThe attestation record is pro", "metadata": {"source": "sg248555.pdf", "chunk_index": 94, "total_chunks": 337}}
{"text": "\nChapter 2. Understanding the solution 212.3.4  The attestation record\nThe attestation record is provided to the workload in the file system in the directory \n/var/hyperprotect. T he workload can then make this record available outside the HPVS \ninstance and ultimately to the Auditor persona. The Auditor can verify the record and verify that deployment has occurred into an HPVS instance before any data is accessible to the workload.\nRefer to 3.4, \u201cAttestation\u201d on page 54 for more information. \n2.3.5  Logging\nAll components log to syslog as the central place for logs. Log output is forwarded to the \ningestion backend defined in the contract. The components do not log any sensitive pieces of information, such as PI data or credentials. The detail level of logging can differ from component to component, but the guiding principle is to provide enough information to identify problems without flooding the logs.\nErrors are logged once, by using the error log level. Each error features a uniqu", "metadata": {"source": "sg248555.pdf", "chunk_index": 95, "total_chunks": 337}}
{"text": "flooding the logs.\nErrors are logged once, by using the error log level. Each error features a unique identifier for \nthe issuing component and the error situation. These identifiers are part of the API of HPCR, so they can be used in automation components to react on error situations. Identifiers are kept stable across semantic releases.\n2.3.6  Hyper Protect layer services\nThe Hyper Protect Platform uses layer services within the HPCR image that validate a user contract signature, validate the authentication of registries, validate the integrity of OCI images being brought up within the HPVS inst ance, encrypt th e volumes, and ensure the \nconfidentiality by not allowing access to the HPVS instance.\nThe Hyper Protect layer consis ts of the following services: \n/SM590000Logging service\n/SM590000Contract validation service\n/SM590000Registry authentication service\n/SM590000Image service\n/SM590000Signature service\n/SM590000Storage service\n/SM590000LUKS passphrase service\n/SM590000Containe", "metadata": {"source": "sg248555.pdf", "chunk_index": 96, "total_chunks": 337}}
{"text": "M590000Signature service\n/SM590000Storage service\n/SM590000LUKS passphrase service\n/SM590000Container service\n/SM590000Catch service\nLogging service\nThe logging component is responsible for the setup of the logging configuration. This \nconfiguration is available in the contract and allows a Workload Deployer to configure a  \nlogging backend, such as Mezmo , or a custom backend compatible with the rsyslog protocol. \nThe logging component validates the configuration and transforms it into a configuration for the rsyslog component that is used as a log forwarder.\nIf the logging configuration is in valid, this is indicated on the serial console, and the start of \nthe virtual server  instance fails.\n\n22 Applying Data Protection and Confidentiality in a Hybrid Cloud EnvironmentContract validation service\nThe contract validation component validates the contract syntactically and semantically \nagainst a JSON schema. If validation fails, so does the start of the virtual server instance.\nRegistr", "metadata": {"source": "sg248555.pdf", "chunk_index": 97, "total_chunks": 337}}
{"text": "gainst a JSON schema. If validation fails, so does the start of the virtual server instance.\nRegistry authen tication service\nThe registry authentication component assembles all credentials in the contract that are \nrequired to authenticate against a remote container registry and transforms them into the configuration format required by the OCI runtime.\nImage service\nThe image service assembles all information in the contract related to the validation of OCI \nimages, for example, Red Hat signatures, and converts them into the format that is required by the OCI runtime.\nSignature service\nThe signature service verifies the optional contract signature.\nStorage service\nThe storage service initializes attached storage volumes according to their configuration in the contract. It creates necessary partitions, encrypts them through LUKS2 encryption or opens an existing LUKS2 encrypted layer. After the successful execution of the storage service, storage is mounted to the file system ready to b", "metadata": {"source": "sg248555.pdf", "chunk_index": 98, "total_chunks": 337}}
{"text": "er the successful execution of the storage service, storage is mounted to the file system ready to be consumed by OCI images.\nLUKS passphrase service\nThe LUKS passphrase service computes the pass phrase that is used for LUKS2 encryption \nof the storage volumes.\nContainer service\nThe container service is responsible for starti ng the OCI images by using the OCI runtime of \nchoice. After the successful execution of this service, the configured containers are running.\nDepending on the selection within the workload section of the contract, a different container \nservice is used to run the container. When specifying the compose subsection within the \ncontract, docker compose will be used. When specifying the play subsection within the \ncontract, podman kube will be used. Refer to 3. 1.1, \u201cThe workload sect ion\u201d on page 39 for \nconfiguration details. \nCatch service\nThe catch service monitors the successful start of  the other services. If there is failure, it will \nautomatically shut down th", "metadata": {"source": "sg248555.pdf", "chunk_index": 99, "total_chunks": 337}}
{"text": "he successful start of  the other services. If there is failure, it will \nautomatically shut down the VSI after a grace period.\n2.3.7  Hyper Protect Vi rtual Server for VPC\nThe HPVS for VPC is built in the IBM Cloud Vi rtual Private Cloud (VPC ) infrastructure for \nextra network security. You can choose from various profile sizes and grow as needed to protect containerized applications, and you ca n pay-as-you-go on an hourly basis. You can \nalso use existing or common network security groups  and logging  infrastructure.\nWhen using IBM Cloud services, there is no need to understand the intricacies of their \nphysical deployment of the infrastructure. De ployment of the services happen automatically \nas part of the managed-service offering. The provisioning process itself depends on a \ncontract as input in the user-data field in the IBM Cloud UI for HPVS for VPC.\n\nChapter 2. Understanding the solution 23HPVS for VPC with Secure Exec ution can be provisioned from the IBM Cloud portal Vir", "metadata": {"source": "sg248555.pdf", "chunk_index": 100, "total_chunks": 337}}
{"text": " the solution 23HPVS for VPC with Secure Exec ution can be provisioned from the IBM Cloud portal Virtual \nPrivate Infrastructure by a registered IBM cloud subscriber. The IBM Cloud command line interface, ibmcloud, can be used to create an instance of HPVS for VPC by selecting the ibm-hyper-protect-container-runtime (HPCR) stock image and the appropriate Secure \nExecution Profile. The HPCR stock image that is associated with the Hyper Protect operating system is periodically updated to provide security fixes and new functionality. To be able to use an updated stock image, depl oy a new instance of HPVS for VPC using your contract and \nthe current version of the HPCR image.\n2.3.8  Hyper Protect Virtual Serv er for IBM LinuxONE and IBM Z\nThe HPVS for IBM LinuxONE and IBM Z is a private, on-premises, cloud deployment solution \nwhere containers can be initiated as KVM guests that run an HPCR image, as shown in Figure 2-2 on page 19. \nThe Secure Execution on Linux feature ( 0115) and CP Ass", "metadata": {"source": "sg248555.pdf", "chunk_index": 101, "total_chunks": 337}}
{"text": " image, as shown in Figure 2-2 on page 19. \nThe Secure Execution on Linux feature ( 0115) and CP Assist for Cryptographic Function \n(CPACF) feature ( 3863 ) are required to enable confidentiality and integrity by protecting and \nisolating the data at the virtual machine (KVM guest) level.\nTo learn how to setup a KVM host LPAR and start KVM guest images, see  Introducing IBM \nSecure Execution for Linux .\n2.3.9  Considerations when depl oying workloads in HPVS instances\nIt is generally accepted that the adoption of  cloud-native principles in a hybrid cloud \nenvironment can enable workloads to become more cost-effective and convenient to run as separate components by using a microservices approach. Microservices typically have their \nown technology stack, including the database and data management, and communicate with other microservices over REST APIs.\nMultiple HPVS instances can be used for each microservice with the infrastructure providing \nthe necessary capabilities to secure netwo", "metadata": {"source": "sg248555.pdf", "chunk_index": 102, "total_chunks": 337}}
{"text": " for each microservice with the infrastructure providing \nthe necessary capabilities to secure networking communicati on between them. Even in the \nabsence of cloud native orchestration such as  Kubernetes, independent scaling of services \nand independent upgrades or updates of services can be achieved.\nFor example, you can use auto mation tools and cloud servic es to deploy multiple HPVS \ninstances and implement failover, load balancing,  and scaling and elimin ate single points of \nfailure. \nTypically, with state-of-the-art cloud services  and automation tools no human intervention is \nrequired during failure events as the requests can be automatically routed around failures. Therefore, do not start multiple independent workloads or microservices within the same HPVS instance.\nEach instance should be a single unified worklo ad or microservice, which can be composed \nof multiple containers. The containers that are specified in a contract are assumed to be mutually dependent, so if dep", "metadata": {"source": "sg248555.pdf", "chunk_index": 103, "total_chunks": 337}}
{"text": "ers. The containers that are specified in a contract are assumed to be mutually dependent, so if deployment of one container fails then the workload stops.\nAs an expected practice, HPVS instances are intended to be deleted and re-created during \nthe lifetime of a workload. Changes to the root volume do not persist after reboot, so be aware of the following conditions and behaviors: \n/SM590000A contract is set when an HPVS instance is deployed and cannot be changed. \n/SM590000HPVS instances cannot be upgr aded. Theref ore, snapshots of the attached boot volumes \nare not recommended.\n\n24 Applying Data Protection and Confidentiality in a Hybrid Cloud Environment/SM590000Updated OCI container images require a new contract, and a new HPVS instance must be \ndeployed.\n/SM590000Updated API keys, passwords, and so on, require a new contract and a new HPVS \ninstance deployment.\n/SM590000An updated HPCR image requires a new HPVS in stance. The previous contract can be \nreused if the encryption ke", "metadata": {"source": "sg248555.pdf", "chunk_index": 104, "total_chunks": 337}}
{"text": " HPCR image requires a new HPVS in stance. The previous contract can be \nreused if the encryption keys for the updated HPCR image are unchanged from the prior image.\n/SM590000Reboot re-pulls container images although ro ot volume changes are not persistent. This \nmeans that contract de tails relating to pulling images mu st remain valid through all HPVS \ninstance reboots after creation.\n/SM590000No workload data should be held on root or boot volumes. The workload data is deleted by \na reboot or update.\n/SM590000Externally attached data volumes have an independent lifecycle and can be reattached to \nthe HPVS instance assuming that  contract sections relating to storage remain consistent.\nTools such as Te rraform can help make generating new contra cts and replacing HPVS \ninstances straightforward. For more information, see 4.1.9, \u201cDeployment automation - Terraform\u201d on page 70.\n2.4  Hyper Protect Secure Build\nAccording to OWASP-SAMM , the Secure Build practice must emphasize the importa", "metadata": {"source": "sg248555.pdf", "chunk_index": 105, "total_chunks": 337}}
{"text": " Protect Secure Build\nAccording to OWASP-SAMM , the Secure Build practice must emphasize the importance of \nbuilding software in a standardized, repeatable manner, and doing so by using secure components. \nThe goal is to reach a Software Assurance Maturi ty Model (SAMM) maturity-level of three in \nthe build process to help  with the following tasks: \n/SM590000Prevent known defects from entering the production environment\n/SM590000Define mandatory security c hecks and ensure that building non-compliant artifacts fails\n/SM590000Analyze the dependencies used for security issues \nSecurity should be effective and at the same time it should not be cumbersome to implement \nbest practices for the following personnel that participate in the secure build process: \n/SM590000Cloud administrators. Create the Secure Build Server and register the repository for the \napplication developer\n/SM590000Application developers. Use the Secure Build Server to build and deploy applications from \na GitHub repos", "metadata": {"source": "sg248555.pdf", "chunk_index": 106, "total_chunks": 337}}
{"text": "cation developers. Use the Secure Build Server to build and deploy applications from \na GitHub repository\nBy using HPSB, a trusted container image can be built within a secure enclave that is \nprovided by IBM HPVS. The enclave is highly  isolated, where deve lopers can access the \ncontainer only by using a specific API and the cloud administrator cannot access the contents of the container. Therefore, the image that is bu ilt can be highly trusted. Specifically, the build \nserver cryptographically signs the image, and a manifest for audit purposes. The manifest is a collection of materials that are used during the build. Because the enclave protects the signing keys within the enclave, the signatures can be used to verify that the image and \nmanifest files are from the HPSB.\nThe HPSB can be used to securely build source code from a GitHub repository, publish the \nbuilt image to a repository like Docker hub or IBM Container Registry  and deploy the built \nimage as an HPVS instance.\n\nCha", "metadata": {"source": "sg248555.pdf", "chunk_index": 107, "total_chunks": 337}}
{"text": "ory like Docker hub or IBM Container Registry  and deploy the built \nimage as an HPVS instance.\n\nChapter 2. Understanding the solution 25For more details and sample configuration files, see I BM Hyper Protect Secure Build .\n2.5  Cryptographic agility is the key to SecDevOps\nCryptographic algorithms can break or become weak or obsolete over time. \nRecommendations and regulations on which cryptography to use often change. Therefore, businesses and organizations must replace the underlying cryptography that they use today, \nand it is not the only  time such a change will be requ ired. For more in formation, see NIST \nCryptographic Algorithm Validation Program .\nWith change comes also an opportunity to rethink how applications use complex \ncryptography such that future enhancements, updates, and patches are simpler to apply. For that reason, the ability to rapi dly change cryptograph ic algorithms and key strengths used to \nencrypt and sign data becomes essential. \nWhen thinking about cryp", "metadata": {"source": "sg248555.pdf", "chunk_index": 108, "total_chunks": 337}}
{"text": "rithms and key strengths used to \nencrypt and sign data becomes essential. \nWhen thinking about cryptographic agilit y, consider the following requirements:\n/SM590000Build a cryptographic inventory and create a roadmap: \n\u2013 Build a cryptographic inventory as a reusable security asset where crypto is used \n\u2013 Perform a risk assessment and gap analysis \u2013 Evaluate vendor products \u2013 Develop plans for use of stronger cryptography \u2013 Understand the open source effect \u2013 Use a bottom-up approach \n/SM590000Design and run with crypto graphic agility in mind: \n\u2013 Manage internal and external dependencies\n\u2013 Make it simple to change underlying algorithms, methods, or protocols \u2013 Verify changes by automating as much as possible\u2013 Prepare for future changes \nDevelop new applications to be as flexible as possible to react to new situations. \n2.6  Hyper Protect Crypto Services\nHyper Protect Crypto Services  (HPCS) is a dedicated key management service (KMS) and \nhardware security module (HSM) that is built ", "metadata": {"source": "sg248555.pdf", "chunk_index": 109, "total_chunks": 337}}
{"text": "HPCS) is a dedicated key management service (KMS) and \nhardware security module (HSM) that is built on the technical assurance of the Hyper Protect \nPlatform (see Figure 2-3 on page 26). \n\n26 Applying Data Protection and Confidentiality in a Hybrid Cloud EnvironmentFigure 2-3   HPCS - high-level view\nHPCS is built on a FIPS 140-2 Level 4-certified HSM. With HP CS, you have complete control \nof your encryption keys for cryptographic operationservice that is known as keep your own key (KYOK). This is in contrast to bring your own key (BYOK) based services. For a detailed comparison on why KYOK is better than BYOK, refer to How is Keep Your Own Key different \nfrom Bring Your Own Key?\nWith the Unified Key Orchestrator (UKO) functi on you can perform encryption key lifecycle \nmanagement from a single pane of glass on IBM Cloud into other cloud environments like AWS, Azure, and Google Cloud. UKO also doubles up as a repository for all encryption keys that can be synced and pushed to multiple", "metadata": {"source": "sg248555.pdf", "chunk_index": 110, "total_chunks": 337}}
{"text": "KO also doubles up as a repository for all encryption keys that can be synced and pushed to multiple keystores with the push of a button. \nHPCS allocates physical crypto-units to every instance provisioned on IBM Cloud in \naccordance with MZR Load Balancing and High Av ailability standards. In  some geographies, \nHPCS also provides cross-regional availab ility to protect the cust omers from regional \ndisasters. \nFor more information, refer to Hyper Protect Crypto Services  and Hyper Protect Crypto \nServices General FAQs .\n2.6.1  Accessing cryptogr aphic services with HPCS\nHPCS supports multiple APIs and programming models that are integrated with other \nservices in the IBM Cloud. HPCS services are accessible from the IBM Cloud UI and programmatically over public and private endpoints. A whole suite of middleware, such as object storage, open data foundation (ODF) cl usters, Kubernetes clusters, databases, load \nbalancers, and so on, can in tegrate seamlessly with HPCS.\nAuthentication a", "metadata": {"source": "sg248555.pdf", "chunk_index": 111, "total_chunks": 337}}
{"text": "usters, databases, load \nbalancers, and so on, can in tegrate seamlessly with HPCS.\nAuthentication and authorization of access to the resources in IBM Cloud is done by IBM \nCloud Identity and Access Management . Applications accessing HPCS through the \nendpoints must do so with an API-Key, which is part of a Service-ID, which in-turn, is a part of an Access Group.\n\n\nChapter 2. Understanding the solution 27HPCS offers the following applicatio n programming interfaces (APIs):\n/SM590000Key Protect API\n/SM590000GREP11 API\n/SM590000PKCS#11 API\nKey Protect API \nHPCS supports Key Lifecycle Management activi ties like creating, maintaining, protecting, \nand deleting cryptographic keys along with other Key Actions like:\n/SM590000Wrap a Key. Use a root key to wrap or encrypt a data encryption key (DEK)\n/SM590000Unwrap a Key. Use a root key to unwrap or decrypt a data encryption key\n/SM590000Rewrap a Key. Use a root key to rewrap or re-encrypt a data encryption key\n/SM590000Rotate a Key. Create a", "metadata": {"source": "sg248555.pdf", "chunk_index": 112, "total_chunks": 337}}
{"text": " a Key. Use a root key to rewrap or re-encrypt a data encryption key\n/SM590000Rotate a Key. Create a new version of a root key\n/SM590000Set a key for deletion\n/SM590000Unset a key for deletion\n/SM590000Enable a key\n/SM590000Disable a key\nFor more details on how to perform the previously listed actions, see IBM Cloud Key Protect \nMethods .\nGREP11 API \nThe FIPS 140-2 Level 4 HSM that HPCS uses is built on the IBM Crypto Express features \noperating in EP11 mode. EP11 is a stateless API5, which provides functionality similar to the \nindustry-standard Public-Key Cryptography Standards (PKCS) #11 API. PKCS #11 API \ndefines a platform-independent API to cryptographic tokens, such as hardware security modules (HSM) and smart cards. Existing applications can use PKCS #11 to benefit from enhanced security with secure key cryptography and from the stateless programming model, which makes the cryptographic operations much more efficient and scalable. \nFor more inform ation about EP11 capabilit ies", "metadata": {"source": "sg248555.pdf", "chunk_index": 113, "total_chunks": 337}}
{"text": "graphic operations much more efficient and scalable. \nFor more inform ation about EP11 capabilit ies and extensions, see Enterprise PKCS #11 \nintroduction .\nHPCS provides a set of EP11 over gRPC (GREP11) API calls, with which the cryptographic \nfunctions are run in the cloud HSM of HPCS. The GREP11 API is a stateless interface for \ncryptographic operations on the cloud that is based on EP11 and gRPC. \nAn application deployed to HPVS can use a stateless cryptographic API like GREP11 to \ncreate and use cryptographic ke ys. With GREP11, cryptographic material like keys is created \nin the HSM, but is stored outside of the HSM by the client application. \nThe application can store the keys in the b oundary of the HPVS inst ance on atta ched devices \nand use volume encryption and protection of memory and data in use. \nYou can use the features that are provided by HPVS, such as separation of duty, with features \nof HPCS to design and implement advanced cr yptographic mechanisms for deriving ke", "metadata": {"source": "sg248555.pdf", "chunk_index": 114, "total_chunks": 337}}
{"text": "y, with features \nof HPCS to design and implement advanced cr yptographic mechanisms for deriving keys \nfrom combined seeds. The combined seeds are a combination of different seeds that are owned by the Workload Provider and Workload  Deployer, and defined in the respective \nsections of the contract.\n5  Stateful services keep track of sessions or information about previous or pending interactions or transactions and \nthus react differently to the same inputs based on that information. Stateless services do not maintain such \ninformation on the side of the service, but rely on clients to maintain \u201cstate\u201d information about sessions or previous \ninteractions.\n\n28 Applying Data Protection and Confidentiality in a Hybrid Cloud EnvironmentRefer to \u201cHow encryption keys are created using GREP11\u201d on page 124 for more information. \nThe topic describes using the stateless capabilities of the EP1 1 interface by keeping state \ninformation like encryption keys, seed-parts and  backup-key parts insi ", "metadata": {"source": "sg248555.pdf", "chunk_index": 115, "total_chunks": 337}}
{"text": "interface by keeping state \ninformation like encryption keys, seed-parts and  backup-key parts insi de secure enclaves \ncreated for an HPVS.\nPKCS#11 API \nHPCS also provides a PKCS#11 library that allows  user applications to interact directly with \nthe FIPS 140-2 Level 4 HSM through the PKCS#11 API. PKCS11 is a standard that specifies an API, called Cryptoki, to perform cryptographic operations. The Cryptoki API follows a simple object-based approach by presenting to applications a common, logical view of the \nHSM, called a cryptographic token.\nCryptoki isolates an application from the details of the cryptographic device, which makes the \napplication portable and usable with any cryp tographic device that supports the PKCS#11 \nstandard. For more information on cryptographic functions supported by HPCS, refer to: Introducing PKCS#11 . \n2.7  Crypto Express Network AP I for Secure Execution Enclaves\nWith Crypto Express Network API for Secure Execution Enclaves, REST API is used to \nconfig", "metadata": {"source": "sg248555.pdf", "chunk_index": 116, "total_chunks": 337}}
{"text": " Enclaves\nWith Crypto Express Network API for Secure Execution Enclaves, REST API is used to \nconfigure the c16 server, which provides gRPC API to access Crypto Express domains that are assigned to the IBM Z or IBM LinuxONE LP AR. After the configuration, your applications \ncan access the c16 gRPC API through the IBM GREP11 interface, provided by the GREP11 server, to securely connect from a Secure Execution for Linux LPAR to the Crypto Express domains. It is possible to enable the c16 server to send logs to a configured Rsyslog server to view logs.\nFigure 2-4 illustrates an architec ture overview of Crypto Ex press Network API for Secure \nExecution for Linux.\nFigure 2-4   Architecture overview of Crypto Express Network API\n\n\nChapter 2. Understanding the solution 292.7.1  Security considerations\nThe Crypto Express Network API for Secure Ex ecution Enclaves' REST API is critical for \nconfiguring and managing the c16 server, so it must never be accessed by any untrusted person or system.", "metadata": {"source": "sg248555.pdf", "chunk_index": 117, "total_chunks": 337}}
{"text": "iguring and managing the c16 server, so it must never be accessed by any untrusted person or system. Users are resp onsible for controlling access to  the API to keep it secure.\nThe c16 API invokes crypto operations on Crypto Express domains that are made accessible \nby the Crypto Express Network API for Secure  Execution Enclaves. Therefore, the c16 API \nmust be kept secure, and it is not recommended to expose the c16 API over a public network. The c16 API is protected through mTLS with the certificate authority (CA) configured through the Crypto Express Network API. Anyone with a valid certificate that the CA issues can \naccess the API. Users are responsible for controlling access to the CA and issuing client certificates only to trusted clients.\nFor more information, see Crypto Express Network API fo r Secure Execution Enclaves .\n2.8  Storage and repositories in the cloud\nData storage requirements can vary by use case. Applications at the front end of interaction \nwith clients need ", "metadata": {"source": "sg248555.pdf", "chunk_index": 118, "total_chunks": 337}}
{"text": " requirements can vary by use case. Applications at the front end of interaction \nwith clients need to be responsive. Any data that is handled by these applications must be accessible to meet the response time requirements of the application. Because of the distributed nature of applications running in the cloud, the application design can be simpler with a design that is independent of storage. For example, the application developer might decide to outsource the data ava ilability requirements to a data service. In such cases, the \ninfrastructure provider must provide several options for data storage, based on latency and access pattern. The provider must also allow data to be moved seamlessly from one storage platform to another. Also, data protection concerns, which are inherent to a cloud environment for data at rest, might require that all storage services be connected to an available key management system. \nData in IBM Cloud storage services, such as cloud object storage, block s", "metadata": {"source": "sg248555.pdf", "chunk_index": 119, "total_chunks": 337}}
{"text": "le key management system. \nData in IBM Cloud storage services, such as cloud object storage, block storage, and file \nstorage, is encrypted by default using randomly generated keys. For added security, you can also use HPCS to create and keep your own root keys\n6 to protect your data through envelope \nencryption.7\nThe following subsections describe the different storage options in a cloud environment.\n2.8.1  Cloud object storage\nIBM Cloud Object Storage (COS) is an industry-leading cloud service that is ideal for storing large volumes of data. It  provides best-in-class security an d data durability at near-infinite \nscalability, complemented  with immutable data retention, audit controls and continuous \ncompliance, which is ideal for meeting the demands of business and regulatory requirements.Note:  The GREP11 client and the GREP11 server are shown in the same KVM host LPAR. \nHowever, the GREP11 client can run anywhere that has connectivity to the GREP11 server if the environment is t", "metadata": {"source": "sg248555.pdf", "chunk_index": 120, "total_chunks": 337}}
{"text": "he GREP11 client can run anywhere that has connectivity to the GREP11 server if the environment is trusted.\n6  The root key is generated by using AES 256\n7  Envelope encryption is the pr actice of encrypting data with a data encryption key (DEK) and then wrapping the \nDEK with a root key that is kept inside HPCS, which you can fully manage.\n\n30 Applying Data Protection and Confidentiality in a Hybrid Cloud EnvironmentCOS has built-in integration with other services in IBM Cloud and security services. Access to \nCOS is available for applicatio ns and services from inside IBM Cloud, other cloud services \nand on-premises through RESTful APIs that are exposed on public and private network endpoints. Data in COS can be protected with encryption keys that are obtained from key management systems like HPCS. \nOther cloud service providers offer object storage like S3 from AWS and Azure Blob Storage \nfrom Azure. For more information, see IBM Cloud Object Storage .\n2.8.2  Block storage\nBlock sto", "metadata": {"source": "sg248555.pdf", "chunk_index": 121, "total_chunks": 337}}
{"text": "age \nfrom Azure. For more information, see IBM Cloud Object Storage .\n2.8.2  Block storage\nBlock storage, sometimes referred to as block-level storage, is a technology that is used to \nstore data files on storage area networks (SANs) or cloud-based storage environments. Block storage divides data into blocks and then stores those blocks as separate pieces, each with a unique identifier. The SAN places those blocks of  data wherever it is most efficient. That \nmeans it can store those blocks across different systems and each block can be configured or partitioned to work with different operating systems.\nBlock storage allows for the creation of raw storage volumes to which server-based operating \nsystems can connect. Block storage also decouples data from user environments, allowing that data to be spread across multiple environments. This creates multiple paths to the data and allows the user to retrieve it quickly. When a user or application requests data from a block storage system, ", "metadata": {"source": "sg248555.pdf", "chunk_index": 122, "total_chunks": 337}}
{"text": " user to retrieve it quickly. When a user or application requests data from a block storage system, the underlying storage system reassembles the data blocks and presents the data to the user or application.\nBlock Storage services in IBM Cloud are av ailable in the VPC environments. For more \ninformation, see What is block storage? .\n2.8.3  File storage\nFile storage, which is also referr ed to as file-level or file-based storage, is normally associated \nwith Network Attached Storage (NAS) technology. NAS presents storage to users and applications by using the same ideology as a tr aditional network file system. In other words, \nthe user or application receives data through directory trees, folders, and individual files. This functions similarly to a local hard disk. However, NAS or the Network Operating System (NOS) handle access rights, file sharing, file locking, and other controls.\nFile storage can be easy to configure, but access to data is constrained by a single path to the \ndata", "metadata": {"source": "sg248555.pdf", "chunk_index": 123, "total_chunks": 337}}
{"text": "le storage can be easy to configure, but access to data is constrained by a single path to the \ndata, which can impact performance compared to block or object storage. File storage also operates only with common file-level protocols, such as a New Technology File System (NTFS) for Windows or a Network File System  (NFS) for Linux. This might limit usability \nacross dissimilar systems. Fo r more information, see: What is file storage? .\n2.8.4  On-premises storage\nOn-premises storage is categorized according to principles of storage tiering that assigns \ndata to various categories of storage media based on requirements such as cost, availability, \nperformance, and recovery objectives. Recovery objectives are usually stated as Recovery Time Objective (RTO) and Recovery Point Ob jective (RPO) policies,  which are crucial \ncomponents of an organization\u2019s data life cycle strategy.\nStorage tiering is a component of Information Lifecycle Management (ILM) that helps \norganizations minimize stor", "metadata": {"source": "sg248555.pdf", "chunk_index": 124, "total_chunks": 337}}
{"text": "ing is a component of Information Lifecycle Management (ILM) that helps \norganizations minimize storage costs and ensures performance and compliance. Storage tiering is applied to the following data classes:\n\nChapter 2. Understanding the solution 31/SM590000Mission critical. For data that should not ex perience any downtime and is usually assigned \nto the fastest storage devices like Fl ash and electronic storage devices.\n/SM590000Hot. For data that needs to be accessed frequently to support business-critical \napplications such as Customer Relationship Management (CRM) and Enterprise Resource Planning (ERP). This category also requires the fastest storage.\n/SM590000Warm. For data that is accessed less frequently. This kind of data can be stored on \nmedium-speed storage devices like disk storage\n/SM590000Cold. For data that might never be accessed again but must be retained for the \norganization to meet regulatory requirements. Such data is usually saved on tape and other archival stora", "metadata": {"source": "sg248555.pdf", "chunk_index": 125, "total_chunks": 337}}
{"text": "ization to meet regulatory requirements. Such data is usually saved on tape and other archival storage devices.\nLUKS encryption with envelope encryption of the root keys in HPCS can be used to protect \ndata for on-premises storage. For a tutorial, see Protect LUKS encryption keys with IBM cloud \nHyper Protect Crypto Services and IBM Key Protect .\nFor more information on various st orage devices and solutions, see IBM Storage .\n2.9  Common usages\nIn general, any application that either uses sensitive data or secrets, or comprises sensitive \ncode, or needs to conform to compliance and regulatory requirements can take advantage of confidential computing with the Hyper Protect Platform.\nThis section discusses multiple exemplary use cases and explains how the Hyper Protect \nPlatform can be used to implement it. In particular, these use cases are discussed:\n/SM590000Securely bring applications to hybrid cloud\n/SM590000Digital assets infrastructure\n/SM590000Confidential AI\n/SM590000Secure mul", "metadata": {"source": "sg248555.pdf", "chunk_index": 126, "total_chunks": 337}}
{"text": " to hybrid cloud\n/SM590000Digital assets infrastructure\n/SM590000Confidential AI\n/SM590000Secure multi-party computation \n/SM590000Secure distributed cloud\n2.9.1  Securely bring app lications to hybrid cloud\nEnterprises are moving their applications to cloud to reduce cost, simplify and consolidate \ntheir IT environment, and take advantage the flexibility of hy brid cloud. However, these \napplications contain many types of sensitive, sometimes regulated data that needs to be protected. Examples for this are applicatio ns in the financial services, healthcare, \ngovernment, and nonprofit domains.\nThe biggest barrier for bringing sensitive applications to the cloud is that the cloud \ninfrastructure is owned and operated by t he cloud provider. There are well-established \nmethods to protect data-at-rest and data-in-motion. However, there was always a concern about data-in-use, until Confidential Computing with the Hyper Protect Platform became available in the cloud. The Hyper Protect Plat", "metadata": {"source": "sg248555.pdf", "chunk_index": 127, "total_chunks": 337}}
{"text": "tial Computing with the Hyper Protect Platform became available in the cloud. The Hyper Protect Platform  protects the code of the application and the \ndata-in-use from a malicious system ad ministrator or other privileged actors.\nIt thus enables taking advantage of hybrid cloud for application modernization and design of \ncloud native applications and ensures that compliance with regulations, data sovereignty, and data protection requirements are met. The Hyper Protect Platform also ensures protection of \ntrade secrets and intellectual property that can be part of the application, such as proprietary business logic, private AI training data, and AI models.\n\n32 Applying Data Protection and Confidentiality in a Hybrid Cloud EnvironmentThe following list includes features of HPVS that are relevant in the context of application \nmodernization:\n/SM590000Secrets can be used to establish instant trust to a newly  deployed HPVS instance as Zero \nKnowledge Proofs are possible. The instance can", "metadata": {"source": "sg248555.pdf", "chunk_index": 128, "total_chunks": 337}}
{"text": "nt trust to a newly  deployed HPVS instance as Zero \nKnowledge Proofs are possible. The instance can be integrated and authenticated in an existing flow. Even if the new instance is in a remote data center or cloud.\n/SM590000HPVS provides LUKS volume encryption fo r attached storage devices. The LUKS \npassphrase can be derived from two seeds, which are defined by and known to separate personas. This ensures that no individual persona can reconstruct the passphrase.\n/SM590000HPVS provides Attestation with which an Auditor persona ca n validate the HPVS instance.\n/SM590000Secure Build can be used to build the application OC I images in HPVS, thus protecting the \nbuild process, the built OCI images, the build manifest and signing keys for signing the images.\n2.9.2  Digital assets infrastructure\nIn a digital assets infrastructure, maintain ing control over private keys is extremely \nchallenging and poses a major risk, especially when managing thousands if not millions of \nwallets. Loss of ", "metadata": {"source": "sg248555.pdf", "chunk_index": 129, "total_chunks": 337}}
{"text": "ing and poses a major risk, especially when managing thousands if not millions of \nwallets. Loss of control of an account\u2019s private key through cyberattack or mishandling can result in irrevers ible asset loss.\n8\nThe Hyper Protect Platform provides a truste d platform for reliable and scalable digital \ncustody applications, for managing, transferring, and storing high value digital assets in highly secure wallets.\nTo provide a secure Digital Assets Infrastructu re, you can use features of the Hyper Protect \nPlatform: \n/SM590000Trusted Container Runtime\n/SM590000Memory protection\n/SM590000Data in use protection\n/SM590000Volume encryption\n/SM590000Attestation\n/SM590000Contract mechanism\n/SM590000Separation of duty\nIn addition, key creation, key derivation, and further cryptographic operations such as \nencryption and signing are done by using HPCS on FIPS 140-2 Level 4 certified hardware that is provided by IBM LinuxONE and IBM Z. Cryptographic keys and access tokens can be kept inside th", "metadata": {"source": "sg248555.pdf", "chunk_index": 130, "total_chunks": 337}}
{"text": "at is provided by IBM LinuxONE and IBM Z. Cryptographic keys and access tokens can be kept inside the HPVS instance and cannot  be accessed even by  privileged actors.\nTo protect high-value transactions and comply wi th industry regulation, many applications are \nisolated, and communications with other applications are restricted. A key regulation that has emerged is the requirement of cold storage or alike for security purposes. However, today's cold storage solutions have several limitations that include protection of keys and assets, manual operations,  and the inability to scale due to the manual process.\nThe IBM Hyper Protect Offline Signing Orchestrator is an alternative approach to cold \nstorage. It is designed to broker communicati ons between two different applications that are \ndesigned not to communicate directly. Hyper Protect Offline Signing Orchestrator is deployed in HPVS instances on IBM LinuxONE and IBM Z.  Hyper Protect Offline Signing Orch estrator \nhelps protect hig", "metadata": {"source": "sg248555.pdf", "chunk_index": 131, "total_chunks": 337}}
{"text": "instances on IBM LinuxONE and IBM Z.  Hyper Protect Offline Signing Orch estrator \nhelps protect high-value transactions by offeri ng additional security layers that include \ndisconnected network operations, time-based securi ty, and electronic transaction approval by \nmultiple stakeholders. Offline Signing Orchestrator also changes the digital asset transaction \n8  Reference: Microsoft mitigates Chi na-based threat actor\n\nChapter 2. Understanding the solution 33signing process from a manual operation to  an automated and policy-driven one, by \neliminating the operational involvement without eliminating the human control.\n2.9.3  Confidential AI\nData that is used for training and testing AI and ML models can be valuable, sensitive, and regulated. Also, AI and ML models can constitute intellectual property or trade secrets, be sensitive, and require confidentiality.\nThe Hyper Protect Platform can protect AI proc esses, like training, test, and inference by \nusing features like memory pro", "metadata": {"source": "sg248555.pdf", "chunk_index": 132, "total_chunks": 337}}
{"text": "orm can protect AI proc esses, like training, test, and inference by \nusing features like memory protection, code and data confidentiality, code and data integrity, volume encryption, attestation, and the contract mechanism with separation of duty. \nFor example, the Hyper Protect Platform can be us ed to build confidential AI as a service in a \nhybrid cloud environment. Separation of duty is possible to allow a Workload Deployer persona to provision confidential AI in an HPVS instance and ensure this persona cannot access the AI model or related data. \nFigure 2-5 shows an example of a complete end-to-end flow for securely training a machine \nlearning model and using this model inference. This all occurs within a confidential computing environment with boundaries of protection around all the components.\nFigure 2-5   Confidential AI example\nYou can also add additional AI acceleration, such as by using the IBM Telum processor  that \ncontains on-chip acceleration for artificial intelligenc", "metadata": {"source": "sg248555.pdf", "chunk_index": 133, "total_chunks": 337}}
{"text": " as by using the IBM Telum processor  that \ncontains on-chip acceleration for artificial intelligence, with the IBM LinuxONE and IBM Z platforms.\nAs another example, confidential, federated learning can be applied to cases in which \nmultiple parties have private data to combine and analyze without exposing the underlying data or machine learning models to any of the other parties. This technology can be applied to preventing fraud in financial services, dete cting or developing cures for diseases in the \n\n\n34 Applying Data Protection and Confidentiality in a Hybrid Cloud Environmenthealthcare industry, or gaining business insight. As an illu stration, multiple hospitals might \ncombine data to train a machine learning mo del to clinically a nalyze medical images. \n2.9.4  Secure multi-party computation\nSecure multi-party computation (SMPC) enables multiple parties, each holding their own \nprivate data, to collaborate in a computation without revealing any of the private data. The two imp", "metadata": {"source": "sg248555.pdf", "chunk_index": 134, "total_chunks": 337}}
{"text": "private data, to collaborate in a computation without revealing any of the private data. The two important requirements on SMPC are privacy and correctness. The privacy requirement states that parties learn their computation output and nothing else. The correctness requirement states that each party receive its correct output. Therefore, no adversary must be able to cause the result of the computation to deviate from the function that the parties set out to compute.\nA primary concern is how the confidentiality and integrity of the data can be preserved when \ncalculations happen outside the party\u2019s direct control.\nFor example, banks can collaborate to find patterns of anti-money laundering. See \nFigure 2-6. Each bank brings encrypted financial-transactions data to a confidential computing enclave, such as an HPVS, where data can be safely decrypted. The multi-party collaboration (MPC) application runs fraud-detection algorithms in the confidential computing enclave. Malicious administra", "metadata": {"source": "sg248555.pdf", "chunk_index": 135, "total_chunks": 337}}
{"text": "lication runs fraud-detection algorithms in the confidential computing enclave. Malicious administrators or operators cannot see financial transaction data from any \nbanks collaborating on the MPC platform.\nFigure 2-6   Banks collaborate to find patterns of anti-money laundering\nBy using the Hyper Protect Pl atform and confidential computing, organizations can now \nensure that data is protected against tampering and compromise, and data sovereignty and privacy regulations can be  fulfilled. This includes threats within the partnering organizations \nand validating the integrity of the code processing that data. \nThe data can be combined and analyzed and the results can be sent in an encrypted format \nback to each party. Data remains protected throughout the entire process: while in transit, in use, and at rest.\n\n\nChapter 2. Understanding the solution 352.9.5  Secure distributed cloud \nA secure distributed computing application can comprise a front end running in a TEE on \nmobile, person", "metadata": {"source": "sg248555.pdf", "chunk_index": 136, "total_chunks": 337}}
{"text": "ecure distributed computing application can comprise a front end running in a TEE on \nmobile, personal computing, or point of sale (POS) devices and a back end in a hybrid cloud infrastructure. Such a type of application can be  required for security cr itical applications like \npayment systems and in financial services, healthcare, or in other regulated industries.\nThe back-end infrastructure can use the Hyper Pr otect Platform to provide protection of the \ncode and data in use by the back end. Data in transit between the back end and the front end is typically protected by mTLS.\n\n36 Applying Data Protection and Confidentiality in a Hybrid Cloud Environment\n\n\u00a9 Copyright IBM Corp. 2024. 37Chapter 3. Making the infrastructure secure\nThe previous chapters described the deficiencies of traditional infrastructures in the context of \nincreased cyberthreats that are posed by malicio us actors, whether internal or external. The \nchapters included strategies to mitigate risks by using infrastr", "metadata": {"source": "sg248555.pdf", "chunk_index": 137, "total_chunks": 337}}
{"text": " whether internal or external. The \nchapters included strategies to mitigate risks by using infrastructures built on the Hyper Protect Platform and described the relevant qualities of the components and services that comprise the solution. \nThere are several distinct steps that are involved in configuring Hyper Protect Virtual Server \n(HPVS) instances, which can quickly become overwhelming wit hout some guidance. This \nchapter provides step-by-step instructions with sample configuration file s, where required, to \ndeploy a secure infrastructure for confidential computing. \nBefore you start, you need an IBM Cloud account  for a Virtual Private Cloud (VPC) or KVM to \nhost LPARs on IBM LinuxONE or IBM Z to deploy the examples in this chapter. For more information, see System requirements.\nRefer to Appendix B, \u201cCreating a Hyper Protect Virtual Server for VPC\u201d on page 107 for \ndetailed steps on deploying an HPVS instance by  using the IBM Cloud Virtual Private Cloud \n(VPC) user interface (U", "metadata": {"source": "sg248555.pdf", "chunk_index": 138, "total_chunks": 337}}
{"text": "on deploying an HPVS instance by  using the IBM Cloud Virtual Private Cloud \n(VPC) user interface (UI).\nYou must also complete Setting up and configuring IBM Hyper Protect Virtual Servers  before \nyou can deploy HPVS instance s on IBM LinuxONE or IBM Z.\nThe deployment of HPVS consists of the following aspects:\n/SM5900003.1, \u201cThe contract\u201d on page 38\n/SM5900003.2, \u201cContract encryption\u201d on page 49\n/SM5900003.3, \u201cContract certificates\u201d on page 53\n/SM5900003.4, \u201cAttestation\u201d on page 54\n/SM5900003.5, \u201cLogging for HPVS instances\u201d on page 56\n/SM5900003.6, \u201cEncrypting data volumes\u201d on page 633\n\n38 Applying Data Protection and Confidentiality in a Hybrid Cloud Environment3.1  The contract\nThe contract is a definition file in the YAML form at that is specific to the Hyper Protect Virtual \nServers (HPVS) instance, wh ich is also called an im age. This file must be  created by  the user \nas a prerequisite for creating an instance. After the file is created, it must be passed as input \nthrough the ", "metadata": {"source": "sg248555.pdf", "chunk_index": 139, "total_chunks": 337}}
{"text": "uisite for creating an instance. After the file is created, it must be passed as input \nthrough the User Data field when an instance is created.\nThe HPCR image decrypts the contract, if it is encrypted, validates the contract schema, \nchecks for contract signature, creates the passp hrase to encrypt the disk device, and starts \nthe container that is specified in the contract.\nThe contract has severa l sections, each one documenting how the H PVS instance should be \nbuilt: \n/SM590000workload (mandatory).\n/SM590000env (mandatory).\n/SM590000attestationPublicKey (optional). This section provides a public RSA key as part of the \ncontract, which is used to encrypt the attestation document and the attribute must be named as attestationPublicKey.\n/SM590000envWorkloadSignature (optional section). This section contains the signature of the other \nsections of the contract.\nThe workload and env sections are mandatory because the information that is provided in \nthese sections defines how the HPVS ", "metadata": {"source": "sg248555.pdf", "chunk_index": 140, "total_chunks": 337}}
{"text": "ions are mandatory because the information that is provided in \nthese sections defines how the HPVS instance is built. The contents of these sections come from two different personas, namely the Workload Provider and the Workload Deployer. See \u201cSeparation of duty\u201d on page 11 for a description of the predefined personas.\nThe Workload Provider persona provides information about the container, or workload that \nneeds to be starte d on the HPVS instance. It incl udes the following information:\n/SM590000Name of the container \n/SM590000Container registry and where it resides \n/SM590000Credentials of the container registry \n/SM590000Image digest \n/SM590000Notary server information, which is required for image validation \n/SM590000Volumes to be present and attached\n/SM590000Environment variables that need to be passed to the container\n/SM590000Docker compose file or Pod descriptors with the container information\nThe Workload Deployer persona works closely with the infrastructure staff. This pe", "metadata": {"source": "sg248555.pdf", "chunk_index": 141, "total_chunks": 337}}
{"text": "ainer information\nThe Workload Deployer persona works closely with the infrastructure staff. This persona \nreceives the workload information, preferably an encrypted workload section, from the Workload Provider persona. The Workload Deployer then creates the env section of the contract. The env section has information that is specific to the environment. Usually, it is information that the Workload Provider persona does not have and does not need to know. An \nexample is information about the \u201cLogging\u201d instance, which the Workload Deployer persona creates, before it adds information to the env section of the contract.Note:  If a docker compose file is used, only one container is supported. However, pod \ndescriptors, a podman construct, support one or multiple containers\n\nChapter 3. Making the infrastructure secure 393.1.1  The workload section\nThis is one of the most important sections of the contract. The workload section can have \nmultiple subsections and the purpose of the s ubsectio", "metadata": {"source": "sg248555.pdf", "chunk_index": 142, "total_chunks": 337}}
{"text": " the contract. The workload section can have \nmultiple subsections and the purpose of the s ubsections is to provide information that is \nrequired for bringing up the workload.  The workload section is defined with type: workload . \nThis section is mandatory and it encompasses the following subsections:\n/SM590000auths. This subsection is optional and required only when authentication is needed to \ndownload or get the image file from the registry.\n/SM590000compose. For a single container. compose subsection must exist if play subsection is not \ndefined. The compose subsection and the play  subsection are mutually exclusive. \n/SM590000play. For multiple containers. pl ay subsection must exist if the compose subsection is not \ndefined. The compose subsection and the play  subsection are mutually exclusive. \n/SM590000images. This subsection is optional and used for validating the integrity of signed images.\n/SM590000volumes. This subsection is optional and used only when a data volume is m", "metadata": {"source": "sg248555.pdf", "chunk_index": 143, "total_chunks": 337}}
{"text": "f signed images.\n/SM590000volumes. This subsection is optional and used only when a data volume is mounted on the \nHPVS guest.\nExample 3-1 shows a high-level sample of the workload section of the contract. The minimum \nthat a workload section needs is the compose section. The other sections can be added based on the requirement.\nExample 3-1   High-level sample of the workload section\ntype: workloadauths:  <registry url>:    password: <password>    username: <user name>  <registry url>:    password: <password>    username: <user name>\ncompose:\n  archive: <base64 encoded of tgz of docker-compose.yaml>\nimages:\n  dct:    <docker image name (without the tag, an example is docker.io/redbookuser/s390x:)>:      notary: \"<notary URL>\"      publicKey: <docker content trust signed public key>    <docker image name>:      notary: \"<notary URL>\"      publicKey: <docker content trust signed public key>\nvolumes:\n  <volume name>:    mount: \"<data volume mount path>\"    seed: \"<Passphrase of the luks e", "metadata": {"source": "sg248555.pdf", "chunk_index": 144, "total_chunks": 337}}
{"text": ">\nvolumes:\n  <volume name>:    mount: \"<data volume mount path>\"    seed: \"<Passphrase of the luks encryption>\"    filesystem: \"ext4\"\n\n40 Applying Data Protection and Confidentiality in a Hybrid Cloud EnvironmentThe auths subsection\nThe auths subsection consists of information about the container's registry. If a public image \nis used in the contract, you do not need the auths subsection because no credentials are required. The auths subsection is required only if the container images are private. This subsection does not have any image informatio n, as shown in the following sample. This \nsubsection needs to contain the name of the image registry and the credentials, such as username and password, for the same. The key must be the hostname of the container registry or the following string for the default docker registry:\nhttps://index.docker.io/v1/\nExample 3-2 shows an IBM Cloud Registry snippet. For more information about using the API \nkey, see Using client software to authenticate ", "metadata": {"source": "sg248555.pdf", "chunk_index": 145, "total_chunks": 337}}
{"text": "y snippet. For more information about using the API \nkey, see Using client software to authenticate in automation .\nExample 3-2   IBM Cloud registry\nauths:\n  us.icr.io:    password: <apikey>    username: iamapikey\nThe compose subsection\nThe compose subsection consists of an archive subsection. The archive subsection contains the Base64 encoded GNU compressed tar (TGZ) file archive of the docker-compose.yaml  file \nwith any other file such as certificates and configuration files. Because the HPCR image uses Docker Engine and Docker Compose to start the container, the information about the container must first be created by using a standard docker-compose file. This file is then archived and Base64 encoded, and the output of this is provided as the value to the archive subsection within the compose section. For more information, see Docker Compose \noverview .\nThe mount points specified under the volumes information of the docker-compose file might \nbe aligned with the volume mount point ", "metadata": {"source": "sg248555.pdf", "chunk_index": 146, "total_chunks": 337}}
{"text": "er the volumes information of the docker-compose file might \nbe aligned with the volume mount point that is specified in the workload section of the \ncontract.\nBoth \u201cyaml\u201d and \u201cyml\u201d formats support docker-compose files. See Example 3-3.\nExample 3-3   Docker-compose file\nversion: '3'\nservices:  nginx:    image: nginx@sha256:e73ba8654ba7fd1834e78a3d4e9d72ffaaa3372d42996af5c34ba3e1abc293e8\n user: 0:0\n    restart: always    ports:    - 80:80Note:  Running a build as part of a docker compose file is not supported. Make sure that \nyour docker compose file does not have a build section.\n\nChapter 3. Making the infrastructure secure 41Use the tar command to get the Base64 encoded archive file. See Example 3-4. The Base64 \noutput is available in the compose.b64 file.\nExample 3-4   Command to get the Base64 encoded archive file\ntar czvf - -C <COMPOSE_FOLDER> . | base64 -w0 > compose.b64\nCopy the content of compose.b64  file as a value of the compose -> archive subsection. See \nExample 3-5.\nExampl", "metadata": {"source": "sg248555.pdf", "chunk_index": 147, "total_chunks": 337}}
{"text": "ntent of compose.b64  file as a value of the compose -> archive subsection. See \nExample 3-5.\nExample 3-5   Copy of compose.b64 file content\ncompose:  archive: <paste the content of compose.b64 >\nFor this example, the response is similar to the output in Example 3-6.\nExample 3-6   Output of the compose -> archive\ncompose:\n  archive: H4sIAKOFmGIAA+2RTW6DMBBGs84pRuyB8Q8k+DIRwZOGtmBkkyrcvhgnLVVV1EWkqhJv4ZHt8ednWZvqhWxcmaYzjpKhed08HETMpQRfd3k2VeRhPpEJCUxymTPkIuOALBOIG8DHq3zn4vrSjiqdLY/nsv+xb2w7nRZywlPgo/4THNm3uiKntgCWdO1aowmZnwLUTflECpwo8Jpu9NyZ2zvQgdADFEudoXyQzSu+fPPzseSvedo6qj\nV7mDa2anZbdH8totL6somtUlvX8K4SJshDsFKU2NmFvAZuMc9U37wceeys+Y6BI8Fi6+6vxK5RS+YFDh6R\nNu//tuVlZWVJd4BcjKckQAIAAA=\nThe play subsection\nIn the play subsection, you can define the workload through Pod descriptors . Each pod can \ncontain one or more container definitions. Descriptors can be provided in one of the following ways:\n/SM590000In plain YAML format in the resources subsection of play. This section is an array of", "metadata": {"source": "sg248555.pdf", "chunk_index": 148, "total_chunks": 337}}
{"text": "ways:\n/SM590000In plain YAML format in the resources subsection of play. This section is an array of \ndescriptors and supports two types of descriptors: Pods  and ConfigMaps .\nExample 3-7 illustrates how to define t he resources in the play subsection.\nExample 3-7   Resources in the play subsection\nworkload: |\n  type: workload  play:    resources:      - apiVersion: v1        kind: PodTip: There are use cases when the workload section is pre-encrypted in which the registry \nis not known. For example, when the Workload Provider wants to allow the Workload Deployer to use a registry mirror or a private container registry. In such a case, it is possible to dynamically override the registry and pull credentials. This is a coordinated effort between the Workload Provider and the Workload Deployer. For more information, see Using a dynamic registry reference .\nNote:  Make sure that the compose tgz file contains only directories and regular files. Links \nor pipes are not supported and will re", "metadata": {"source": "sg248555.pdf", "chunk_index": 149, "total_chunks": 337}}
{"text": " tgz file contains only directories and regular files. Links \nor pipes are not supported and will resu lt in an error during deployment.\n\n42 Applying Data Protection and Confidentiality in a Hybrid Cloud Environment        metadata:\n          name: busybox        spec:          containers:          - name: main            image: ...            command:            - printenv            envFrom:            - configMapRef:                name: contract.config.map                optional: false          restartPolicy: Never\n/SM590000In the archive subsection of play. The archiv e is a Base64 encoded, compressed, tar file. \nThe Pods or ConfigMaps are represented as YAML files, top level in th is tar file. The file \nmay also contain extra files and all files are ex tracted to the host file system before starting \nthe Pods. The current working directory is the directory in which the files have been extracted, so it's possible to use a volume mount with a relative path to mount files or direct", "metadata": {"source": "sg248555.pdf", "chunk_index": 150, "total_chunks": 337}}
{"text": "been extracted, so it's possible to use a volume mount with a relative path to mount files or directories from the contract.\n/SM590000In a template format in the templates subsection of play. This section is an array of \ndescriptors in the YAML format. Pods or Co nfigMaps may have points of variability (POV) \nthat are not known at the time of writing the descriptors. These POVs may be represented as templates and the values are provided at deployment time from information in the contract. Go templates  are used as the templating syntax, which is the same as used for \nHelm charts , so templates can easily be exchanged with Kubernetes. The following \nBuilt-In objects are supported:\n\u2013 Environment: this object contains the environment variables as merged between the \nworkload and the environment section. See Example 3-8. The object is available as {{ .Env }}.\nExample 3-8   Environment variables\nworkload: |  type: workload  play:    templates:      - apiVersion: v1        kind: Pod        m", "metadata": {"source": "sg248555.pdf", "chunk_index": 151, "total_chunks": 337}}
{"text": "les\nworkload: |  type: workload  play:    templates:      - apiVersion: v1        kind: Pod        metadata:          name: busybox        spec:          containers:          - name: main            image: \"{{ .Env.REGISTRY }}/hpse-docker-busybox-s390x@sha256:732efa374f1e6c964caeacab0bcb370385ee386041a14d4a32176462e3f75c7b\"            command:            - printenv            envFrom:            - configMapRef:                name: contract.config.map                optional: false          restartPolicy: Neverenv:\n\nChapter 3. Making the infrastructure secure 43  env:\n    REGISTRY: docker-eu-private.artifactory.swg-devops.com/sys-zaas-team-hpse-dev-docker-local/zaas\nEnvironment variables\nIn the contract, environment variables can be defined in the workload and env sections. Both sets of variables are merged together with  workload taking prec edence. Pods use the \nconcept of a ConfigMap to define configuration, so HPCR represents the merged environment sections as a special ConfigMap n", "metadata": {"source": "sg248555.pdf", "chunk_index": 152, "total_chunks": 337}}
{"text": "to define configuration, so HPCR represents the merged environment sections as a special ConfigMap named contract.config.map. Example 3-9 mounts all environment variables from the contract into the container.\nExample 3-9   Environment variables in the contract\napiVersion: v1kind: Podmetadata:  name: busyboxspec:  containers:  - name: main    image: ...    command:    - printenv    envFrom:    - configMapRef:        name: contract.config.map        optional: false  restartPolicy: Never\nPod communication\nPod communication can be container-to-container, pod-to-host, or pod-to-pod\n/SM590000Container-to-container\nContainers inside one Pod communicate to each other through the localhost. Each \ncontainer needs to listen on a different port because, per design, they share the same IP address.\n/SM590000Pod-to-host\nUsually, a Pod needs to expose at least one of  its containers to the host so that the \nexposed container is accessible through the IP address on the host through a mapped port. For t", "metadata": {"source": "sg248555.pdf", "chunk_index": 153, "total_chunks": 337}}
{"text": "the \nexposed container is accessible through the IP address on the host through a mapped port. For this use case, use the hostPort feature on a container. This is not best practice when you use Kubernetes, for which a service would be used instead.\nSee Example 3-10 for a snippet.\nExample 3-10   Pod communication\napiVersion: v1\nkind: Podmetadata:    name: nginx-with-busyboxImportant:  Specify both hostPort and containerPort explicitly. If you specify only \ncontainerPort, ports are not bound.\n\n44 Applying Data Protection and Confidentiality in a Hybrid Cloud Environmentspec:\n    containers:        - image: ...          name: frontend          ports:            - containerPort: 80              hostPort: 80          volumeMounts:            - mountPath: /etc/nginx              name: local-frontend              readOnly: true        - command:            - httpd            - -vv            - -f            - -p            - \"8080\"            - -h            - /www          image: ...        ", "metadata": {"source": "sg248555.pdf", "chunk_index": 154, "total_chunks": 337}}
{"text": "-f            - -p            - \"8080\"            - -h            - /www          image: ...          name: backend          volumeMounts:            - mountPath: /www              name: local-backend              readOnly: true    volumes:        - hostPath:            path: ./www            type: Directory          name: local-backend        - hostPath:            path: ./nginx            type: Directory          name: local-frontend\n/SM590000Pod-to-Pod\nTo reach from one Pod to another, expose a hostPort on the target Pod. The source Pod can \nthen make a request to the host on the exposed port to get to the target Pod.\nThe source Pod can find the IP address of the host through the following command:\n    ip route | awk '/default/ { print $3 }'\nVolumes\nFor HPCR, volumes are managed by the volumes section in the contract. Based on this \ninformation, HPCR will encrypt and mount external blo ck devices on the host. To mount these \nvolumes into the pod, use the hostPath  mount option on th", "metadata": {"source": "sg248555.pdf", "chunk_index": 155, "total_chunks": 337}}
{"text": "o ck devices on the host. To mount these \nvolumes into the pod, use the hostPath  mount option on the volume. See Example 3-11.\nExample 3-11   Mount volume into pod\napiVersion: v1\nkind: Podmetadata:  name: busyboxspec:\n\nChapter 3. Making the infrastructure secure 45  containers:\n  - name: main    image: ...    volumeMounts:    - name: test-volume      readOnly: true      mountPath: /fromHost  volumes:  - name: test-volume    hostPath:      path: /var/hyperprotect      type: Directory  restartPolicy: Never\nThe images subsection\nThe images subsection is meant only for an image that is signed. See Example 3-12.\nThe following list includes aspects of images that are described by docker compose:\n/SM590000The container image that is listed in the docker -compose file can be signed or not signed \nby using Docker Content Trust (DCT).\n/SM590000The following example shows an image URL:\n<container registry >/<username or namespace >/<image nam e>\nAn example with defined variables: \nus.icr.io/myna", "metadata": {"source": "sg248555.pdf", "chunk_index": 156, "total_chunks": 337}}
{"text": "registry >/<username or namespace >/<image nam e>\nAn example with defined variables: \nus.icr.io/mynamespace/my-haproxy:\n/SM590000The following contents show an example of a notary URL:\nnotary: \"https://notary.us.icr.io\"\n/SM590000The publicKey is the public key corresponding to the private key by which the images are \nsigned using DCT. Use the following command to get the public key:\ncat ~/.docker/trust/tuf/us.icr.io/<username>/<imagename>/metadata/root.json\nExample 3-12   Image that is signed using DCT\nimages:\n  dct:    us.icr.io/mynamespace/my-haproxy:      notary: \"https://notary.us.icr.io\"      publicKey: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUJpRENDQVM2Z0F3SUJBZ0lSQUxCMXBPYlpEQlRRc09GSFlxazMzaWd3Q2dZSUtvWkl6ajBFQXdJd0tqRW8KTUNZR0ExVUVBeE1mZFhNdWFXTnlMbWx2TDNCeVlXSm9ZWFF4TWpNdmJYa3RhR0Z3Y205NGVUQWVGdzB5TWpBMApNVE14TURFd01ETmFGdzB6TWpBME1UQXhNREV3TUROYU1Db3hLREFtQmdOVkJBTVRIM1Z6TG1samNpNXBieTl3CmNtRmlhR0YwTVRJekwyMTVMV2hoY0hKdmVIa3dXVEFUQmdjcWhrak9QUUlCQmdncWhrak9QUU1CQndOQ0FBU1AK", "metadata": {"source": "sg248555.pdf", "chunk_index": 157, "total_chunks": 337}}
{"text": "amNpNXBieTl3CmNtRmlhR0YwTVRJekwyMTVMV2hoY0hKdmVIa3dXVEFUQmdjcWhrak9QUUlCQmdncWhrak9QUU1CQndOQ0FBU1AKWGsrelE2MlFZNjI3MWQ1cTBMZHY3SGc3QzZkMGZOUlRsQmJXekhOWWFDZzlpU0piYnVNdjVBY0JmMjlqQi83eApqYzhzVitxMksyemtkTHV4QWxGWm96VXdNekFPQmdOVkhROEJBZjhFQkFNQ0JhQXdFd1lEVlIwbEJBd3dDZ1lJCkt3WUJCUVVIQXdNd0RBWURWUjBUQVFIL0JBSXdBREFLQmdncWhrak9QUVFEQWdOSUFEQkZBaUIzd0JTa0IxaXAKZHZZYlBMbFBmS3RZT0hsYnZzUllKa0FZM2hnY0xuNWhwQUloQUt6cmhsU3p4K1I5bmdtMTBlZVkyaFNCRmgrawpMWHp6SFkwaktTVzhyM1FhCi0tLS0tRU5EIENFUlRJRklDQVRFLS0tLS0KNote:  The volumes field here defines the data on the host to be mounted into the pod. It's \ndifferent from volumes in the HPCR contract.\n\n46 Applying Data Protection and Confidentiality in a Hybrid Cloud EnvironmentFor an image that is not signed, no entry is re quired in the images subsection. However, for \nunsigned images, a digest is required. Complete the following steps to get the digest:\n1. Log in to the container registry dashboard.\n2. Open the image.3. Click Tag, and then click Dige", "metadata": {"source": "sg248555.pdf", "chunk_index": 158, "total_chunks": 337}}
{"text": ":\n1. Log in to the container registry dashboard.\n2. Open the image.3. Click Tag, and then click Digest.\nAfter you get the digest, add this digest in the docker-compose.yaml  file. The following entry is \nan example:\nservices:\n  <imagename >:\n    image: \ns390x/redis@sha256:db467ab5c53bdeef65762a7534e26fecb94a0f218bd38afd2eaba1a670c472b1\nThe following images are described by Pod descriptors:\n/SM590000Container images that are described by Pod descriptors can be validated by Red Hat \nSimple Signing.\n/SM590000If the image is referenced by a digest, the service allows its usage without additional \nchecks.\n/SM590000Images without a digest need a GPG key to be validated. The key is transferred in Base64 \nencoded binary format that can be crea ted as shown in the following example:\ngpg --export ${KEY_ID} | base64 -w0\nThis key is conveyed through the rhs subsection of the images section. This section is a map \nwith the image identifier as the key and the GPG key in the publicKey field as shown ", "metadata": {"source": "sg248555.pdf", "chunk_index": 159, "total_chunks": 337}}
{"text": "tion is a map \nwith the image identifier as the key and the GPG key in the publicKey field as shown in the following example:\nimages:  rhs:\n      OCI-image-identifier:\n        publicKey: abcdef\n3.1.2  The workload volumes subsection\nThe volumes subsection needs to be provided in the contract only if a data volume is attached \nto the instance at the time of creation. The information that is provided in this subsection is used to mount the attached data volume, which is  provided by the user, and is later encrypted \nusing the seeds that are provided in the workload and env sections. You can provide any path of your choice for the mount field. The path that is provided by the user is used internally to mount the data volume. The mount path that is provided in the contract must match the path provided under the volumes subsection of the docker-compose.yaml  file, so that all the data \nassociated with the container workload is stored in this data volume.\nThe volumes subsection has support f", "metadata": {"source": "sg248555.pdf", "chunk_index": 160, "total_chunks": 337}}
{"text": "ated with the container workload is stored in this data volume.\nThe volumes subsection has support for auto encryption of the data volume with \nuser-provided seeds. If a data volume is attached to the HPVS instance, it is encrypted automatically with the seeds that are provided through the seed field in the volumes subsections of the contract. Thus, two seeds must be provided, one through the workload section, by the Workload Provider persona and the other through the env section by the Workload Deployer persona. These two seeds ar e internally converted to UTF8 sequences \nand then concatenated. Later, the hash (SHA256) of the concatenated sequence is computed as a hexdigest, which is used as the LUKS passphrase to encrypt the data volume. \n\nChapter 3. Making the infrastructure secure 47You can use the following command to validate the hexdigest:\necho -n \"seed1seed2\" | sha256sum\nThis is how the seed can be provided in the workload section of the contract. For more \ninformation about ho", "metadata": {"source": "sg248555.pdf", "chunk_index": 161, "total_chunks": 337}}
{"text": "how the seed can be provided in the workload section of the contract. For more \ninformation about how the seed input can be provided through the env section, see 3.1.3, \u201cThe env section\u201d on page 47. It is mandatory to provide both the seeds for encryption. If only one of the seeds is provided then encryption fails and the instance shuts down.\nNote that for deployments on IBM Cloud it is possible to add a higher level of encryption \nprotection and control to the data-at-rest by integrating with Hyper Protect Crypto Services \n(HPCS). Starting with ibm-hyper-protect- container-runtim e-1-0-s390x- 11 for HPVS for VPC \ninstance or ibm-hy per-protect-conta iner-runtime-23.6.2- encrypt.crt for HPVS instance on IBM \nLinuxONE or IBM Z version 23.6.2, HPCS can be used to generate a random value as the third seed and wrap it with the root key. The LUKS passphrase is generated by using three seeds: the seed in the metadata partition and the two seeds from the contract. For more information, see Se", "metadata": {"source": "sg248555.pdf", "chunk_index": 162, "total_chunks": 337}}
{"text": "the seed in the metadata partition and the two seeds from the contract. For more information, see Securing your data .\nThe following snippet is an example of the volumes subsection:\nvolumes:\n  test:    filesystem: ext4\n    mount: /mnt/data\n    seed: workload phraseFor more information on the volume subsection, see HPVS for VPC: The workload - volumes \nsubsection and HPVS on IBM LinuxONE and IBM Z: Th e workload - volumes subsection .\n3.1.3  The env section\nThe env section is one of the most important sections in a contract and is mandatory. The env \nsection of a contract deals with information that is specific to the cloud environment and is not \nknown to the Workload Provider persona. This section is created by the Workload Deployer persona.\nThe env section is defined with type: env . The env section includes the following \nsubsections:\n/SM590000logging. This subsection is mandatory and te lls the HPVS service w here to send logging \ndata.\n/SM590000volumes. This subsection is optional", "metadata": {"source": "sg248555.pdf", "chunk_index": 163, "total_chunks": 337}}
{"text": " te lls the HPVS service w here to send logging \ndata.\n/SM590000volumes. This subsection is optional and must be used only when a data volume is \nattached.\n/SM590000signingKey. This subsection is optional and mu st be used only when a contract signature \nis used.\n/SM590000env. This subsection is optional and used to specify values for env variables when defined \nby the Workload Provider, specifically.\n\n48 Applying Data Protection and Confidentiality in a Hybrid Cloud EnvironmentThe logging subsection\nThe minimum subsection that is required for this  section is the logging subsection. For more \ninformation, see Logging for Hyper Protect Virtual Server for VPC  and Logging for IBM Hyper \nProtect Virtual Servers .\nThe following snippet is an example of the logging subsection:\nlogging:\n  logDNA:    hostname: <host name of the Log Analysis instance>\n    ingestionKey: <ingestion Key of the Log Analysis instance>\n    port: <port default-6514>\nThe env - volumes subsection\nBefore continuing wit", "metadata": {"source": "sg248555.pdf", "chunk_index": 164, "total_chunks": 337}}
{"text": " Analysis instance>\n    port: <port default-6514>\nThe env - volumes subsection\nBefore continuing with this subsection, read 3.1.2, \u201cThe workload volumes subsection\u201d on \npage 46. For auto volume encryption of the attached data volume two customer seeds must be provided, one in the workload - volumes subsection, and the other in the env - volumes subsection. Currently only one volume is supported. The seeds can be any random text. However, note that if the same volume is used with a different contract, then the seed must match the contract that was used when the volume was firs t used. Otherwise an error will \noccur during deployment.\nThis is an example of the env - volumes subsection:volumes:\n  test:\n    seed: env phrase\nAs mentioned, you can integrate with HPCS to generate a third seed and wrap it with your \nroot key. See the following example. For more information, see Securing your data .\nvolumes: test:   \n   kms:   \n     - apiKey: \"xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\"      ", "metadata": {"source": "sg248555.pdf", "chunk_index": 165, "total_chunks": 337}}
{"text": "a .\nvolumes: test:   \n   kms:   \n     - apiKey: \"xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\"          crn: \n\"crn:v1:bluemix:public:hs-crypto:us-south:a/xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx:xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx:key:xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx\"  \n       type: \"public\"\n     - apiKey: \"xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\"   Note:  The name of the volume must be the same as that in the workload - volumes \nsubsection.\n\nChapter 3. Making the infrastructure secure 49       crn: \n\"crn:v1:bluemix:public:hs-crypto:us-south:a/xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx:xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx:key:xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx\"  \n       type: \"private\"\n   seed:\"seed1\"   \n   kmsTimeout: 10  \nsigningKey subsection\nFor information about how to use the signingKey, see \u201cContract signature\u201d on page 52.\nenv subsection\nIf Pod descriptors are used in the workload section, see the example for the template format \nin \u201cThe play subsection\u201d on page 41.\nIf a docker compos", "metadata": {"source": "sg248555.pdf", "chunk_index": 166, "total_chunks": 337}}
{"text": "on, see the example for the template format \nin \u201cThe play subsection\u201d on page 41.\nIf a docker compose file is used in the workload section:\nIf the docker compose file has an environment section, use the following snippet as an \nexample:\nenvironment:  KEY1: \"${Value1}\"\n  KEY2: \"${Value2}\"\nWhen the docker compose file has an environment section, as shown in the previous \nexample, it is possible to pass the values in the env section of the Workload Deployer. The following example shows how to specif y the values for the env variables:\nenv: value1: \"abc\"\n value2: \"xyz\"\nFor details about each section and subsection of the contract, see IBM Hyper Protect Virtual \nServers: About the Contract\n3.2  Contract encryption\nWhen the HPVS instance boots, the bootloader decrypts the cont ract. It takes the contents of \neach of the sections in the contract and decrypts the sections that are encrypted. \nAlthough the contract can be passed through the User Data field without encryption, the \nalways encryp", "metadata": {"source": "sg248555.pdf", "chunk_index": 167, "total_chunks": 337}}
{"text": "though the contract can be passed through the User Data field without encryption, the \nalways encrypt the contract with an encryption ce rtificate to protect all sensitive information. \nIt is possible to encrypt all the sections of the contract or just one. At a minimum, it is best \npractice to encrypt sections that have login credentials for container registries or LogDNA ingestion keys, for example. \nEach encryption and attestation certificate is signed by the IBM intermediate certificate,\n1 \nwhich in turn is signed by DigiCert Trusted Root G4. For more information about the certificates, see DigiCert Trusted Root Authority Certificates .\n1  An intermediate certificate acts as a layer between t he certificate authority and the end user's certificate.\n\n50 Applying Data Protection and Confidentiality in a Hybrid Cloud EnvironmentWhere to find the encryption certificate \nFor HPVS for VPC, and instance in  IBM Cloud, do the following steps:\n1. For instructions to download the encryption ", "metadata": {"source": "sg248555.pdf", "chunk_index": 168, "total_chunks": 337}}
{"text": " and instance in  IBM Cloud, do the following steps:\n1. For instructions to download the encryption certificate, see Downloading the encryption \ncertificate and extracting the public key .\n2. For instructions to validate the encryption certificate, see Validating the contract \nencryption certificate .\nFor the HPVS instan ce on IBM LinuxONE or IBM Z do the following steps: \n1. Follow the instructions from: \nhttps://www.ibm.com/docs/en/hpvs/2.1.x?topic=servers-downloading-hyper-protect-container-runtime-image  \nLook for the file with name ibm-hyper-protect-container-runtime-XX.YY.Z-encrypt.crt  \nWhere XX.YY.Z is the version being used. \nThe certificates are available in the  /config/certs  directory of the downloaded TAR.GZ \npackage.\n2. Validate the encryption certificate by using the instructions found in the download \npackage. \nEncryption of the workload  section of the contract\nTo encrypt the workload section used in a contract, on an Ubuntu image, perform the \nfollowing steps: \n/SM59", "metadata": {"source": "sg248555.pdf", "chunk_index": 169, "total_chunks": 337}}
{"text": "pt the workload section used in a contract, on an Ubuntu image, perform the \nfollowing steps: \n/SM590000Create the docker-compose.yaml  file based on the workload requirements. For example:\nservices:\n  redisnode01:\n    image: \ns390x/redis@sha256:db467ab5c53bdeef65762a7534e26fecb94a0f218bd38afd2eaba1a670c472b1\n    ports:\n      - \"6379:6379\"For more information, see Docker Compose overview .\n/SM590000Create the workload section of the contract and add the contents in the workload.yaml  file. \nDo not include the top-level element \"workload\" of the workload section if it is encrypted. Example 3-1 on page 39 shows an example of a workload section in a format that can be encrypted. \nFor more information see the following documentation:\n\u2013 HPVS for VPC: IBM cloud: The workload section\n\u2013 HPVS on IBM LinuxONE or IBM Z: IBM Hyper Protect Virtual Servers: The workload \nsection\n/SM590000Export the complete path of the workload.yaml  file and the public certificate (this can be \nibm-hyper-protect-co", "metadata": {"source": "sg248555.pdf", "chunk_index": 170, "total_chunks": 337}}
{"text": "mplete path of the workload.yaml  file and the public certificate (this can be \nibm-hyper-protect-container-runtime-1-0-s390x-11-encrypt.crt  for HPVS for VPC or \nthe file in the /config/certs  directory if you are using HPVS for IBM LinuxONE or IBM Z \non-premises:Note:  For illustration purposes on ly, the sample code in t he examples throughout this \nchapter is unencrypted code.\n\nChapter 3. Making the infrastructure secure 51WORKLOAD=\"< PATH to workload.yaml >\"\nCONTRACT_KEY=\"< PATH to public certificate \u2026encrypt.crt >\"\n/SM590000Create a random password. The contract is encrypted through symmetric AES with a \nrandom PASSWORD):\nPASSWORD_W=\"$(openssl rand 32 | base64 -w0)\"\n/SM590000Encrypt password with \nibm-hyper-protect-container-runtime-1-0-s390x-11-encrypt.crt :\nENCRYPTED_PASSWORD_W=\"$(echo -n \"$PASSWORD_W\" | base64 -d | openssl rsautl \n-encrypt -inkey $CONTRACT_KEY -certin | base64 -w0 )\"\n/SM590000Encrypt the workload.yaml  file with a random password:\nENCRYPTED_WORKLOAD=\"$(echo -n", "metadata": {"source": "sg248555.pdf", "chunk_index": 171, "total_chunks": 337}}
{"text": "w0 )\"\n/SM590000Encrypt the workload.yaml  file with a random password:\nENCRYPTED_WORKLOAD=\"$(echo -n \"$PASSWORD_W\" | base64 -d | openssl enc \n-aes-256-cbc -pbkdf2 -pass stdin -in \"$WORKLOAD\" | base64 -w0)\"\n/SM590000Get the encrypted section of the contract using the echo command:\necho \"hyper-protect-basic.${ENCRYPTED_PASSWORD_W}.${ENCRYPTED_WORKLOAD}\"\n/SM590000Paste the encrypted section of the contract to the user-data.yaml  file with the prefix \n\"workload:\" or use the echo command to start a new user-data.yaml  file with an encrypted \nworkload section:\necho \"workload: \nhyper-protect-basic.${ENCRYPTED_PASSWORD_W}.${ENCRYPTED_WORKLOAD}\" > user-data.yaml\nIt should be noted that the prefix hyper-protect-basic is mandatory.\nEncryption of environment (e nv) section of the contract\nWe are using an Ubuntu image for our examples. Similar to the workload section, these are \nthe steps to encrypt the env section used in a contract:\n/SM590000Create the env section  of the contract and add the con", "metadata": {"source": "sg248555.pdf", "chunk_index": 172, "total_chunks": 337}}
{"text": "the env section used in a contract:\n/SM590000Create the env section  of the contract and add the contents in the env.yaml  file. Do not \ninclude the top level element \"env\" in the envi ronment subsection that is to be encrypted.\nFor more information see:\n\u2013 HPVS for VPC: \nhttps://cloud.ibm.com/docs/vpc?topic=vpc-about-contract_se#hpcr_contract_env\n\u2013 HPVS on IBM LinuxONE or IBM Z: \nhttps://www.ibm.com/docs/en/hpvs/2.1.x?topic=servers-about-contract#hpcr_contract_env\n/SM590000Export the complete path of the env.yaml  file and the public certificate. For HPVS for VPC, \nthe public certificate can be ibm-hyper-protect-container-runtime-1-0-s390x-11-encrypt.crt. For HPVS for IBM \nLinuxONE or IBM Z on-premises, use the file in the /config/certs  directory:\nENV=\"<PATH to env.yaml >\"\nCONTRACT_KEY=\"< PATH to public certificate \u2026encrypt.crt >\"\n/SM590000Create a random password. The contract is encrypted through symmetric AES with a \nrandom PASSWORD:\nPASSWORD-E=\"$(openssl rand 32 | base64 -w0)\"\n/SM", "metadata": {"source": "sg248555.pdf", "chunk_index": 173, "total_chunks": 337}}
{"text": "pted through symmetric AES with a \nrandom PASSWORD:\nPASSWORD-E=\"$(openssl rand 32 | base64 -w0)\"\n/SM590000Encrypt password wit h public certificate:\nENCRYPTED_PASSWORD_E=\"$(echo -n \"$PASSWORD_E\" | base64 -d | openssl rsautl \n-encrypt -inkey $CONTRACT_KEY -certin | base64 -w0 )\"\n\n52 Applying Data Protection and Confidentiality in a Hybrid Cloud Environment/SM590000Encrypt the  env.yaml  file with a random password:\nENCRYPTED_ENV=\"$(echo -n \"$PASSWORD_E\" | base64 -d | openssl enc -aes-256-cbc \n-pbkdf2 -pass stdin -in \"$ENV\" | base64 -w0)\"\n/SM590000Get the encrypted section of the contract by using the echo command:\necho \"hyper-protect-basic.${ENCRYPTED_PASSWORD_E}.${ENCRYPTED_ENV}\"\n/SM590000Paste the encrypted section of the contract to the user-data.yaml  file with the prefix \n\"evn:\", or use the echo command to append the encrypted section of the contract to the \nuser-data.yaml  file started in the previous workload section: \necho \"env: hyper-protect-basic.${ENCRYPTED_PASSWORD_E}.${ENCR", "metadata": {"source": "sg248555.pdf", "chunk_index": 174, "total_chunks": 337}}
{"text": "ted in the previous workload section: \necho \"env: hyper-protect-basic.${ENCRYPTED_PASSWORD_E}.${ENCRYPTED_ENV}\" >>  \nuser-data.yaml\nContract signature\nContract signature is an optional feature that can be used to sign a contract before it is passed as input. Any contract can be signed regardless of it being encrypted (fully or partially) or in plain text. Va lidation of the contra ct signature is per formed by the HPVS \ninstance. The purpose of this signature feat ure is to ensure that the workload and env \nsections are always used together and are not tampered with by a third party. The signature of the workload and the env sections are added as the value to the envWorkloadSignature section of the contract. The following are two sections in a contract that are relevant while creating and adding a contract signature:\n/SM590000envWorkloadSignature. This is a section where the signature of the other sections of the \ncontract is added. This section is not required for a contract that is n", "metadata": {"source": "sg248555.pdf", "chunk_index": 175, "total_chunks": 337}}
{"text": " the other sections of the \ncontract is added. This section is not required for a contract that is not signed.\n/SM590000signingKey. This is a subsecti on that must be added to the env section of the contract. \nThis holds the value to the user-generated pu blic key, whose corresponding private key \nwas used to create the contract signature.\nComplete the following steps to create the contract signature. We are using an Ubuntu image \nfor these examples:\n/SM590000Use the following commands to generate a key pair to sign the contract. Note that \n\"CustomPassphrase\" is the passphrase to generate keys; you can use your own:\nopenssl genrsa -aes128 -passout pass:CustomPassphrase -out private.pem 4096openssl rsa -in private.pem -passin pass:CustomPassphrase -pubout -out \npublic.pem\n/SM590000Use the following command to save the signing key from the public.pem certificate in yaml \ncompatible format:\nkey=$(awk -vRS=\"\\n\" -vORS=\"\\\\\\n\" '1' public.pem)echo ${key%\\\\n}\nThe key must be added to the env se", "metadata": {"source": "sg248555.pdf", "chunk_index": 176, "total_chunks": 337}}
{"text": "\nkey=$(awk -vRS=\"\\n\" -vORS=\"\\\\\\n\" '1' public.pem)echo ${key%\\\\n}\nThe key must be added to the env section of the contract with the prefix \"signingKey: \" \nbefore it is encrypted. \n/SM590000To add the key, run the following command below in the same directory where the \nenv.yaml  file is located to append the signing key to the env.yaml  file: \necho ${key%\\\\n} >> env.yaml\nAfter appending the signing key, see \u201cEncryption of environment (env) section of the \ncontract\u201d on page 51 to encrypt the  env.yaml  file with the signing key.\n/SM590000Create the contract.txt file. Add the value of workload first then add the value of env from \nthe user-data.yaml  file. Ensure that there is no space or new line after workload and \nbefore env. Also, ensure that there is no new line or space at the end of the file. It is \n\nChapter 3. Making the infrastructure secure 53recommended to cross-check the binary content of the contract.txt  file with tools such \nas hexdump. In the binary file dump, make sure th", "metadata": {"source": "sg248555.pdf", "chunk_index": 177, "total_chunks": 337}}
{"text": "content of the contract.txt  file with tools such \nas hexdump. In the binary file dump, make sure that there is no 0a ASCII value as the last \nentry. The contract.txt  file should look sim ilar to the following text:\nhyper-protect-basic.js7TGt77EQ5bgkjhC0pViFTRHqWtn..............hyper-protect-ba\nsic.VWg/5/SWE+9jLkjhr8q4i.........\nAlternatively, if you defined the workload and env sections as discussed in 3.1.1, \u201cThe \nworkload section\u201d on page 39 and 3.1.3, \u201cThe env section\u201d on page 47, then you can create the  contract.txt  file with the echo command:\necho \n\"hyper-protect-basic.${ENCRYPTED_PASSWORD_W}.${ENCRYPTED_WORKLOAD}hyper-protect-basic.${ENCRYPTED_PASSWORD_E}.${ENCRYPTED_ENV}\" > contract.txt\n/SM590000A signature can then be generated with the echo command:\necho $( cat contract.txt | openssl dgst -sha256 -sign private.pem | openssl enc \n-base64) | tr -d ' '\n/SM590000This can then be added to the user-data.yaml  contract with the prefix \n\"envWorkloadSignature:\" or use the echo comm", "metadata": {"source": "sg248555.pdf", "chunk_index": 178, "total_chunks": 337}}
{"text": " added to the user-data.yaml  contract with the prefix \n\"envWorkloadSignature:\" or use the echo command to append the signature directly in the \nuser-data.yaml  file that was started in the workload section and add to the env section:\necho \"envWorkloadSignature: `echo $( cat contract.txt | openssl dgst -sha256 \n-sign private.pem -passin pass:CustomPassphrase | openssl enc -base64) | tr -d ' '`\"  >> user-data.yaml\n3.3  Contract certificates\nTo protect the contract a public and private key pair is created as part of the Hyper Protect Secure Build (HPSB) pipeline that  is used to generate the HPCR image. This key pair is used \nto provide confidentiality for contract contents. The public X509 certificate of the Contract Encryption public key is published by IBM and can be validated with the 3rd party certificate authority root key by any persona out-of-band. \nEach persona independently encrypts their contra ct section using this Contract Encryption \npublic key. The contract encryption priv", "metadata": {"source": "sg248555.pdf", "chunk_index": 179, "total_chunks": 337}}
{"text": "pts their contra ct section using this Contract Encryption \npublic key. The contract encryption private ke y is randomized during image build and exists \ninside the Secure Execution encrypted HPCR image only. Such image can only be decrypted by using Secure Execution and keys rooted in hardware of the IBM Z or IBM LinuxONE \nplatform. During deployment this key is used by the Bootloader to decrypt the Contract and the Bootloader ensures protection of this key from User space and the Workload. \nCertificate Revocation List\nA Certificate Revocation List (CRL) is a list of digital certificates that have been revoked by \nthe Certificate Authority (CA) before their scheduled expiration date and should no longer be trusted. According to RFC 5280, a revoked certificate can be in one of two states:\n1. Revoked. A certificate is  irreversibly revoked if: \n\u2013 it is discovered that the CA improperly issued a certificate\u2013 the private-key for the certificate is compromised for some reason\n2. Hold. A ce", "metadata": {"source": "sg248555.pdf", "chunk_index": 180, "total_chunks": 337}}
{"text": "sued a certificate\u2013 the private-key for the certificate is compromised for some reason\n2. Hold. A certificate can be put on hold if there is a chance that a private key is \ncompromised. The hold can be removed if it is determined that the private key was not compromised.\n\n54 Applying Data Protection and Confidentiality in a Hybrid Cloud EnvironmentThe HPCR images used to build  HPVS instances are accompanie d by a CRL, so the user \ncan verify that the certificates being used to validate contract encryption certificate and validate attestation certificate are in fact valid.\nFor more details, consult IBM Hyper Protect Virtual Server fo r VPC: Validating the Certificates  \nand IBM Hyper Protect Virtual Serv er: Validating the certificates  \n3.4  Attestation\nAttestation is the process with which a TEE or Hyper Protect Platform can provide evidence \nor measurements of its origin and current state. This evidence can be verified by another party, for example a party assuming the Auditor perso", "metadata": {"source": "sg248555.pdf", "chunk_index": 181, "total_chunks": 337}}
{"text": "tate. This evidence can be verified by another party, for example a party assuming the Auditor persona, who can then decide whether to trust the application running in the TEE or not. Typically, the attestation record is signed by a trusted key that is anchored in hardware that can be vouched for by a manufacturer. This is \nnecessary to assure the Auditor that is representing the party validating the evidence was not created or altered by an unauthorized component or actor. The attestation record enables validation and proof by the Auditor persona with root of trust based in 3rd-party authority. See Figure 3-1.\nFigure 3-1   Verifying trust in an attestation record\nThe HPVS instance provides an attestation record  that is securely generated and signed by \nthe Bootloader during the instance deployment. The signing key is published as a X509 certificate and can be validated out-of-band to a 3rd-party certificate authority. The attestation record is available to the workload only if the at", "metadata": {"source": "sg248555.pdf", "chunk_index": 182, "total_chunks": 337}}
{"text": " 3rd-party certificate authority. The attestation record is available to the workload only if the attestationPublicKey  section is provided in the \ncontract.\nThe Workload Provider persona can implement me ans for providing the attestation record to \nthe Auditor persona. The Auditor can then verify, out-of-band, the environment in which the workload was started. \nFigure 3-2 on page 55 highlights the creation and management of the certificate hierarchy \nthat is involved in signing th e Attestation Record. The Attestation Record is signed by the \nHyper Protect Attestation Signing Key (HPASK). The HPASK can be confirmed by the \npublished intermediate certificate. The intermediate certificate is signed by a 3rd party \n\n\nChapter 3. Making the infrastructure secure 55certificate authority, which is proven by the root certificate of that given certificate authority, \nthus completing the chain of trust. \nFigure 3-2   Validating content  of an attestation record\nAn optional public key for encryp", "metadata": {"source": "sg248555.pdf", "chunk_index": 183, "total_chunks": 337}}
{"text": " trust. \nFigure 3-2   Validating content  of an attestation record\nAn optional public key for encrypting the Attestation Record at the point of creation is provided \nby the Auditor persona. The public key is defined in the contract section: attestationPublicKey. The private part of this key is kept secret by the Auditor. The hash of this public key is added to the Attestation Record. By encrypting the Attestation Record and including the hash of the public key that is used for encryption within the Attestation Record, only the Auditor can decrypt the attestation record. Only the auditor ca n validate that the workload that is deployed \nin the enclave is the expected and untampered version of the workload that is expected to be deployed. \nThis attestation record contains measurements of what has been started and can be used to \nvalidate that the environment is the one deployed based on the following measurements: \n/SM590000The original base image. The compressed root file system to be s", "metadata": {"source": "sg248555.pdf", "chunk_index": 184, "total_chunks": 337}}
{"text": "e following measurements: \n/SM590000The original base image. The compressed root file system to be stored in the LUKS \nencrypted partition. \n/SM590000The cloud initialization options, including t he contract. The Hyper Protect Attestation \nSigning Key confirms with signature that the image got created in the HPSB pipeline. \nThe reference values for the measurements spec ific to the HPCR Image used are originated \nin the HPSB pipeline. Ot her measurements like the Cloud in itialization options  are dependent \non the contract or can be used by the workload to provide insight about identifying individual \ninstance, which enables the Auditor persona to  validate that the deployment is as expected.\nFor more details, consult the following web pages:\n/SM590000IBM Cloud Hyper Protect for VPC: Attestation  \n/SM590000The Second Generation of Hyper Protect Platform\n/SM590000Confidential Computing with SUSE Linux Ente rprise Base Container Images Using the \nIBM Hyper Protect Platform\n\n\n56 Applying", "metadata": {"source": "sg248555.pdf", "chunk_index": 185, "total_chunks": 337}}
{"text": "ith SUSE Linux Ente rprise Base Container Images Using the \nIBM Hyper Protect Platform\n\n\n56 Applying Data Protection and Confidentiality in a Hybrid Cloud Environment3.5  Logging for HPVS instances\nTo start an HPVS instance, set up logging first by  adding the logging co nfiguration in the env \nsection of the contract. The instance reads the configuration and configures logging. All other services start only after logging is configured. If the logging configuration is incorrect, the instance will not start and an error message is displaye d in the serial console.\nThe logs include startup logs, service logs issued by the HPVS instance, and container logs.\nIBM Log Analysis in IBM Cloud\nLogging to Log Analysis depends on the state and health of the Log Analysis service. Service \noutages might lead to a loss of log data. If yo u are logging data for audit purposes, consider \nusing a logging service by performing the following steps:\n1. Log in to your IBM Cloud account.\n2. Provision a Log A", "metadata": {"source": "sg248555.pdf", "chunk_index": 186, "total_chunks": 337}}
{"text": "service by performing the following steps:\n1. Log in to your IBM Cloud account.\n2. Provision a Log Analysis instance. Choose a plan according to your requirements.\n3. After creating the Log Analysis instance, click it to open it and click Open dashboard .\n4. Click the question mark icon at the lower left  of the page to view Install Inst ructions. \n5. On the Add Log Source page, under Via Syslog, click rsyslog .\n6. Make a note of the ingestion key value at the upper right of the page, and the endpoint \nvalue. The endpoint value is contained in that starts with *.*. In Example 3-13, the \nendpoint value is syslog-u.au-syd.logging.cloud.ibm.com .\nExample 3-13   Start log analysis\n### START Log Analysis rsyslog logging directives ###\n## TCP TLS only ##\n$DefaultNetstreamDriverCAFile /etc/ld-root-ca.crt # trust these CAs$ActionSendStreamDriver gtls # use gtls netstream driver$ActionSendStreamDriverMode 1 # require TLS$ActionSendStreamDriverAuthMode x509/name # authenticate by hostname$Action", "metadata": {"source": "sg248555.pdf", "chunk_index": 187, "total_chunks": 337}}
{"text": "riverMode 1 # require TLS$ActionSendStreamDriverAuthMode x509/name # authenticate by hostname$ActionSendStreamDriverPermittedPeer *.au-syd.logging.cloud.ibm.com## End TCP TLS only ##\n$template LogDNAFormat,\"<%PRI%>%protocol-version% %timestamp:::date-rfc3339% \n%HOSTNAME% %app-name% %procid% %msgid% [logdna@48950 key=\\\"bc8a5ba9aa5c0c12b26c6c45089228a4\\\"] %msg%\"\n# Send messages to Log Analysis over TCP using the template.\n*.* @@syslog-u.au-syd.logging.cloud.ibm.com:6514;LogDNAFormat\n### END Log Analysis rsyslog logging directives ##7. Add these values in the env logging subsection of the contract: \n    env:\n      logging:        logDNA:Tip: For workloads that produce sensitive info rmation, it is poss ible to encrypt log \nmessages.\n\nChapter 3. Making the infrastructure secure 57          hostname: ${RSYSLOG_LOGDNA_HOSTNAME}\n          ingestionKey: ${LOGDNA_INGESTION_KEY}\nFor more information, see \u201cThe logging subsection\u201d on page 48.\nWhen the HPVS instance boots, it extracts the Log Analy", "metadata": {"source": "sg248555.pdf", "chunk_index": 188, "total_chunks": 337}}
{"text": "on, see \u201cThe logging subsection\u201d on page 48.\nWhen the HPVS instance boots, it extracts the Log Analysis info rmation from the contract and \nconfigures accordingly, so that all the logs are routed to the endpoint specified. The information can be seen on the console window of HPVS during boot up. After that happens, open the Log Analysis dashboard and view the logs from the virtual server instance.\nsyslog\nLogging can be configured with a generic syslog backend such as an rsyslog server or a Logstash server. The HPVS instan ce uses TLS with mutual auth entication to connect to the \nlogging backend. Find the following pieces of information to configure logging:\n/SM590000Syslog hostname and port.\n/SM590000Certificate Authority (CA). The certificate used to verify the certificate chain both for client \nand server authentication. The same CA must be used for both the client and server certificates.\n/SM590000Client certificate. Used to  prove the client to the server, signed by the CA.\n/SM590", "metadata": {"source": "sg248555.pdf", "chunk_index": 189, "total_chunks": 337}}
{"text": "ates.\n/SM590000Client certificate. Used to  prove the client to the server, signed by the CA.\n/SM590000Client key. A private key used by the vi rtual server instance to establish trust.\nComplete the following parts of the contract with the information. The certificates and the key \nmust be in PEM format\n2:\nenv: |\ntype: env\n  logging:\n    syslog:\n      hostname: ${HOSTNAME}      port: 6514      server: ${CA}\n      cert: ${CLIENT_CERTIFICATE}\n      key: ${CLIENT_PRIVATE_KEY}\n2  A container format that includes public  certificate or the entire certificate chain (private key, public key, root \ncertificates).Note:  Make sure to use a strong digest algorithm for the certificates. Otherwise, the syslog \nserver might reject the certificates.\nAlso, the port value can be changed to any valid TCP port number, however, 6514 is the \ndefault port that is used for secure logging. If you use the Crypto Express Network API, also called the Crypto Appliance, the default port must be used. A different p", "metadata": {"source": "sg248555.pdf", "chunk_index": 190, "total_chunks": 337}}
{"text": " Express Network API, also called the Crypto Appliance, the default port must be used. A different port configuration is not supported by the Crypto Appliance.\n\n58 Applying Data Protection and Confidentiality in a Hybrid Cloud EnvironmentPreparation steps\nYou can use the following procedure to create the required certificates and keys. The example \nuses openssl  and shows bash  syntax.\n1. Create a CA private key and a certificate signing request (CSR).\nPrepare the ca.cnf  configuration file:\n[ req ]default_bits = 2048\ndefault_md = sha256\nprompt = noencrypt_key = no\ndistinguished_name = dn\n[ dn ]\nC = US\nO = Logstash Test CACN = ca.example.org\n2. Create the key and certificate:\n# create private key\nopenssl genrsa -out ca-key.pem 4096# create CSR\nopenssl req -config ca.cnf -key ca-key.pem -new -out ca-req.csr\n# create self-signed CA\nopenssl x509 -signkey ca-key.pem -in ca-req.csr -req -days 365 -out ca.crt\n3. Create files used on the rsyslog server:\nPrepare the server.cnf  configuration f", "metadata": {"source": "sg248555.pdf", "chunk_index": 191, "total_chunks": 337}}
{"text": " 365 -out ca.crt\n3. Create files used on the rsyslog server:\nPrepare the server.cnf  configuration file. It is important to set the default_md value to at \nleast sha256 . Make sure to complete the correct information for the dn field. It is preferred \nto use a domain name for CN, but an IP is also acceptable. For more information, see the OpenSSL documentation on Subject Alternative Name.\n\u2013 Example that uses a hostname:\n[ req ]default_bits = 2048\ndefault_md = sha256\nprompt = noencrypt_key = no\ndistinguished_name = dn\n[ server ]Note:  Make sure to update dn with your values. The actual values can be selected, and \nthey do not play a role for the subsequent processing.\n\nChapter 3. Making the infrastructure secure 59subjectAltName = DNS:${HOSTNAME}\nextendedKeyUsage = serverAuth\n[ dn ]\nC = US\nO = Rsyslog Test Server\nCN = ${HOSTNAME}\n\u2013 Example that uses an IP address:\n[ req ]\ndefault_bits = 2048default_md = sha256\nprompt = no\nencrypt_key = nodistinguished_name = dn\n[ server ]\nsubjectAltName", "metadata": {"source": "sg248555.pdf", "chunk_index": 192, "total_chunks": 337}}
{"text": "048default_md = sha256\nprompt = no\nencrypt_key = nodistinguished_name = dn\n[ server ]\nsubjectAltName = IP:${IP}\nextendedKeyUsage = serverAuth\n[ dn ]\nC = US\nO = Rsyslog Test ServerCN = ${IP_OR_HOSTNAME}\n4. Create the key and certificate. Ensure the server certificate server.crt  contains a SAN for \nthe IP or the hostname, depending on whether the server is accessed through IP or hostname.\n    # create private key\n    openssl genrsa -out server-key.pem 4096\n    # create CSR for the server certificate    openssl req -config server.cnf -key server-key.pem -new -out server-req.csr\n    # have the CA created in (1) sign the certificate\n    openssl x509 -req -in server-req.csr -days 365 -CA ca.crt -CAkey ca-key.pem \n-CAcreateserial -extfile server.cnf -extensions server -out server.crt\n5. Create files used on the client side for the HPVS instance.\nPrepare the client.cnf configuration file:\n    [ req ]\n    default_bits = 2048\n    default_md = sha256\n    prompt = no    encrypt_key = no\n\n60 Apply", "metadata": {"source": "sg248555.pdf", "chunk_index": 193, "total_chunks": 337}}
{"text": " req ]\n    default_bits = 2048\n    default_md = sha256\n    prompt = no    encrypt_key = no\n\n60 Applying Data Protection and Confidentiality in a Hybrid Cloud Environment    distinguished_name = dn\n    [ dn ]\n    C = US    O = Logstash Test Client\n    CN = client.example.org\n6. Create the key and certificate:\n    # create private key\n    openssl genrsa -out client-key.pem 4096\n    # create CSR for client auh\n    openssl req -config client.cnf -key client-key.pem -new -out client-req.csr    # have the CA created in (2) sign the certificate\n    openssl x509 -req -in client-req.csr -days 365 -CA ca.crt -CAkey ca-key.pem \n-CAcreateserial -out client.crt\n    # export key to PKCS#8 format    openssl pkcs8 -topk8 -inform PEM -outform PEM -nocrypt -in client-key.pem \n-out client-key-pkcs8.pem\nClient setup steps\n1. Configure the contract with the template in Example 3-14.\nExample 3-14   Contract template\nenv: |\ntype: env\n    logging:        syslog:            hostname: ${HOSTNAME}            por", "metadata": {"source": "sg248555.pdf", "chunk_index": 194, "total_chunks": 337}}
{"text": "emplate\nenv: |\ntype: env\n    logging:        syslog:            hostname: ${HOSTNAME}            port: 6514            server: ${CA}            cert: ${CLIENT_CERTIFICATE}            key: ${CLIENT_PRIVATE_KEY}\n2. Use the content of the follo wing files in preparation to  fill in the placeholders:\n\u2013 The value for ${CA} can be found in the ca.crt\n file. See Step 1 on page 58 . \n\u2013 The value for ${CLIENT_CERTIFICATE} can be found in the client.crt  file. See Step \n5 on page 59.\n\u2013 The value for ${CLIENT_PRIVAT E_KEY} can be found in the client-key-pkcs8.pem \nfile. See Step 5 on page 59Note:  Make sure to update dn with your values. Whether the actual values play a role \ndepends on the StreamDriver.Authmode setting. In this example, we use the setting StreamDriver.Authmode=\"x509/certvalid\". In this case, the value of dn does not play a \nrole because all valid client certificates ar e accepted. Adjust this according to your \nneeds. For more information, see StreamDriver.Authmode .\n\nChapter 3.", "metadata": {"source": "sg248555.pdf", "chunk_index": 195, "total_chunks": 337}}
{"text": " Adjust this according to your \nneeds. For more information, see StreamDriver.Authmode .\n\nChapter 3. Making the infrastructure secure 61\u2013 The values for ${HOSTNAME}, ${ CA}, ${CLIENT_CERTIFICATE}, and \n${CLIENT_PRIVATE_KEY} are strings without extra encoding or escaping. Regardless \nof their, ensure you use valid YAML For more information, see Scalars . \nIn Example 3-15, \u201c|\u201d (the pipe symbol) can be us ed to provide literal values, so the value of \nthe certificates or keys can simply be pasted into the YAML file. The correct indentation must be observed. Note that the certificate values are truncated with \u201c\u2026\u201d. For the complete example, see Append ix A, \u201cClient contract setu p sample files\u201d on page 99.\nExample 3-15   Client cert ificate - literal values \nenv: |\ntype: env\n   logging:      syslog:         hostname: ${HOSTIP} # eg 10.0.0.8 or ${HOSTNAME}         port: 6514         server: |            -----BEGIN CERTIFICATE-----            MIIEuDCCAyCgAwIBAgIUBR9g6L5hivov7eNT00HSXW39oD0wDQ", "metadata": {"source": "sg248555.pdf", "chunk_index": 196, "total_chunks": 337}}
{"text": "           -----BEGIN CERTIFICATE-----            MIIEuDCCAyCgAwIBAgIUBR9g6L5hivov7eNT00HSXW39oD0wDQYJKoZIhvcNAQEL            BQAwXzELMAkGA1UEBhMCVVMxEzARBgNVBAgMCkNhbGlmb3JuaWExFDASBgNVBAcM            C0xvcyBBbmdlbGVzMQwwCgYDVQQKDANJQk0xFzAVBgNVBAMMDmNhLmV4YW1wbGUu            \u2026            -----END CERTIFICATE-----         cert: |            -----BEGIN CERTIFICATE-----            MIID0zCCAjsCFFS5goaaDyhsJsUHv5WooqDg9gqGMA0GCSqGSIb3DQEBCwUAMF8x            CzAJBgNVBAYTAlVTMRMwEQYDVQQIDApDYWxpZm9ybmlhMRQwEgYDVQQHDAtMb3Mg            QW5nZWxlczEMMAoGA1UECgwDSUJNMRcwFQYDVQQDDA5jYS5leGFtcGxlLm9yZzAe            \u2026            -----END CERTIFICATE-----         key: |            -----BEGIN RSA PRIVATE KEY-----            MIIEogIBAAKCAQEAvQoaZ9z2ZU0sKCoJ+lTyzI7vN3Mhc2QOsSYBWxrQIFUt4WW1            pinXXOqlo4iPRnQsQPzhkN8blZrgI2SFk1N8IdK8JHFcO9yVWEKmnxNeIOgiOvjr            k3nSTkDH7GZyZe0p0d+Dbk671P4cKoxi32JgSK2iFelZnYrgELiZFWbIZfKuy4Yz\n            \u2026\n            -----END RSA PRIVATE KEY-----\nIn Examp", "metadata": {"source": "sg248555.pdf", "chunk_index": 197, "total_chunks": 337}}
{"text": "oxi32JgSK2iFelZnYrgELiZFWbIZfKuy4Yz\n            \u2026\n            -----END RSA PRIVATE KEY-----\nIn Example 3-16 the new lines are replaced with \\n and carriage returns are deleted to \nmake sure the content fits in one line between the inverted commas. For more information, see scalars in double-quoted style . The certificate values are truncated with \u201c\u2026\u201d. For the \ncomplete example, see Append ix A, \u201cClient contract setu p sample files\u201d on page 99.\nExample 3-16   Client certificate - double-quoted\nenv: |\ntype:env\n   logging:      syslog:         hostname: ${HOSTIP} # eg 10.0.0.8 or ${HOSTNAME}         port: 6514         server: \"-----BEGIN CERTIFICATE-----\\nMIIFCTCCAvECFEp7wJLz4jNStIsVH2dUeHDN26ZyMA0GCSqGSIb3DQEBCwUAMEEx\\nCzAJBgNVBAYTAlVTMRkwFwYDVQQKDBBMb2dzdGFzaCBUZXN0IENBMRcwFQYDVQQD\\nDA5jYS5leGFtcGxlLm9yZzAeFw0yMzAxMDUxNjU0MTNaFw0yNDAxMDUxNjU0MTNa\u2026\\n-----END CERTIFICATE-----\\n\"\n\n62 Applying Data Protection and Confidentiality in a Hybrid Cloud Environment         cert: \"-----BEGIN \nCERTI", "metadata": {"source": "sg248555.pdf", "chunk_index": 198, "total_chunks": 337}}
{"text": "g Data Protection and Confidentiality in a Hybrid Cloud Environment         cert: \"-----BEGIN \nCERTIFICATE-----\\nMIIFETCCAvkCFBhx5DuYtRzCxRx8Bo+WIS2LFI2uMA0GCSqGSIb3DQEBCwUAMEEx\\nCzAJBgNVBAYTAlVTMRkwFwYDVQQKDBBMb2dzdGFzaCBUZXN0IENBMRcwFQYDVQQD\u2026\\n-----END CERTIFICATE-----\\n\"         key: \"-----BEGIN PRIVATE KEY-----\\nMIIJQQIBADANBgkqhkiG9w0BAQEFAASCCSswggknAgEAAoICAQCtj437cgRishCl\\n0w9PrEyqSxJLjeDb7jgR1iI82ic/YqMRR0b+DnsIGcg5pR9nK+DcVz1E4EyGphro\u2026\\n-----END PRIVATE \nYou can also use other valid YAML variations. Out of the two variations described, the \nliteral variation is considered more user friend ly as it allows for eas ier visualization of the \ncomplete YAML file. However, unless a YAML compatible editor is used, spaces must be added to the beginning of the pasted lines to match the correct indentation. In this case, it might be easier to use double-quoted variants a nd a simple script to output the certificate \nand key files in the correct fo rm. See Appendix A, \u201cClient cont ract s", "metadata": {"source": "sg248555.pdf", "chunk_index": 199, "total_chunks": 337}}
{"text": "t to output the certificate \nand key files in the correct fo rm. See Appendix A, \u201cClient cont ract setup sample files\u201d on \npage 99 for sample script yaml_doublequoted_input.sh .\nServer setup steps\nThere are many ways to set up a compatible server endpoint. The following steps provide a \nsimple setup of an rsyslog server: \n1. Wwe are using an Ubuntu image for our examples. Install the required server packages:\napt-get install rsysl og rsyslog-gnutls\n2. Get certificates and keys from the preparation steps: \n\u2013 ca.crt - from Preparation Step 1 on page 58 , copy to /certs/ca.crt\n\u2013 server.crt - from Preparation Step 3 on page 58 , copy to /certs/server.crt\n\u2013 server-key.pem - from Preparation Step 3 on page 58 , copy to /certs/server-key.pem\n3. Configure the rsyslog server in the /etc/r syslog.d/server.conf file. See Example 3-17.\nExample 3-17   rsyslog server config file\n# make gtls driver the default and set certificate files\n$DefaultNetstreamDriver \"gtls\"$DefaultNetstreamDriverCAFile /cert", "metadata": {"source": "sg248555.pdf", "chunk_index": 200, "total_chunks": 337}}
{"text": " default and set certificate files\n$DefaultNetstreamDriver \"gtls\"$DefaultNetstreamDriverCAFile /certs/ca.crt$DefaultNetstreamDriverCertFile /certs/server.crt$DefaultNetstreamDriverKeyFile /certs/server-key.pem# provides TCP syslog receptionmodule(load=\"imtcp\"        StreamDriver.Name=\"gtls\"        StreamDriver.Mode= \"1\"        StreamDriver.Authmode=\"x509/certvalid\" # Currently, CA does not support#       StreamDriver.Authmode=\"anon\" # Use this for CA server)input(type=\"imtcp\" port=\"6514\")# Template for incoming logs$template incoming-remote-logs,\"/var/log/remotelogs/%FROMHOST-IP%/%PROGRAMNAME%.log\"*.* ?incoming-remote-logs    \nFor more information, see rsyslog . The example config will log the received logs to the \ndirectory and file / var/log/remotelogs/%FROMHOST-IP%/%PROGRAMNAME%.log.  So host-ip  is \nthe IP of the remote host that is sending logs and the program name is the running application that is sending logs. In a producti on configuration, you might want to forward \nthe logs ", "metadata": {"source": "sg248555.pdf", "chunk_index": 201, "total_chunks": 337}}
{"text": "plication that is sending logs. In a producti on configuration, you might want to forward \nthe logs to a database, but this is outside of the scope of this documentation.\n\nChapter 3. Making the infrastructure secure 63If you are setting up a logging server that will also be used by the Crypto Express Network \nAPI, then uncomment the line StreamDriver.Authmode=\"anon\" and comment the previous line, StreamDriver.Authmode=\"x509/certvalid\", because the Crypto Appliance is not compatible with StreamDriver.Authmode=\"x509/certvalid\".\n4. Restart the syslog service:\nservice syslog restart\n3.6  Encrypting data volumes\nThe data volume that can be at tached to an HPVS instance is  protected by a Linux Unified \nKey Setup (LUKS) encryption passphrase that is derived from seeds provided during deployment. \nFor workloads on IBM Cloud, a higher level of encry ption protection and control is possible by \ncombining the seeds with an additional secret that is generated by, and held within, the HPCS. HPCS i", "metadata": {"source": "sg248555.pdf", "chunk_index": 202, "total_chunks": 337}}
{"text": "ombining the seeds with an additional secret that is generated by, and held within, the HPCS. HPCS is backed by FIPS 140-2 Level 4-certified hardware, which is the highest offered by any cloud provider in the industry.\nBefore proceeding with this of fering, thought should be given to the availability aspects of \nHPCS from the on-premises environment, such as additional physical internet connections. \nHow your data volume is encrypted\nWithout your own key, the data volume that is attached to the instance is encrypted \nautomatically with two seeds that are provided in the  workload - volume s and env - volumes \nsections of the contract. The seeds are internally converted to UTF8 sequences and then concatenated. The hash (SHA256) of the concatenated sequence is computed as a hexdigest, which is used as the LUKS passphrase to encrypt the data volume. For more information, see 3.1, \u201cThe contract\u201d on page 38.\nProtecting your sensitive data with your own key\nKey management service (KMS) suppo", "metadata": {"source": "sg248555.pdf", "chunk_index": 203, "total_chunks": 337}}
{"text": "act\u201d on page 38.\nProtecting your sensitive data with your own key\nKey management service (KMS) support is integrated in HPCS for HPVS for VPC with \nibm-hyper-pro tect-container-r untime-1-0-s390x-11 and for HPVS for IBM LinuxONE or IBM Z \nwith product version 2.1.5. Note:  The gnutls package imposes a requirement for the signatures for the client \ncertificate. For more information, see Digital signatures. \nAlso, in this configuration, logs are accepted from any client certificate that is signed by \nthe certificate authority through the x509/certvalid mode. This might change depending on the StreamDriver.Authmode setting. For more information, see StreamDriver.Authmode .\n\n64 Applying Data Protection and Confidentiality in a Hybrid Cloud EnvironmentHPCS generates a random value as the third seed and wraps it with the customer root key \n(CRK). The wrapped seed is stored in the metadata partition of your data volume. The LUKS passphrase is generated by using three seeds: the seed in the me", "metadata": {"source": "sg248555.pdf", "chunk_index": 204, "total_chunks": 337}}
{"text": "ition of your data volume. The LUKS passphrase is generated by using three seeds: the seed in the metadata partition, which is unwrapped first, and the two seeds from the contract. See Figure 3-3.\nFigure 3-3   Integration with key management service\nNote:  For new HPVS instances, the data volume is partitioned into two parts. The first \npartition of 100 MiB is reserved for internal metadata only. It is not to be accessed by a workload. The second partition remains as the data volume for workload. Only new volumes are partitioned.\n\n\n\u00a9 Copyright IBM Corp. 2024. 65Chapter 4. Application development in a \ntrusted environment\nThis chapter describes how IBM Hyper Protect Services can be used to establish a trusted \napplication development and deployment process. It shows how secure practices can be used to improve each part of the development process and different parts of deployed applications.\nThe chapter topics include improvements of  the application lifecycle and application \ndevelopmen", "metadata": {"source": "sg248555.pdf", "chunk_index": 205, "total_chunks": 337}}
{"text": "s.\nThe chapter topics include improvements of  the application lifecycle and application \ndevelopment, test, build, and release. It includes descriptions of initial and update deployment, and aid for secure implementation of the different steps is provided. Where feasible, multiple options are provided as alternatives. Less secure implementation or configuration options might be omitted.\nThe concepts are demonstrated with sample code that uses a combination of shell, makefiles, \nand Terraform commands to show how the resources can be deployed. Sample code of deployed applicatio ns is written in golang  and JavaScript .\nFor more information about the source code from this chapter, see IBM hyperprotect GitHub \nrepository .\nRequired configuration values are supplied in the form of environment variables and \nTerraform variable files. For convenience, the environment variables can be set from .env* \nfiles located next to the Makefile files within the different directories. The required valu", "metadata": {"source": "sg248555.pdf", "chunk_index": 206, "total_chunks": 337}}
{"text": " .env* \nfiles located next to the Makefile files within the different directories. The required values are outlined and describe d in sample files.\nIn this chapter, the following topics are discussed:\n/SM5900004.1, \u201cSecuring the application lifecycle\u201d on page 66\n/SM5900004.2, \u201cBuild container image by using Hyper Protect Secure Build\u201d on page 71\n/SM5900004.3, \u201cZero knowledge proofs: TLS server certificates and wrapped secrets\u201d on page 78\n/SM5900004.4, \u201cTrust in-depth based on boot flow attestation\u201d on page 85\n/SM5900004.5, \u201cData storage\u201d on page 87\n/SM5900004.6, \u201cSecuring cloud native services\u201d on page 92\n/SM5900004.7, \u201cSecure supply chain with SLSA\u201d on page 954\n\n66 Applying Data Protection and Confidentiality in a Hybrid Cloud Environment4.1  Securing the application lifecycle\nThe use cases that are described in this chapter are based on the application lifecycle of a \nsecured application that presents an interface for making monetary payments. The application is called \nSamplePayment", "metadata": {"source": "sg248555.pdf", "chunk_index": 207, "total_chunks": 337}}
{"text": "on that presents an interface for making monetary payments. The application is called \nSamplePaymentSystem and shows how sensitive payment-related \ninformation, such as credit card data, is used in a secure way. A key requirement is to run this \napplication in a confidential computing environment to ensure PII data that is in use is protected from malicious actors.\nFigure 4-1 shows a high-level overview of the Hyper Protect components that are involved in \nthe development lif ecycle of the SamplePaym entSystem application. \nFigure 4-1   SamplePa ymentSystem applicat ion lifecycle using Hyper Protect services\nFor an explanation of the different Hyper Protect components, refer to Chapter 2, \n\u201cUnderstanding the solution\u201d on page 15. For a description of the personas see, \u201cSeparation of duty\u201d on page 11.\nThe subsequent section includes discussi on of the development lifecycle phases:\n/SM590000Development\n/SM590000Test\n/SM590000Build\n/SM590000Release\n/SM590000Deployment\n/SM590000Update\n\n\nCh", "metadata": {"source": "sg248555.pdf", "chunk_index": 208, "total_chunks": 337}}
{"text": "00Development\n/SM590000Test\n/SM590000Build\n/SM590000Release\n/SM590000Deployment\n/SM590000Update\n\n\nChapter 4. Application developme nt in a trusted environment 674.1.1  Development\nCode is stored and developed against a source-code management system, which is \npredominantly Git. The most prominent hosted Git service currently is GitHub. For more information, see github.com .\nCode scanning and tests are run by a pipeline such as Jenkins, Tekton on Red Hat OpenShift \nPipelines, GitHub Actions. Also, see 4.7, \u201cS ecure supply chain with SLSA\u201d on page 95. You \ncan use the pipeline model to run various checks on source code that is committed to a repository. These checks are typi cally run against the source co de directly, but can also be \nrun during the build steps, test cases, or ephemeral automatic test deployments. Not all checks that are run need to be blocking or critical . It is also possible to  run checks that are not \npreventing integration of the code but are rais ing only informa", "metadata": {"source": "sg248555.pdf", "chunk_index": 209, "total_chunks": 337}}
{"text": "ssible to  run checks that are not \npreventing integration of the code but are rais ing only informational findings. To distinguish \nthis, the repository is configured with the required status checks. For more information, see About protected branches .\nThese repository settings can also be used to force commit signatures to allow \ncryptographically secured tracking of the code authorship. Other source-code-hosting facilities typically provid e similar functionality.\n4.1.2  Test\nThe functionality is typically secured by tests on multiple test layers. While in development, \nthe code is locally tested by using unit tests. These unit tests are designed to be portable and quick to run, and are often implemented against mocked services and static test data.\nAfter a push into the source-code management, more complicated tests can be run. These \ntests can include integration tests against ot her services that are deployed within a test \ndeployment.\nDepending on the stage in the application li", "metadata": {"source": "sg248555.pdf", "chunk_index": 210, "total_chunks": 337}}
{"text": "r services that are deployed within a test \ndeployment.\nDepending on the stage in the application lifecycle, the application is then either promoted for \nintegration, acceptance testing, or for production deployment.\nThe steps that follow are the same for all cases and differ by only the environment in which \nthe application is deployed.\n4.1.3  Build\nDepending on the specific implementation of the development pipeline and application, the developer can choose to push the developed and tested code forward into the integration test. To be able to run the application within a secured environment, it needs to be built into either a custom image or into a container to be started within the HPCR image.\nWith Hyper Protect Secure Build (HPSB), you can build a trusted container image within a \nsecure enclave that is provided by an HPVS instance. The enclave is highly isolated, where \ndevelopers can access the container only by using a specific hardened API and the cloud administrator cannot acc", "metadata": {"source": "sg248555.pdf", "chunk_index": 211, "total_chunks": 337}}
{"text": "an access the container only by using a specific hardened API and the cloud administrator cannot access the contents of the container. Therefore, the image that is built can be highly trusted. Specifically, the build server cryptographically signs the image and a \nmanifest. The manifest is a collection of materials that are used during the build and can be used for audits. Because the enclave protects the signing keys within the enclave, the signatures can be used to verify whether the image and manifest are from the build server and not from elsewhere.\n\n68 Applying Data Protection and Confidentiality in a Hybrid Cloud EnvironmentFor more details on configur ing and using HPSB in IBM Cloud  VPC and IBM LinuxONE or \nIBM Z, see Configuring and using Hyper Protect Secure Build in Hyper Protect Virtual \nServers for VPC and Building your applications wit h Hyper Protect Secure Build\n4.1.4  Release\nReleases can be targeted to internal or exte rnal deployment for different purposes ranging \nf", "metadata": {"source": "sg248555.pdf", "chunk_index": 212, "total_chunks": 337}}
{"text": "lease\nReleases can be targeted to internal or exte rnal deployment for different purposes ranging \nfrom integration testing to production use. \nAlong with the published container images the Workload Provider persona publishes the \nencrypted workload section of the contract.\nFor detailed information on the contract creation see 3.1, \u201cThe contract\u201d on page 38 and IBM \nCloud VPC: The workload section and IBM Hyper Protect Virtual Servers: About the contract .\nThe workload section of the contract defines wh ether there is a single container through the \ncompose subsection or multiple containe rs though the play subsection. For the \nSamplePaymentSystem application, we configure three containers in the play subsection. For \nmore information, see hyperprotect/redbook-samples/sf248555 .\nThe workload section of the contract can op tionally contain the references and login \ncredentials to the container registry and required volumes. Because it is encrypted by the contract encryption key of the w", "metadata": {"source": "sg248555.pdf", "chunk_index": 213, "total_chunks": 337}}
{"text": "ainer registry and required volumes. Because it is encrypted by the contract encryption key of the workload image, the workload section is not readable by the Workload Deployer persona or anyone else, such as a system administrator. \n4.1.5  Deployment\nTo deploy the application, the Workload Deployer persona complements the workload section of the contract with the env section as needed for the current scenario.\nFor detailed information on the contract creation see 3.1.3, \u201cThe env section\u201d on page 47  or \nIBM Cloud: The env section and IBM Hyper Protect Virtual Servers: The env section .\n4.1.6  Update\nUpdating a service that is  deployed on a Hyper Prot ect Virtual Server (HPVS)1 can affect \nmultiple components. When a new Hyper Protect Container Runtime (HPCR) image is released, it is recommended to update to the new version. New revisions of the images are typically released every four to six weeks and contain fixes and new features.\nFurthermore, the containers and services running wi", "metadata": {"source": "sg248555.pdf", "chunk_index": 214, "total_chunks": 337}}
{"text": "to six weeks and contain fixes and new features.\nFurthermore, the containers and services running within the runtime might need to be \nupdated for the same reasons of applying fixes and new features.\nBecause the HPCR follows a container lifecycle, an update always requires a restart of the \nHPVS instance and is thus disr uptive for the node. In cases where high availability (HA) \ncapabilities are required for the overall service, it is ne cessary to stagge r the rollout and Note:  The contract should always be encrypted with an encryption certificate to protect all \nsensitive information. See 3.2, \u201cContract encryption\u201d on page 49 for details.\nFor illustration purposes only, we show unencrypted sample co de throughout this chapter.\n1  An HPVS instance is also referred to as a Virtual Server Instance (VSI) as part of a Vi rtual Private Cloud within IBM \nCloud. \n\nChapter 4. Application developme nt in a trusted environment 69update of each HPVS so that the overall service re mains availab", "metadata": {"source": "sg248555.pdf", "chunk_index": 215, "total_chunks": 337}}
{"text": "lopme nt in a trusted environment 69update of each HPVS so that the overall service re mains available duri ng the update. All \nupdates are triggered by updates to the contract.\nUpdating the HPCR image\nWhen a new image is available within the cloud or on-premises, it can be selected when starting the HPVS. When a differ ent image is selected, it might be necessary to re-encrypt the \ncontract with HPCR-Contract-E ncryption-Public-Key. When working with a separate Workload \nProvider, they must provide the encrypted workload section first. \nTo build a complete contract for HPVS on IBM LinuxONE or IBM Z, see Downloading the IBM \nHyper Protect Container Runtime image\nTo build a complete contract for HPVS for VPC, the crea tion can be done by using the \nIBM Cloud virtual server for VPC User Interface. See Virtual server for VPC . Also, refer to \nAppendix B, \u201cCreating a Hyper Protect Virtual Server for VPC\u201d on page 107 for the corresponding steps.\nUpdating service  containers\nWhen new contain", "metadata": {"source": "sg248555.pdf", "chunk_index": 216, "total_chunks": 337}}
{"text": "rver for VPC\u201d on page 107 for the corresponding steps.\nUpdating service  containers\nWhen new container versions for the service are available, the H PVS instance must be \nrestarted to pull the image and run the new service version.\nWhen a floating tag with container signing is used to define the container versions, the \nchange might not be visible on the contract, and is in effect only at runtime. Otherwise, the digest of the images needs to be updated.\nDepending on the workload, the composition of containers might change.\n4.1.7  Application an d service development\nWithin the context of the zero-trust architecture, each service must be implemented with \nsecurity in mind. This is true for services co mmunicating over the public internet and within \nthe seemingly protected intranet.\nTo implement services following this posture, it  is useful to consider  each microservice or \nservice to be always under attack. Because of this, no connection should be trusted. Each \nconnection must be pr", "metadata": {"source": "sg248555.pdf", "chunk_index": 217, "total_chunks": 337}}
{"text": "e always under attack. Because of this, no connection should be trusted. Each \nconnection must be protected and verified.\nFurthermore, the development team must be prepared to fix and redeploy any service rapidly.\nAs previously outlined, there exist multiple attack vectors on any service that make it \nnecessary to update the service code itself or its dependencies. See 1.1, \u201cIdentifying the threat\u201d on page 2. To be able to develop, test, and deploy service updates, various best practices can be followed.\nA good starting point is the 12-factor app. For more information, see The Twelve-Factor App . \nDeveloping services this way co ntributes to testability, portab ility, scalability, and security.\n4.1.8  Working with the log\nThe log of the HPVS image does contain information th at originated from  multiple sources \nwithin the HPVS.\nUpon connection to the log server, the boot log is replayed. The first item that is replayed is \nthe kernel startup. After the in itial kernel messages,  the r", "metadata": {"source": "sg248555.pdf", "chunk_index": 218, "total_chunks": 337}}
{"text": ". The first item that is replayed is \nthe kernel startup. After the in itial kernel messages,  the rest of the HPVS boot process is \n\n70 Applying Data Protection and Confidentiality in a Hybrid Cloud Environmentvisible. The boot and HPVS configuration is internally orchestrated using systemd. After the \ncontract validation and mounting of eventual data volumes the log shows the start of the workload containers.\nDifferent boot stages record their states into the log for audit purposes. Notable log tokens \nhave the format HPL[0-9]{5}[IE ]. Other tokens are logged during the boot and deployment \nprocess of an HPVS instance.\nFor example, a successful startup of the instance logs the special token HPL10001I. Se e \nExample 4-1.\nExample 4-1   Successful startup example\nhpcr-dnslookup: HPL14000I: Network connectivity check completed successfully.hpcr-logging: HPL01010I: Logging has been setup successfully.hpcr-disk-mount: HPL07003I: Mounting volumes donehpcr-container-play: HPL15004I: The pod ", "metadata": {"source": "sg248555.pdf", "chunk_index": 219, "total_chunks": 337}}
{"text": "ccessfully.hpcr-disk-mount: HPL07003I: Mounting volumes donehpcr-container-play: HPL15004I: The pod started successfully.verify-disk-encryption: HPL13000I: Verify LUKS Encryptionverify-disk-encryption: HPL13003I: Checked for mount point /, LUKS encryption with 1 key slot foundverify-disk-encryption: HPL13001I: Boot volume and all the mounted data volumes are encryptedhpcr-catch-success: HPL10001I: Services succeeded -> systemd triggered hpl-catch-success service\nA failure to start the containers that are defined within the contract logs the special token \nHPL10000E  and schedule a shutdown of the HPVS. See Example 4-2.\nExample 4-2   Failed startup example\nhpcr-logging: HPL01010I: Logging has been setup successfully.\nhpcr-disk-mount: HPL07003I: Mounting volumes done hpcr-catch-failure: VSI has failed to start!hpcr-catch-failure: HPL10000E: One or more service failed -> systemd triggered hpl-catch-failed servicehpcr-catch-failure: Shutdown scheduled, use 'shutdown -c' to cancel.systemd: ", "metadata": {"source": "sg248555.pdf", "chunk_index": 220, "total_chunks": 337}}
{"text": "pl-catch-failed servicehpcr-catch-failure: Shutdown scheduled, use 'shutdown -c' to cancel.systemd: Finished Trigger Catch failed service and shutdown.\nThe workload containers are expected to log to stdout and stderr. These outputs are gathered \ninto the journal of the HPVS. Fr om the journal,  the messages are forwar ded to the configured \nlog server. \nLog configuration\nThe forwarding of the log to a remote server is mandatory and is configured within the env section of the contract. For details on the log configuration see 3.5, \u201cLogging for HPVS instances\u201d on page 56. \nA single logDNA instan ce can be used to capt ure the logs of mult iple HPVSs and other \nservers.\n4.1.9  Deployment automation - Terraform\nTo easily deploy and ma nage applications bas ed on HPVS, a certain deg ree of automation is \nencouraged. The primary mode to drive the deployment and configuration of cloud infrastructure and workload is Terraform. For more information, see Terraform .\n\nChapter 4. Application devel", "metadata": {"source": "sg248555.pdf", "chunk_index": 221, "total_chunks": 337}}
{"text": "cture and workload is Terraform. For more information, see Terraform .\n\nChapter 4. Application developme nt in a trusted environment 71The IBM-Cloud/ibm Terraform plug-in is required to manage all deployments on IBM Cloud. \nIBM provides a separate ibm-hyper-protect/hpcr Terraform plugin specific ally to simplify the \nhandling of the HPVS contract.\nFor more information, see the following websites:\n/SM590000Sample Terraform te mplates for IBM Cloud\n/SM590000Terraform samples for Hyper Protect Virtual Servers for VPC\n/SM590000ibm-hyper-protect/linuxone-vsi-automation-samples  \n4.2  Build container image by using Hyper Protect Secure Build\nYou can build a trusted container image within a secure enclave that is provided by an IBM \nHPVS. See Figure 4-2. The enclave is highly is olated. Developers ca n access the secure \nbuild server by using a specific API, and the administrator cannot access the contents of the secure build server. Therefore, the image that is built can be highly trusted. S", "metadata": {"source": "sg248555.pdf", "chunk_index": 222, "total_chunks": 337}}
{"text": "the contents of the secure build server. Therefore, the image that is built can be highly trusted. Specifically, the build server cryptographically signs the image, and a manifest. The manifest, a collection of materials that are used during the build, is fo r audit purposes. Because the enclave protects \nthe signing keys within the enclave, the signatures can be used to verify that the image and manifest are from the secure build server.\nFigure 4-2   Trusted container image\nTo securely build container images, follow the process in the subsequent sections:\n/SM590000\u201cDetermine readiness\u201d on page 71\n/SM590000\u201cInstall the secure build CLI\u201d on page 72\n/SM590000\u201cCreate client and server certificates for secure build\u201d on page 72\n/SM590000\u201cPrepare user_data.yaml\u201d on page 73\n/SM590000\u201cCreate the Hyper Protect Secure Build instance\u201d on page 74\n/SM590000\u201cConfigure the HPSB client with t he HPVS IP address\u201d on page 75\n4.2.1  Determine readiness\nEnsure that you meet the following hardware or softw", "metadata": {"source": "sg248555.pdf", "chunk_index": 223, "total_chunks": 337}}
{"text": " address\u201d on page 75\n4.2.1  Determine readiness\nEnsure that you meet the following hardware or software prerequisites: \n\n\n72 Applying Data Protection and Confidentiality in a Hybrid Cloud Environment/SM590000Linux management server from where you can run the build CLI tool \n/SM590000Recommended 2 CPUs/4 GB memory or more\n/SM590000KVM hosts in IBM Secure Execution mode are supported by these distributions:\n\u2013 Red Hat Enterprise Linux 9.0 with service\u2013 Red Hat Enterprise Linux 8.4 with service\u2013 SUSE Linux Enterprise Serv er 15 SP3 with service\n\u2013 Ubuntu Server 20.04 LTS with service\n/SM590000KVM guests in IBM Secure Execution mode  are supported by these distributions:\n\u2013 Red Hat Enterprise Linux 9.0 with service\u2013 Red Hat Enterprise Linux 8.4 with service\u2013 Red Hat Enterprise Linux 7.9 with service\u2013 SUSE Linux Enterprise Serv er 15 SP3 with service\n\u2013 SUSE Linux Enterprise Serv er 12 SP5 with service\n\u2013 Ubuntu Server 20.04 LTS with service\n/SM590000Attestation is available on IBM z16\u2122 and IBM ", "metadata": {"source": "sg248555.pdf", "chunk_index": 224, "total_chunks": 337}}
{"text": "ervice\n\u2013 Ubuntu Server 20.04 LTS with service\n/SM590000Attestation is available on IBM z16\u2122 and IBM LinuxONE 4 by these distributions:\n\u2013 Red Hat Enterprise Linux 9.1 with service\u2013 Red Hat Enterprise Linux 8.7 with service\n/SM590000Python 3.8 (Python 2.x is not supported) \n/SM590000Access to GitHub, for hosting the source code\n/SM590000Dockerfile (everything that you need to build your container image)\n/SM590000Access to IBM Cloud Registry\n/SM590000(Optional) Access to IBM Cloud Object Storage (COS) Service\n/SM590000Access to IBM HPVS for VPC\n/SM590000Get the encrypted workload section of the contract file of Secure Build from Configuring \nand using Hyper Protect Secure Build in Hyper Protect virtual server for VPC\n4.2.2  Install the secure build CLI\nUse the following steps to install the se cure build command line interface (CLI):\n1. On the client machine where Linux is installed, verify the OS version. See Example 4-3.\nExample 4-3   Verify the OS version\n$ cat /etc/os-release | grep 2", "metadata": {"source": "sg248555.pdf", "chunk_index": 225, "total_chunks": 337}}
{"text": " the OS version. See Example 4-3.\nExample 4-3   Verify the OS version\n$ cat /etc/os-release | grep 20.04 \nVERSION=\"20.04.6 LTS (Focal Fossa)\" PRETTY_NAME=\"Ubuntu 20.04.6 LTS\" VERSION_ID=\"20.04\" \n2. Download the secure build CLI code to the client machine where linux is installed. See \nExample 4-4.\nExample 4-4   Download secure build CLI\n$ git clone git@github.com:ibm-hyper-protect/secure-build-cli.git Cloning into 'secure-build-cli'... \n4.2.3  Create client and serve r certificates for secure build \nUse the following steps to create certificates  for the secure build CLI and secure build \ncommunication:\n1. Create a client cert ificate for the secure build CLI a nd secure build communication. See \nExample 4-5 on page 73.\n\nChapter 4. Application developme nt in a trusted environment 73Example 4-5   Create client certificate \n$ ./build.py create-client-cert --env sbs-config.json \nINFO:__main__:parameter file sbs-config.json renamed to sbs-config.json.2023-07-21_14-35-53.197898 INFO:root:c", "metadata": {"source": "sg248555.pdf", "chunk_index": 226, "total_chunks": 337}}
{"text": "n__:parameter file sbs-config.json renamed to sbs-config.json.2023-07-21_14-35-53.197898 INFO:root:client_certificate: generating client CA and certificate \n2. Create a server certificate for the secure build CLI and secure bu ild communication. See \nExample 4-6.\nExample 4-6   Create server certificate \n$ ./build.py create-server-cert --env sbs-config.json INFO:root:server_certificate: using supplied pem files cert_directory=.HPSBContainer-2e6ce21c-4c05-4101-abea-564f3adbd8e4 capath=./.HPSBContainer-2e6ce21c-4c05-4101-abea-564f3adbd8e4.d/client-ca.pem cakeypath=./.HPSBContainer-2e6ce21c-4c05-4101-abea-564f3adbd8e4.d/client-ca-key.pem INFO:root:server_certificate: Generating server certificate INFO:root:server_certificate: Successfully generated server CSR INFO:root:server_certificate: Successfully generated server certificate \n3. Get the environment key value pair to be used in instance-create command. See \nExample 4-7.\nExample 4-7   Get environment key value pair \n$ ./build.py instanc", "metadata": {"source": "sg248555.pdf", "chunk_index": 227, "total_chunks": 337}}
{"text": "create command. See \nExample 4-7.\nExample 4-7   Get environment key value pair \n$ ./build.py instance-env --env sbs-config.json INFO:root:client_certificate: using supplied pem files client_crt_key=.HPSBContainer-2e6ce21c-4c05-4101-abea-564f3adbd8e4 capath=./.HPSBContainer-2e6ce21c-4c05-4101-abea-564f3adbd8e4.d/client-ca.pem cakeypath=./.HPSBContainer-2e6ce21c-4c05-4101-abea-564f3adbd8e4.d/client-ca-key.pem WARNING:gnupg:gpg returned a non-zero error code: 2 INFO:__main__: \n****** Copy below environment variables and use in env contract as environment \nvariables. ******  \nCLIENT_CRT: \"LS0tLS1CRUdJTiBD\u2026\u2026RCBDRVJUSUZJQ0FURS0tLS0tCg==\" \nCLIENT_CA: \"LS0tLS1CRUdJTiB\u2026\u20265EIENFUlRJRklDQVRFLS0tLS0K\" SERVER_CRT: \"LS0tLS1CRUdJTiBDRVJUSUZJ\u2026\u2026ZCi0tLS0tRU5EIENFUlRJRklDQVRFLS0tLS0K\" SERVER_KEY: \"LS0tLS1CRUdJTiBQR1Ag\u2026\u2026U1NBR0UtLS0tLQo=\" \n4.2.4  Prepare user_data.yaml\nUse the following steps to prepare the encrypted env section of the contract:\n1. Compose a plain text contract. See Example 4-8.\nExample 4-8", "metadata": {"source": "sg248555.pdf", "chunk_index": 228, "total_chunks": 337}}
{"text": "ncrypted env section of the contract:\n1. Compose a plain text contract. See Example 4-8.\nExample 4-8   Plain text contract \nenv: | \n  type: env   logging:     logDNA:       hostname: syslog-a.us-***.ibm.com \n\n74 Applying Data Protection and Confidentiality in a Hybrid Cloud Environment      ingestionKey: ********** \n      port: 6514   volumes:     hpsb:       seed: \"******\"   env:     CLIENT_CRT: LS0tLS1CRUdJTiBD\u2026\u2026RCBDRVJUSUZJQ0FURS0tLS0tCg==     CLIENT_CA: LS0tLS1CRUdJTiB\u2026\u20265EIENFUlRJRklDQVRFLS0tLS0K     SERVER_CRT: LS0tLS1CRUdJTiBDRVJUSUZJ\u2026\u2026ZCi0tLS0tRU5EIENFUlRJRklDQVRFLS0tLS0K     SERVER_KEY: LS0tLS1CRUdJTiBQR1Ag\u2026\u2026U1NBR0UtLS0tLQo= \n2. Encrypt the env section of the contract (see Example 4-9).\nExample 4-9   Encrypted env section \nenv: hyper-protect-basic.ItMcZ+CaxWp4YbUMs2eVF6o7hiaRDMhgwWPwaTWChg2a/. \n/7cwKUEthQ1ww=\n3. Get the encrypted secure build workload of the contract. See Example 4-10.\nExample 4-10   Encrypted workload section\nworkload: \nhyper-protect-basic.JNNGRfeic/H4j5XcOLMM", "metadata": {"source": "sg248555.pdf", "chunk_index": 229, "total_chunks": 337}}
{"text": " 4-10.\nExample 4-10   Encrypted workload section\nworkload: \nhyper-protect-basic.JNNGRfeic/H4j5XcOLMMCA2KrAUpUu5+gcO5\u2026\u2026ax4E2mCzHZMUuHVk3U \n4. Add the encrypted content from the env and workload sections of the contract to prepare \nthe user_data.yaml. See Example 4-11.\nExample 4-11   Combined encrypted env and workload sections\nenv: hyper-protect-basic.ItMcZ+CaxWp4YbUMs2eVF6o7hiaRDMhgwWPwaTWChg2a/. \n/7cwKUEthQ1ww= workload: hyper-protect-basic.JNNGRfeic/H4j5XcOLMMCA2KrAUpUu5+gcO5\u2026\u2026ax4E2mCzHZMUuHVk3U \n4.2.5  Create the Hyper Prot ect Secure Build instance \nThe HPSB instance can run in an HPVS for VPC instance and in HPVS on IBM LinuxONE or \nIBM Z running in a KVM host LPAR: \n/SM590000To create an HPVS for VPC instance for the HPSB using IBM Cloud VPC UI, see \nAppendix B, \u201cCreating a Hyper Protect Virtual Server for VPC\u201d on page 107 for a setup example.\nAlso see Creating a Hyper Protect Virtual Server for VPC instance . \nA virtual private cloud (VPC) can be created in  IBM Cloud by followi", "metadata": {"source": "sg248555.pdf", "chunk_index": 230, "total_chunks": 337}}
{"text": "ual Server for VPC instance . \nA virtual private cloud (VPC) can be created in  IBM Cloud by following the instructions in \nCreating and configuring a VPC . \n/SM590000To create the HPVS in a KVM host L PAR, follow the in structions in Example of bringing up \nIBM Hyper Protect Virtual Servers on a KVM host by using the virsh utility . You must \nprovide the combined env and workload section obtained from the previous step, and use them as the content of the user-data file for deployment.\nTo configure your  HPSB instance see Bringing up the Hyper Protect Secure Build on the \nKVM LPAR .\n\nChapter 4. Application developme nt in a trusted environment 754.2.6  Configure the HPSB client with the HPVS IP address\nUse the following steps to configure the HPSB client with the HPVS IP address in  \n/etc/hosts :\n1. Ensure the floating IP addr ess of the HPSB server is ma pped to the hostname in the \n/etc/hosts  file, which is given during the certificate creation. See Example 4-12.\nExample 4-12   Veri", "metadata": {"source": "sg248555.pdf", "chunk_index": 231, "total_chunks": 337}}
{"text": "c/hosts  file, which is given during the certificate creation. See Example 4-12.\nExample 4-12   Verify the floating IP address\n$ cat sbs-config.json | grep HOSTNAME \n\"HOSTNAME\": \"test.xyz.com\", \n$ cat /etc/hosts | grep test.xyz.com  \n150.239.221.33 test.xyz.com \n2. Check that the HPSB client and HPSB server  are able to communicate. See \nExample 4-13. \nExample 4-13   Verify communications\n$ ./build.py status --env sbs-config.json INFO:__main__:status: response={     \"status\": \"\" }\n3. Update the  sbs-config.json  with the GitHub repo where the source code and dockerfile \nis present. Include the registry details for where the built container image needs to be pushed. See Example 4-14. \nExample 4-14   HPSB configuration details\n$ cat sbs-config.json {    \"HOSTNAME\": \"test.xyz.com\",     \"CICD_PORT\": \"443\",     \"IMAGE_TAG\": \"\",     \"CONTAINER_NAME\": \"HPSBContainer\",     \"GITHUB_KEY_FILE\": \"~/.ssh/id_rsa\",     \"GITHUB_URL\": \"https://github.com/ibm-hyper-protect/paynow-website\",     \"GITHUB_B", "metadata": {"source": "sg248555.pdf", "chunk_index": 232, "total_chunks": 337}}
{"text": ".ssh/id_rsa\",     \"GITHUB_URL\": \"https://github.com/ibm-hyper-protect/paynow-website\",     \"GITHUB_BRANCH\": \"main\",     \"DOCKER_REPO\": \"devuser/samplepaymentsystem\",     \"DOCKER_USER\": \"devuser\",     \"DOCKER_PASSWORD\": \"*******\",     \"IMAGE_TAG_PREFIX\": \"v3\",     \"DOCKER_CONTENT_TRUST_BASE\": \"False\",     \"DOCKER_CONTENT_TRUST_BASE_SERVER\": \"\",     \"DOCKER_RO_USER\": \"devuser\",    \"DOCKER_RO_PASSWORD\": \"******\",     \"RUNTIME_TYPE\": \"vpc\"} \n4. Initialize the HPSB server with configuration. See Example 4-15.\nExample 4-15   Initialize the HPSB server\n$ ./build.py init --env sbs-config.json \nINFO:__main__:init: response={    \"status\": \"OK\" \n\n76 Applying Data Protection and Confidentiality in a Hybrid Cloud Environment}\n5. Initiate the build  for the HPSB server. See Example 4-16.\nExample 4-16   Build for the HPSB server\n$ ./build.py build --env sbs-config.json \nINFO:__main__:build: response={     \"status\": \"OK: async build started\" } \n6. Check the progress stat us of the HPSB server build. S", "metadata": {"source": "sg248555.pdf", "chunk_index": 233, "total_chunks": 337}}
{"text": "    \"status\": \"OK: async build started\" } \n6. Check the progress stat us of the HPSB server build. See Example 4-17.\nExample 4-17   Check the status of the HPSB server build\n$ ./build.py status --env sbs-config.json \nINFO:__main__:status: response={    \"build_image_tag\": \"1.3.0.11\",    \"build_name\": \"\",    \"image_tag\": \"\",    \"manifest_key_gen\": \"\",    \"manifest_public_key\": \"\",    \"status\": \"github cloned\"} \n7. To check the final status of the build, run the command shown in Example 4-18.\nExample 4-18   Check the status after the HPSB build\n$ ./build.py status --env sbs-config.json\nINFO:__main__:status: response={    \"build_image_tag\": \"1.3.0.11\",    \"build_name\": \"docker.io.devuser.samplepaymentsystem.v3-f29b1ab.2023-07-25_09-01-40.401144\",     \"image_tag\": \"v3-f29b1ab\",    \"manifest_key_gen\": \"soft_crypto\",    \"manifest_public_key\": \"manifest.docker.io.devuser.samplepaymentsystem.v3-f29b1ab.2023-07-25_09-01-40.401144-public.pem\",    \"status\": \"success\"}\n8. Run the command in Example", "metadata": {"source": "sg248555.pdf", "chunk_index": 234, "total_chunks": 337}}
{"text": "29b1ab.2023-07-25_09-01-40.401144-public.pem\",    \"status\": \"success\"}\n8. Run the command in Example 4-19 to see the build logs. \nExample 4-19   HPSB logs\n$ ./build.py log --log build --env sbs-config.json\nINFO:__main__:2023-07-25 08:59:36,446  build_task               INFO    starting a build...\nThe full build log can be found in the Example C-1 on page 116.\n9. Get digest for the built image. See Example 4-20.\nExample 4-20   Digest for the build image\n$ ./build.py get-digest --env sbs-config.json \n\nChapter 4. Application developme nt in a trusted environment 77Digest value of the built image: \ndocker.io/devuser/samplepaymentsystem@sha256:d10e26e72a2f83a3fdf8a6a79da5b88f1b6747ce0af9309749afc55295973bd8 \n10.To get the signed public key, use the command in Example 4-21.\nExample 4-21   Signed public key\n$ ./build.py get-signed-image-publickey --env sbs-config.json\nINFO:__main__:Downloaded signed image public key to file docker.io-devuser-samplepaymentsystem-public.key \n$ cat docker.io-dev", "metadata": {"source": "sg248555.pdf", "chunk_index": 235, "total_chunks": 337}}
{"text": "igned image public key to file docker.io-devuser-samplepaymentsystem-public.key \n$ cat docker.io-devuser-samplepaymentsystem-public.key\nLS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUJsVENDQVR1Z0F3SUJBZ0lRV2RmQStQcm9tVjRwd2RVS01KYnFqREFLQmdncWhrak9QUVFEQWpBeE1TOHcKTFFZRFZRUURFeVprYjJOclpYSXVhVzh2WVdKb2FYSmhiV3N2YzJGdGNHeGxjR0Y1YldWdWRITjVjM1JsYlRBZQpGdzB5TXpBM01qVXdPVEF4TXpoYUZ3MHpNekEzTWpJd09UQXhNemhhTURFeEx6QXRCZ05WQkFNVEptUnZZMnRsCmNpNXBieTloWW1ocGNtRnRheTl6WVcxd2JHVndZWGx0Wlc1MGMzbHpkR1Z0TUZrd0V3WUhLb1pJemowQ0FRWUkKS29aSXpqMERBUWNEUWdBRWplMmFPYTVPYUE4UHJFUThHNTgybTZxWmlJaEFvYWo2bDZaaThsaDFwM01VbTBLNAp4TVBJcytZNHA2TzVzeE9tRFpFaW9SbmJOeU1NRDJrN05zNXVLYU0xTURNd0RnWURWUjBQQVFIL0JBUURBZ1dnCk1CTUdBMVVkSlFRTU1Bb0dDQ3NHQVFVRkJ3TURNQXdHQTFVZEV3RUIvd1FDTUFBd0NnWUlLb1pJemowRUF3SUQKU0FBd1JRSWdZUnZObW1nRkg1dTBSNnlENUhxcDFTcW9zM2k5cVczbWxRWVlJN2oyZXJVQ0lRRFZGNjhXbXo0RQplUXExeVJvaHIwZXpZck52OEh4eXQvUS9CMDBlQUY1NzlRPT0KLS0tLS1FTkQgQ0VSVElGSUNBVEUtLS0tLQo=>  \n11.Get the manifest files, which consist of ", "metadata": {"source": "sg248555.pdf", "chunk_index": 236, "total_chunks": 337}}
{"text": "MDBlQUY1NzlRPT0KLS0tLS1FTkQgQ0VSVElGSUNBVEUtLS0tLQo=>  \n11.Get the manifest files, which consist of files needed for auditor to check on the build. See \nExample 4-22.\nExample 4-22   Manifest files\n$ ./build.py get-manifest --env sbs-config.jsonINFO:__main__:get-manifest manifest_name: manifest.docker.io.devuser.samplepaymentsystem.v3-f29b1ab.2023-07-25_09-01-40.401144 \n12.Use the command in Example 4-23 to verify the manifest files.\nExample 4-23   Verifying the manifest files\n$ ./build.py get-manifest --env sbs-config.json  --verify-manifest\nINFO:__main__:get-manifest manifest_name: manifest.docker.io.devuser.samplepaymentsystem.v3-f29b1ab.2023-07-25_09-01-40.401144INFO:__main__:verify_manifest: manifest_name=manifest.docker.io.devuser.samplepaymentsystem.v3-f29b1ab.2023-07-25_09-01-40.401144 test=0INFO:__main__:verify=OK\n13.Get the state image, which c an be used later to bring up the HPSB instance with the same \nset of GitHub and registry configuration. It is important to safely stor", "metadata": {"source": "sg248555.pdf", "chunk_index": 237, "total_chunks": 337}}
{"text": "PSB instance with the same \nset of GitHub and registry configuration. It is important to safely store this state image. This image consists of keys that are needed to push the image into the registry. \nExample 4-24   Get state image\n$ ./build.py get-state-image --env sbs-config.jsonINFO:__main__:state:name: docker.io.devuser.samplepaymentsystem.v3-f29b1ab.2023-07-25_09-01-40.401144\n\n78 Applying Data Protection and Confidentiality in a Hybrid Cloud Environment4.3  Zero knowledge proofs: TLS server certificates and \nwrapped secrets\nWithin the context of the zero knowledge architecture, the communication between different \ncomponents requires authentication of the components against each other. These authentications depend on secrets that are generated by the components and depend on certificates that are used to exchange PINs and secret keys.\nThis section explains how secrets can be generated safely and securely, how secret keys and \ncertificates can be injected into components, and how ", "metadata": {"source": "sg248555.pdf", "chunk_index": 238, "total_chunks": 337}}
{"text": "ted safely and securely, how secret keys and \ncertificates can be injected into components, and how some common communication components, such as reverse proxies, can be configured and hardened against attacks.\n4.3.1  Passing secrets  into a secure HPVS\nTo establish verified and trusted connections to other parts of the IT landscape, it is required \nto pass information to HPVS instances. The mechanism used to pass the information must be checked for integrity and confidentiality. \nWith such a unidirectional communication ch annel, it is possible to distribute shared \ninformation and even shared secrets. The following list includes examples of shared secrets:\n/SM590000CA and server certificates to establish c onnections to only trusted servers or peers\n/SM590000Secret keys used for identification of an instance\n/SM590000Credentials used to log in to other services\nIn the HPVS instance this unidirectional comm unication channel is provided by the contract. \nFor more information, see IBM ", "metadata": {"source": "sg248555.pdf", "chunk_index": 239, "total_chunks": 337}}
{"text": "s unidirectional comm unication channel is provided by the contract. \nFor more information, see IBM Cloud: About the contract .\n4.3.2  Certificate benefits\nCertificates are generally used to support the di stribution of public keys. Embedding a public \nkey within a certificate does provide three main benefits:\n1. The certificate is signed by a certificate au thority called issuer, relaying trust to the \ncontained public key. This allo ws building a verifiable key hier archy of which only the public \nroot key must be distributed. \n2. The validity of the certificate can be defined. This is done by definition of a validity time \nframe and the option to embed revocation information that can be checked additionally. \n3. Each certificate can restrict the intended usage of the public key.\nFor a complete definition, see Internet X.509 Public Key Infrastructure Certificate and \nCertificate Revocation  List (CRL) Profile .\nWithin the context of se curing a container running in HPVS, certificates", "metadata": {"source": "sg248555.pdf", "chunk_index": 240, "total_chunks": 337}}
{"text": "tion  List (CRL) Profile .\nWithin the context of se curing a container running in HPVS, certificates are useful in many \nways. Certificates are used to simplify the verification of keys that are used to encrypt and sign the contract and to allow attestation of the started virtual server instances.\nCertificates can be used by the Workload Prov ider and the Workload Deployer to introduce \ntrusted keys within the contract. These can also be used to extend the trust into keys introduced within the workload. This is either being done by introducing an owned certificate authority (CA) or preparing a new CA for this pu rpose. It is also possible to generate and use \na key within HPCS for the CA.\n\nChapter 4. Application developme nt in a trusted environment 79For example guidance on manual generation of self-signed certificates, see Generate root CA \nkey and certificate .\n4.3.3  Importing server certificate from contract\nA common function of  an HPVS is to provide a communica tion end point in", "metadata": {"source": "sg248555.pdf", "chunk_index": 241, "total_chunks": 337}}
{"text": " certificate from contract\nA common function of  an HPVS is to provide a communica tion end point in the form of a \nsecure web server. Apart from the recommended hardening of the web server configuration, configure the server to use TLS / HTTPS. For more information, see SSL/TLS Best Practices \nfor 2023 .\nThe simplest way to achieve this as the Workload Provider is to add the required files to the \nworkload directly. This has the downside that a ll instances of the workload would be using the \nsame secret. A better option is to let the Workload Deployer supply the secrets and dependent information for each instance. In the current example, the Workload Deployer pre-generates a key and a certificate for the server to use. Certificate and key are then set as environment variables within the compose or play file.\nIt is a best practice to encode keys and certificates in Base64 when handing them through the \ncontract. How this is introduced within the container differs from the composition ", "metadata": {"source": "sg248555.pdf", "chunk_index": 242, "total_chunks": 337}}
{"text": "hem through the \ncontract. How this is introduced within the container differs from the composition method that is used to orchestrate the containers.\nSecret environment definition in compose\nWhen you use the compose option to define th e workload, the environment attribute can be \ndefined to declare variables. For more information, see docker docs: Use the environment \nattribute . \nThe value of the variables can then be deferred to the env section. See Example 4-25.\nExample 4-25   Defer vari ables to the env section\n# set by the workload provider in compose\nenvironment:  HTTPS_CERT: \"${HTTPS_CERT_VALUE}\"  HTTPS_KEY: \"${HTTPS_KEY_VALUE}\"\nSecret environment definiti on in play with templates\nWhen using the play option to define the workload, the env attribute can be defined to declare \nvariables. For more information, see kubernetes: Define an environment variable for a \ncontainer .\nThe value of the variables can then be deferred to the env section using templates. See \nExample 4-26.\nEx", "metadata": {"source": "sg248555.pdf", "chunk_index": 243, "total_chunks": 337}}
{"text": "alue of the variables can then be deferred to the env section using templates. See \nExample 4-26.\nExample 4-26   Defer variables to the env section using templates\nworkload: |  type: workload   play:     templates:     - apiVersion: v1 ...       env:       - name: HTTPS_CERT         value: {{ .Env.HTTPS_CERT_VALUE }}       - name: HTTPS_KEY \n\n80 Applying Data Protection and Confidentiality in a Hybrid Cloud Environment        value: {{ .Env.HTTPS_KEY_VALUE }}\nSecret environment defin ition using config map\nIn simpler workload setups, it might be feasible to not use a template. Instead, you can set all \nvariables from the env section as environment variables of a container by using the special content map file, contract.config.map. In the contract.config.map file , the Workload \nDeployer adds secrets in the env section of the contract. See Example 4-27.\nExample 4-27   Variables settings in the env section\n# set by deployer in env sectionenv: |  type: env    HTTPS_CERT_VALUE: LS0tLS1CRUd", "metadata": {"source": "sg248555.pdf", "chunk_index": 244, "total_chunks": 337}}
{"text": "n the env section\n# set by deployer in env sectionenv: |  type: env    HTTPS_CERT_VALUE: LS0tLS1CRUdJTiBDRVJUS...0tLS0tCg==    HTTPS_KEY_VALUE: HVkp4BMwFunWgmay...OBwM0w==\n4.3.4  Random number generation\nAn important part of each application is the generation of random numbers. Random numbers are needed in cryptographic calculations, simulation, and other usages. IBM z/Architecture\u00ae, also known as s390x, of the IBM LinuxONE and IBM Z platforms provides special support for these functions.\nGenerating a new random key\nThe HPCS offering provides multiple improvements to generate strong keys over other environments. This extension is provided by the IBM LinuxONE and IBM Z cryptographic \ncoprocessors (Crypto Express adapter in CCA coprocessor mode or in EP11 mode).\nLinux users might already be fa miliar with the default kernel in terface to the random number \ngenerator. /dev/urandom is used for non-blocking random numbers, and /dev/random  is used \nfor entropy based random numbers.\nWhen you", "metadata": {"source": "sg248555.pdf", "chunk_index": 245, "total_chunks": 337}}
{"text": "or non-blocking random numbers, and /dev/random  is used \nfor entropy based random numbers.\nWhen you run Linux on Z, the additional pseudo random number generator, (PRNG) device, \n/dev/prandom , and true random number generator (TRNG) device, /dev/trng , are provided \nfor enhanced random number generation. See Table 4-1.\nTable 4-1   Pseudo random and random number generator devices\nFor more information, see Device Drivers, Features, and Commands .\nGenerating a new r andom key using HPCS\nIn addition to the random sources built into every IBM LinuxONE and IBM Z, the \ncryptographic accelerator hardware or hardware security module (HSM) can be used to Tip: When using this method, use only an encrypted contract to protect the secret key. \nThis can be encoded with base64 -w 0 server.crt . The application can then read and \napply these values on startup.\nLinux Linux on Z\nPseudo Random /dev/urandom /dev/prandom\nRandom /dev/random /dev/trng\n\nChapter 4. Application developme nt in a trusted envi", "metadata": {"source": "sg248555.pdf", "chunk_index": 246, "total_chunks": 337}}
{"text": "dom /dev/prandom\nRandom /dev/random /dev/trng\n\nChapter 4. Application developme nt in a trusted environment 81generate keys within the tamper resistant HSM alone without depending on or being \ninfluenced by the VM.\nIBM provides a golang grep11  library to interface with the HSM provided by the HPCS. For \nmore information, see IBM-Cloud/hpcs-grep11-go .\nThe library does include coding examples to  perform simple key operations, such as \ngenerate, encrypt, decrypt, sign, verify, and more.\nCA backed by HPCS\nTo further improve the protection for keys used by a workload, it is possible to store and use \nthe key within an HSM. This section explains the usage of the HSM provided by the HPCS service to protect a CA root key and to use it for the signing of certificates.\nTo be able to use the HPCS service, the access  information must be passed into the virtual \nserver instance. This can be done through the workload section of the contract by the Workload Provider or through the env section of ", "metadata": {"source": "sg248555.pdf", "chunk_index": 247, "total_chunks": 337}}
{"text": "through the workload section of the contract by the Workload Provider or through the env section of the contract by the Workload Deployer.\nBy using the play section within the contract, the HPCS access information is made available \nto the instance. Se Example 4-28.\nExample 4-28   HPCS access information\nworkload: |  type: workload  play:    templates:    - apiVersion: v1      kind: Pod      metadata:        name: samplepaymentsystem      spec:        containers:        - name: backend          image: icr.io/ibm/samplepaymentsystem@sha256:aa921f4009b33b926aeae931fef2b0536514e7a62ae013cee6c345b1ac7f11ba\u2026      env:      - name: HPCS_ADDRESS        value: {{ .Env.HPCS_ADDRESS }}      - name: HPCS_KEY        value: {{ .Env.HPCS_KEY }}\u2026env:\u2026  env:    HPCS_ADDRESS: ep11.us-south.hs-crypto.cloud.ibm.com:8082    HPCS_KEY: SFBDU19BUElfS0VZCg==\nThese environment variables HPCS_ADDRESS and HPCS_KEY can now be used within the \nworkload. See Example 4-29.\nExample 4-29   Environment variables\n// Rea", "metadata": {"source": "sg248555.pdf", "chunk_index": 248, "total_chunks": 337}}
{"text": " can now be used within the \nworkload. See Example 4-29.\nExample 4-29   Environment variables\n// Read the HPCS configuration from the environmentvar (\n\n82 Applying Data Protection and Confidentiality in a Hybrid Cloud EnvironmentAddress     = os.Getenv(\"HPCS_ADDRESS\")\nAPIKey      = os.Getenv(\"HPCS_KEY\")IAMEndpoint = \"https://iam.cloud.ibm.com\")\nWith the newly defined HPCS_ADDRESS and HPCS_KEY variables, you can generate a \nnew RSA keypair to be used within the certificate. See Example 4-30.\nExample 4-30   RSA keypair\nvar callOpts = []grpc.DialOption{grpc.WithTransportCredentials(credentials.NewTLS(&tls.Config{MinVersion: tls.VersionTLS12})),grpc.WithPerRPCCredentials(&util.IAMPerRPCCredentials{APIKey:   APIKey,Endpoint: IAMEndpoint,}),} func main() {context := context.Background()conn, err := grpc.Dial(Address, callOpts...)if err != nil {panic(fmt.Errorf(\"could not connect to server: %s\", err))}defer conn.Close() cryptoClient := pb.NewCryptoClient(conn)_, _, _ = GenerateKeyPair(context", "metadata": {"source": "sg248555.pdf", "chunk_index": 249, "total_chunks": 337}}
{"text": ", err))}defer conn.Close() cryptoClient := pb.NewCryptoClient(conn)_, _, _ = GenerateKeyPair(context, cryptoClient)} // generate a new 4096 bit RSA key pairfunc GenerateKeyPair(context context.Context, cryptoClient pb.CryptoClient) ([]byte, []byte, error) {generateKeyPairResponse, err := cryptoClient.GenerateKeyPair(context, \ngenerateRSA4096KeyPairRequest())\nif err != nil {panic(fmt.Errorf(\"generate RSA key pair error: %w\", err))} return generateKeyPairResponse.PubKeyBytes, generateKeyPairResponse.PrivKeyBytes, nil} func generateRSA4096KeyPairRequest() *pb.GenerateKeyPairRequest {return &pb.GenerateKeyPairRequest{Mech: &pb.Mechanism{Mechanism: ep11.CKM_RSA_PKCS_KEY_PAIR_GEN,},PubKeyTemplate: util.AttributeMap(ep11.EP11Attributes{ep11.CKA_ENCRYPT:         true,ep11.CKA_VERIFY:          true,ep11.CKA_MODULUS_BITS:    4096,ep11.CKA_PUBLIC_EXPONENT: 65537,}),PrivKeyTemplate: util.AttributeMap(ep11.EP11Attributes{\n\nChapter 4. Application developme nt in a trusted environment 83ep11.CKA_PRIV", "metadata": {"source": "sg248555.pdf", "chunk_index": 250, "total_chunks": 337}}
{"text": "p(ep11.EP11Attributes{\n\nChapter 4. Application developme nt in a trusted environment 83ep11.CKA_PRIVATE:     true,\nep11.CKA_SENSITIVE:   true,ep11.CKA_VERIFY:      false,ep11.CKA_ENCRYPT:     false,ep11.CKA_DECRYPT:     false,ep11.CKA_SIGN:        true,ep11.CKA_EXTRACTABLE: false,}),}}\nThe resulting key pair can be used to create a new certificate. Although it is possible to create \na CA this way if that is required for the use case, it is recommended to not use a CA with a key in the clear like this. This method should rather be used to generate keys that are required to be in the clear.\nAfter this generation, the key is open in the clear and available for use as a TLS certificate \nwithin a reverse proxy or web server.\nIn our SamplePaymentSystem  example, we use the generated RSA key as a key for a \ncertificate.\n4.3.5  Reverse proxy\nTo adhere to the zero trust architecture, all communication between different services must be authenticated and encrypted.\nThe communication between the ", "metadata": {"source": "sg248555.pdf", "chunk_index": 251, "total_chunks": 337}}
{"text": "ation between different services must be authenticated and encrypted.\nThe communication between the reverse proxy and internal services might or might not be \nencrypted, based on security needs. Internal communication does not need to be encrypted.\nIn case any inter-service communication leaves a single pod,\n2 the communication should be \nauthenticated and encrypted because pods might be moved into other scopes.\nA reverse proxy within the pod can be used for various purposes, such as SSL/TLS \ntermination, caching, content serving, load balancing, and authentication.\nExisting proxies SSL certificates can be set up between the reverse proxy and backend or \nother services to check a JSON Web Token (JWT) authentication. See Example 4-31.\nExample 4-31   SSL certificate checks\ncontainers:  - name: frontend    image: docker.io/library/nginx@sha256:67f9a4f10d147a6e04629340e6493c9703300ca23a2f7f3aa56fe615d75d31ca    ports:      - containerPort: 80        hostPort: 80      - containerPort: 443  ", "metadata": {"source": "sg248555.pdf", "chunk_index": 252, "total_chunks": 337}}
{"text": "aa56fe615d75d31ca    ports:      - containerPort: 80        hostPort: 80      - containerPort: 443        hostPort: 443Note:  Note: For more examples on how to use the grep11 go library, see \nIBM-Cloud/hpcs-grep11-go/blob/master/examples/server_test.go .\n2  A pod encapsulates one or more applications or containers. \n\n84 Applying Data Protection and Confidentiality in a Hybrid Cloud Environment    volumeMounts:\n      - mountPath: /etc/nginx        name: contract-nginx        readOnly: true      - mountPath: /www        name: contract-www        readOnly: true\nThe nginx server can be configured. See Example 4-32.\nExample 4-32   nginx server configuration\nerror_log /dev/stderr info;\n events {}http {    access_log /dev/stdout;    server {        # reverse proxy with tls termination        listen 443 ssl;...        location ~ .ico {            # serve static content            root /www;        }        location / {            # serve dynamic content from backend            index index.html", "metadata": {"source": "sg248555.pdf", "chunk_index": 253, "total_chunks": 337}}
{"text": "   }        location / {            # serve dynamic content from backend            index index.html;            proxy_pass https://localhost:8443/;            proxy_ssl_trusted_certificate /etc/nginx/backend.crt;            proxy_ssl_session_reuse on;            proxy_ssl_verify on;        }    }}\nNo logs are written into the containers file system. Instead, all logs are written to stdout to be \nsurfaced on the container host. On the host, the logs are further integrated into the journal and forwarded to the configured remote log server.\nWhen possible, container volumes should be read-only to prevent any modification and \npotential compromise of other containers that use the same volume mounts for configuration.\n4.3.6  Basic web server (nginx) hardening\nThe use of a reverse proxy like nginx allows the protection of secondary services within or outside of the deployed pod. To maximize this protection, the configuration should be hardened to allow only the minimum required fo r the func", "metadata": {"source": "sg248555.pdf", "chunk_index": 254, "total_chunks": 337}}
{"text": "is protection, the configuration should be hardened to allow only the minimum required fo r the function of the services. This includes \nthe used protocols, encryption, timeouts, and enforcement of certain headers. See Example 4-33 on page 85.\nFor more information about nginx security configuration, see Security Controls .\nFor more information, see SSL/TLS Best Practices for 2023 .\n\nChapter 4. Application developme nt in a trusted environment 85Example 4-33   Reverse proxy \nhttp {\n...    server {        # reverse proxy with tls termination        listen 443 ssl;        ssl_certificate sample.test.crt;        ssl_certificate_key sample.test.key;        ssl_protocols TLSv1.2 TLSv1.3;        ssl_ciphers ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-CHACHA20-POLY1305:ECDHE-RSA-CHACHA20-POLY1305:DHE-RSA-AES128-GCM-SHA256:DHE-RSA-AES256-GCM-SHA384;        ssl_prefer_server_ciphers on;        ssl_session_cache s", "metadata": {"source": "sg248555.pdf", "chunk_index": 255, "total_chunks": 337}}
{"text": "CM-SHA256:DHE-RSA-AES256-GCM-SHA384;        ssl_prefer_server_ciphers on;        ssl_session_cache shared:SSL:50m;        ssl_session_tickets off;         # set default headers        add_header X-Frame-Options SAMEORIGIN;        add_header X-Content-Type-Options nosniff;        add_header X-XSS-Protection \"1; mode=block\";        add_header Content-Security-Policy \"default-src 'self'; script-src 'self' 'unsafe-inline' 'unsafe-eval' https://code.jquery.com/, img-src 'self'; style-src 'self' 'unsafe-inline'; font-src 'self'; object-src 'none'\";        add_header Strict-Transport-Security \"max-age=31536000; includeSubdomains; preload\";...\n4.3.7  Offloading NGINX TLS to HPCS\nWith the nginx server running as a reverse proxy within the application pod,  it is also possible \nto further offload the TLS handling completely to HPCS. For more information, see Use IBM \nCloud Hyper Protect Crypto Services to offload NGINX TLS.\n4.4  Trust in-depth based on boot flow attestation\nAfter successful depl", "metadata": {"source": "sg248555.pdf", "chunk_index": 256, "total_chunks": 337}}
{"text": "vices to offload NGINX TLS.\n4.4  Trust in-depth based on boot flow attestation\nAfter successful deployment of a service, the Workload Deployer should verify that the \nservice has been deployed as specified. This includes the running containers as specified within the contract as well as the underlying HPCR image.\nDuring deployment of the virtual server instance in the cloud, an attestation record is created. \nIt contains hashes of the following items:\n/SM590000The original base image\n/SM590000The root partition at the moment of the first boot\n/SM590000The root partition at build time\n/SM590000The cloud initialization options\nThe attestation record is signed by the attestation key.As an extra protection layer, you can provide a public key within the contract as \nattestationPublicKey (see Example 4-34 on page 86). When the public key is provided, the \n\n86 Applying Data Protection and Confidentiality in a Hybrid Cloud Environmentattestation record ( se-checksums.txt ) is encrypted and gen", "metadata": {"source": "sg248555.pdf", "chunk_index": 257, "total_chunks": 337}}
{"text": "dentiality in a Hybrid Cloud Environmentattestation record ( se-checksums.txt ) is encrypted and generated ( se-checksums.txt.enc ). \nOnly one of the files is present depending on if a public key was provided or not.\nExample 4-34   Public key provided with the attestation record\nenv: |...attestationPublicKey: |-  -----BEGIN PUBLIC KEY-----   MIICIjANBgkqhkiG9w0BAQEFAAOCAg8AMIICCgKCAgEA6v4drcQa2Rm6+Gdp3+xG   InhWhTG1TVN8kzCAZmZfwiYxc6RE0TVIUAqEwcXxo0lA4Qp8rGRpR5RFsdGVry95    yachZkW4utO/0d6BHDEG306hQVYMZYQmj8GX7IFHbGv/eqdvZJIWm0m3Oc+NLJRXpU9XdAY31J4tzxRQwyM1wsDt/3u7TWGi5P7cZMfjYeoP1CyWJujvCTWGNH855OcUBoF3833NcJSKpN3LOo/v71IMp3H4Frq5OJuek/QQIkhPN9muNlyUBaOujp5WDWaclHwwqd2dNRx6Z0X/X4nLI3OY8rrScFcU+TnZKHaVGQ2eFTMdGDLJehTUG0VOeuvb  +7OQRCg+VP2AyolsU53Q20Dr+AEr49qjdxN+8Pjw94AVdtC5dvTPmG08p9bB9IHx3ycMH2RxgkixsBMtZ+iu4vXOzw9zIynQhsUQoKE9prJtLI7O11+JfpMVaJtkYaUa  zb2wnsj740CwhucP8q2wtqyKbaz8xj8wXXRGNCvkERzYaOYzcRQb9t+IPb5iDD3Oeq7cA+uM5n3CXB7cpDluq1SPIpWmUztCbvcWmI0HPcpPlPa+98t3izAHpkl/90Td  qcZ", "metadata": {"source": "sg248555.pdf", "chunk_index": 258, "total_chunks": 337}}
{"text": "XRGNCvkERzYaOYzcRQb9t+IPb5iDD3Oeq7cA+uM5n3CXB7cpDluq1SPIpWmUztCbvcWmI0HPcpPlPa+98t3izAHpkl/90Td  qcZSox81iEMg4RUzxLVpVM7FR6+CN6nVSck0P/8mhf1A1dzoGeLN2UGRlTfpDmDU1cRQ95+mlxdGk7sSwZpvRA0CAwEAAQ==-----END PUBLIC KEY-----\nThe hash of this public key is added to the attestation record to ensure that the record can be \nviewed only by the compliance authority, and the expected authority can be easily identified \nthrough that hash.\nWithin the env volume section of the compose contract, add /var/hyperprotect . See \nExample 4-35.\nExample 4-35   Volume section\nvolumes:  - \"/var/hyperprotect/:/var/hyperprotect/:ro\"\nThe attestation record is signed by the attestation signing key, and the signature is a provided \nseparate file se-signature.bin .\nThe attestation signing key can be confirmed by the IBM intermediate certificate. The IBM \nintermediate certificate is si gned by DigiCert, which is proven by the root certificate of \nDigiCert, thus completing the chain of trust.\nThe encryption and attestati", "metadata": {"source": "sg248555.pdf", "chunk_index": 259, "total_chunks": 337}}
{"text": " the root certificate of \nDigiCert, thus completing the chain of trust.\nThe encryption and attestation certificates are signed by the IBM intermediate certificate and \nthis has been signed by the IBM Digicert intermediat e cert (which in turn is signed by DigiCert \nTrusted Root G4). For more information about the certificates, see DigiCert Trusted Root Authority Certificates.\nTo validate the attestation record and hashes, obtain the attestation record se-checksums.txt  \nand the signature file se-signature.bin  from your HPVS instance. To do so, you can \nimplement your container to provide the attestation record and the signature file. The attestation record and the signature file are made available to your container in the /var/hyperprotect  directory.\nSample node.js code snippet implementation to get attestation .zip files. See Example 4-36 \non page 87.\n\nChapter 4. Application developme nt in a trusted environment 87Example 4-36   Get attestation .zip files\napp.get('/api/v1/attestatio", "metadata": {"source": "sg248555.pdf", "chunk_index": 260, "total_chunks": 337}}
{"text": " nt in a trusted environment 87Example 4-36   Get attestation .zip files\napp.get('/api/v1/attestation', function(req, res) {\n    console.log('GET ' + req.path);    const fileName = 'attestation.zip';    const fileType = 'application/zip';    var zip = new admzip();    try {        zip.addLocalFile(\"/var/hyperprotect/se-checksums.txt.enc\");    }    catch (e) {        zip.addLocalFile(\"/var/hyperprotect/se-checksums.txt\");    }    zip.addLocalFile(\"/var/hyperprotect/se-signature.bin\");    var zipFileContents = zip.toBuffer();    res.writeHead(200, {        'Content-Disposition': `attachment; filename=\"${fileName}\"`,        'Content-Type': fileType,      })    res.end(zipFileContents);}); app.get('/api/v1/attestationdocument', function(req, res) {    console.log('GET ' + req.path);    res.type('txt').sendFile('/var/hyperprotect/se-checksums.txt');Y});\nFor the sample code that we used in our environment, see \nIBM/hyperprotec/redbook-samples/sg248555 .\nYou can decrypt the encrypted attestat", "metadata": {"source": "sg248555.pdf", "chunk_index": 261, "total_chunks": 337}}
{"text": " environment, see \nIBM/hyperprotec/redbook-samples/sg248555 .\nYou can decrypt the encrypted attestation by using the provided script For more information \nfor HPVS for VPC, see IBM Cloud: Decrypting the attestation document . For more information \nfor IBM LinuxONE or IBM Z, see IBM Hyper Protect Virtual Servers: Decrypting the \nattestation document .\n4.5  Data storage\nHPVS does not suppor t persistent st orage over reboot on the root  partition. Therefore, the \nroot volume is deployed in the same state on each boot of the HPVS. This means that all data must be stored on  user data volumes that are attached to the HPVS.\nTo provide effective data at rest protection, all encryption must happen within the trusted \nexecution environment (TEE) before any data blocks or objects are written back to external storage.\nThe two main storage classes are block storage and object storage.\n4.5.1  Encrypting block storage\nLinux Unified Key Setup (LUKS) is the standard for Linux volume encryption. It en", "metadata": {"source": "sg248555.pdf", "chunk_index": 262, "total_chunks": 337}}
{"text": "ting block storage\nLinux Unified Key Setup (LUKS) is the standard for Linux volume encryption. It enables \nsecure management of multiple user passwords. LUKS stores all necessary setup information in the partition header, which enables users to transport or migrate data seamlessly.\n\n88 Applying Data Protection and Confidentiality in a Hybrid Cloud EnvironmentThe user data volumes of a H PVS are encrypted using LUKS by default. To open and mount \na LUKS protected partition, a password is required. This password is derived from the password seeds that are supplied within the workload and env sections of the contract.\n4.5.2  Encryption state\nHPVS periodically logs the encryption state of  the attached block st orage devices to the \ninternal journal. Because the journal is forwarded to a remote log server, this output can be used to audit the encryption state of the data at rest.\nIn case the default cadence is not sufficient, the workload can request additional audit output \nby logging the", "metadata": {"source": "sg248555.pdf", "chunk_index": 263, "total_chunks": 337}}
{"text": " default cadence is not sufficient, the workload can request additional audit output \nby logging the special token HPL13000I . See Example 4-37.\nExample 4-37   Request additional audit output\nworkload: |\n...        containers:        - name: verify-disk-encryption-trigger          image: docker.io/library/ubuntu:22.04          command: echo\n    args:\n          - HPL13000I...\nLogging the token to stdout of any of the containers triggers the verify-disk-encryption \nservice, which adds information about the encryption state of the attached block devices to the log. See Example 4-38.\nExample 4-38   Verify disk (volume) encryption\nconmon[991]: HPL13000I...verify-disk-encryption: HPL13003I: Checked for mount point /, LUKS encryption with 1 key slot found\nverify-disk-encryption: HPL13001I: Boot volume and all the mounted data volumes \nare encrypted\nA complete example of the log is displayed in the Example C-2 on page 118.\nFor more information on disk (volume) encryption verification, see IBM ", "metadata": {"source": "sg248555.pdf", "chunk_index": 264, "total_chunks": 337}}
{"text": "the Example C-2 on page 118.\nFor more information on disk (volume) encryption verification, see IBM Cloud: Verifying disk \nencryption status .\nHPCS user data volume encryption\nAn HPVS instance can also be  configured to use an addit ional HPCS seed for the LUKS \npassword. Because this secret is tied to the HPCS instance, it can also be remotely controlled.\nWhen this option is used, the key state on the HPCS instance is monitored to lock the \npartition when the HPCS key is disabled or removed.\nThe service can be configured within the env par t of the contract, which allows the use of a \ndifferent HPCS instance in ea ch deployed HPVS instance and volume. See Example 4-39 on \npage 89.\n\nChapter 4. Application developme nt in a trusted environment 89Example 4-39   HPVS volume encryption\nenv: |\n  type: env  volumes:    payment-data-volume:      seed: \"secret-env-seed1\"      kms:        - apiKey: \"${var.ibmcloud_api_key}\"          crn: \"${var.hpcs_crn}\"          type: \"private\"      kmsTimeou", "metadata": {"source": "sg248555.pdf", "chunk_index": 265, "total_chunks": 337}}
{"text": "y: \"${var.ibmcloud_api_key}\"          crn: \"${var.hpcs_crn}\"          type: \"private\"      kmsTimeout: 10  signingKey: \"xxxxxxxxx\"...\nWhen it is possible, give precedence to the pr ivate API endpoint before the public endpoint. \nWhen configured this way, the communication does not need to leave the VPC network. If only the private API endpoints of the HPCS serv ice are used, it is po ssible to completely \ndisable the public API endpoint on the service. This further reduces the attack surface.\nThe additional protection by an HPCS secret can be added to an existing volume. To do so, \nthe workload and env seeds still mu st match to allow access to th e volume. This is reflected in \nthe HPVS log with an entry that is  similar to the following message:\nhpcr-disk-mount[699]: HPL07011I: Migration started from non-BYOK to BYOK for \nvolume [/dev/vdd]\nThe KMS connection can be changed to another KMS but cannot be removed as this is \nindistinguishable from a downgrade attack.\nIn case the data nee", "metadata": {"source": "sg248555.pdf", "chunk_index": 266, "total_chunks": 337}}
{"text": "MS but cannot be removed as this is \nindistinguishable from a downgrade attack.\nIn case the data needs to be exported, this must be done on the workload level.If the KMS connection is lost or the KMS key is  locked at any time, the HPVS restarts. After \nthe restart, the HPVS starts pollin g for an enabled key for a limited  time to re-o pen the volume \nand re-start the workload. This can be retried anyt ime by restarting the HPVS.\nThe required crn can be easily obtained by using the ibmcloud  CLI command as shown in \nExample 4-40.\nExample 4-40   Retrieve service instance\n$ ibmcloud resource service-instance \"sample-hpcs\"Retrieving service instance sample-hpcs in all resource groups under account XXX's Account as xxx@ibm.com...OK\nName:                  sample-hpcs\nID:                    crn:v1:bluemix:public:hs-crypto:us-south:a/xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx:xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx::GUID:                  xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxxLocation:              us-sout", "metadata": {"source": "sg248555.pdf", "chunk_index": 267, "total_chunks": 337}}
{"text": "xxxxxxxxx::GUID:                  xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxxLocation:              us-southService Name:          hs-cryptoService Plan Name:     standardResource Group Name:   xxxState:                 activeType:                  service_instanceSub Type:              kms\n\n90 Applying Data Protection and Confidentiality in a Hybrid Cloud EnvironmentLocked:                false\nCreated at:            2023-07-30T14:16:13ZCreated by:            IBMid-xxxxxxxxxxUpdated at:            2023-08-17T08:30:13ZLast Operation:        ...\nWhen you use Terraform to manage HPCS, the information can also be acquired from the \nTerraform state. See Example 4-41.\nExample 4-41   Manage Terraform information\n$ terraform show# ibm_hpcs.hpcs:resource \"ibm_hpcs\" \"hpcs\" {    created_at            = \"2023-07-30T14:16:13Z\"    created_by            = \"IBMid-xxxxxxxxxx\"    crn                   = \"crn:v1:bluemix:public:hs-crypto:us-south:a/xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx:xxxxxxxx-xxxx-xxxx-xxxx-xxxxxx", "metadata": {"source": "sg248555.pdf", "chunk_index": 268, "total_chunks": 337}}
{"text": ":bluemix:public:hs-crypto:us-south:a/xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx:xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx::\"...    extensions            = {        \"allowed_network\"         = \"public-and-private\"        \"endpoints.private\"       = \"https://api.private.us-south.hs-crypto.cloud.ibm.com:8080\"        \"endpoints.privateGrep11\" = \"https://ep11.private.us-south.hs-crypto.cloud.ibm.com:8080\"        \"endpoints.public\"        = \"https://api.us-south.hs-crypto.cloud.ibm.com:8080\"        \"endpoints.publicGrep11\"  = \"https://ep11.us-south.hs-crypto.cloud.ibm.com:8080\"    }...    id                    =\"crn:v1:bluemix:public:hs-crypto:us-south:a/xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx:xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx::\"\n    location              = \"us-south\"\n    name                  = \"redbook-sample\"    plan                  = \"standard\"    service               = \"hs-crypto\"    service_endpoints     = \"public-and-private\"    state                 = \"active\"    status                = \"active\"    u", "metadata": {"source": "sg248555.pdf", "chunk_index": 269, "total_chunks": 337}}
{"text": " = \"public-and-private\"    state                 = \"active\"    status                = \"active\"    update_at             = \"2023-08-17T08:30:13Z\"...}\nThe results of the output is the crn of the service: \n\"crn:v1:bluemix:public:hs-crypto:us-south:a/xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx:xxxxx\nxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx:: \". \nTo secure a disk (volume) with this, the key id must be specified in the end of the crn. The \noutput is similar to the following example: \"crn:v1:bluemix:public:hs-crypto:us-south:a/xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx:xxxxx\nxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx:key:xxxxxxxx-xxxx-xxxx-xxxxxxxxxxxxxxxxx \".\n\nChapter 4. Application developme nt in a trusted environment 914.5.3  Upgrade, backup, and disaster recovery\nAlthough all volumes can be ba cked up by taking a snapshot, th is is not necessary for HPVS \nroot volumes. Because the root volume is cleanly prepared on  each boot, it will always be in \ngood shape after a reboot.\nAll valuable application data must be stored on data", "metadata": {"source": "sg248555.pdf", "chunk_index": 270, "total_chunks": 337}}
{"text": "t will always be in \ngood shape after a reboot.\nAll valuable application data must be stored on data volumes. The data volumes can be \nsnapshot. Snapshots can be restored into new data volumes that can be attached to the same or another HPVS instance. When attempting this, the following criteria must be met:\n/SM590000The workload volume seed within the contract must be the same\n/SM590000The env volume seed within the contract must be the same\n/SM590000The HPCS instance attached to the data volume must provide the same key\nIt is possible to change the workload containe rs and the provided environment data between \nsnapshot and restore. This means, if it is needed, that it is possible to move data volumes to another region and update the workload in one step.\nFor details about snapshots of data volumes, refer to the following documentation: \n/SM590000For creating snapshots, see Creating snapshots .\n/SM590000For restoring a volume, see Restoring a volume from a snapshot .\n/SM590000For man", "metadata": {"source": "sg248555.pdf", "chunk_index": 271, "total_chunks": 337}}
{"text": "apshots .\n/SM590000For restoring a volume, see Restoring a volume from a snapshot .\n/SM590000For managing a snapshot, see Managing snapshots.\nWhen creating snapshots while an HPVS is running, it is possible that the snapshot does \ncontain inconsistent data that cannot be read by the application. Therefore, it is recommended that the HPVS is re booted or restar ted before a snapshot  is requested. The \nreboot or restart flushes all data from memory to disks (volumes). Alternatively, the workload \ncontainers might provide modes that allow for safe  snapshots. This is highly dependent on the \nworkload and cannot be controlled by the IBM infrastructure or container runtime image.\n4.5.4  High Availability\nHPVS does not provide any servic es in support of a high ava ilability (HA) environment. The \ncontainers run as defined within the contract. The Workload Deployer persona of the application is responsible for providing enough instances and a configuration for the overall service to perform", "metadata": {"source": "sg248555.pdf", "chunk_index": 272, "total_chunks": 337}}
{"text": "is responsible for providing enough instances and a configuration for the overall service to perform properly. Note:  Create a separate API key to provide within the contract instead of using the same \nAPI key within the contract and to deploy the contract. Using different keys does provide the benefit that the key can be restricted and follow its own lifecycle.\n\n92 Applying Data Protection and Confidentiality in a Hybrid Cloud EnvironmentFor more dynamic applications, including sca ling and workload migration, Kubernetes3 is the \nindustry standard. \nDeployment of pods that are protected by Secure Execution for Linux is allowed within the \nCloud Native Community: Confidential Container Project. For more information, see confidential-containers .\n4.6  Securing cloud native services\nKubernetes is an open source container orchestr ation platform that is extensively used in the \nindustry for managing, scaling, and automating cloud native services.\nKubernetes has four key underlying infrast", "metadata": {"source": "sg248555.pdf", "chunk_index": 273, "total_chunks": 337}}
{"text": " managing, scaling, and automating cloud native services.\nKubernetes has four key underlying infrastructure layers to protect, which include the public, \nprivate, or hybrid cloud infrastructure, clus ters, containers, and code. From a security \nperspective, each layer relies on the next layer. For example, the code layer benefits from strong security at the public, private or hybrid  cloud infrastructure, cluster, and container \nlayers. You cannot safeguard against poor security standards at the other layers by addressing security at only the code layer. \nDepending on the attack surface of the service, focusing on specific aspects of security is \nimportant. For instance, if  a critical service, \nService A , is in a chain of other resources with a \nseparate service, Service B , which is exposed to a resource exhaustion or vulnerable API \nattack, then the risk of comp romising Service A is high. \nIf services are run in the same cluster with a shared set of resources and common base \nwher", "metadata": {"source": "sg248555.pdf", "chunk_index": 274, "total_chunks": 337}}
{"text": " high. \nIf services are run in the same cluster with a shared set of resources and common base \nwhere a privilege escalation can be achieved through one service (Service B), then potentially, Service B can be used to attack or exploit Service \nThere are three areas of concern for securing Kubernetes: \n1. Cluster components like kubelet\n4 that are configurable \n2. Applications that run in the cluster 3. Appropriate level of protection for APIs \n4.6.1  Confidential cluster\nWith the ability to protect virtua l machines through conf idential computing, it is also possible \nto create confidential clusters. For more information, see Red Hat OpenShift Container \nPlatform for IBM Z and LinuxONE 4.13 . Virtual machines, by using confidential computing, \nprotect the control plane and worker or compute nodes from the underlaying infrastructure. Although such clusters addre ss several attack vectors, one ke y aspect to consider is the \nprotection boundary. Kubernetes requires multiple APIs to oper", "metadata": {"source": "sg248555.pdf", "chunk_index": 275, "total_chunks": 337}}
{"text": ", one ke y aspect to consider is the \nprotection boundary. Kubernetes requires multiple APIs to operate a cluster, and with possible vulnerability of those APIs, the cluste r might be infiltrated.  At that point, a \ncyberattacker is within the protection boundary with administrator privileges at the control node. Therefore, the compute nodes and workloads that are running within the cluster are considered compromised.\nA secondary aspect to consider is that clusters  are managed more and more by other parties. \nThis can be either by cloud providers offeri ng managed Kubernetes clusters or by a service \npartner managing a cluster in a data center. Either way, confidential clusters need to protect a \n3  If a pod (or the node it runs on) should fail, Kubernetes can automatically cr eate a new replica of that pod to \ncontinue operations\n4   Kubelet is an agent that runs on each node in a cluster to ensure the container or containers are running in a pod.\n\nChapter 4. Application developme nt", "metadata": {"source": "sg248555.pdf", "chunk_index": 276, "total_chunks": 337}}
{"text": "ter to ensure the container or containers are running in a pod.\n\nChapter 4. Application developme nt in a trusted environment 93larger attack surface and must rely on network-level segmentation for security to protect \nagainst lateral movement5 if one part of the cluster is compromised.\nTherefore, a more enhanced security approach th at uses confidential containers is needed, \nparticularly when considering the principles of zero trust. \n4.6.2  Confidential containers\nConfidential containers is an open source community working to enable cloud-native \nconfidential computing by using TEE to protect containers and data. The community has the following goals:\n/SM590000Allow cloud-native application owners to enforce application security requirements\n/SM590000Transparent deployment of unmodified containers\n/SM590000Support for multiple TEE and hardware platforms\n/SM590000Create a trust model that separates Cloud Service Providers (CSPs) from guest \napplications\nThanks to the confidential con", "metadata": {"source": "sg248555.pdf", "chunk_index": 277, "total_chunks": 337}}
{"text": "hat separates Cloud Service Providers (CSPs) from guest \napplications\nThanks to the confidential containers comm unity, there is now an operator to deploy \nconfidential containers runtime and required configurations on a Kubernetes cluster. The confidential containers operator provides a means to deploy and manage confidential containers runtime on Kubernetes clusters. The primary resource describes runtime details such as installation type, source, and nodes to deploy. \nConfidential containers work by embedding a Kubernetes pod inside a virtual machine (VM) \ntogether with an engine called the enclave software stack. There is a one-to-one mapping between a Kubernetes pod and a VM-based TEE or enclave. The container images are kept inside the enclave and can be either signed or encrypted. \nThe enclave software stack is measured, which means that a trusted cryptographic algorithm \nis used to authenticate its content. It contains  the enclave agent, which is responsible for \ninitiating at", "metadata": {"source": "sg248555.pdf", "chunk_index": 278, "total_chunks": 337}}
{"text": "to authenticate its content. It contains  the enclave agent, which is responsible for \ninitiating attestation and for fetching the secrets from the key management service. \nThe supporting components for the solution are the container image registry and the relying \nparty, which combines the attestation service and key management service. \nAfter the VM has been started, the flow can be summarized in the following four steps: \n1. A request is sent to the attestation service through the enclave agent. In response to this, \nthe attestation service sends a cryptographic challenge for the agent to prove the workload's identity using the measurement of the enclave. If the enclave agent effectively \nsolves this challenge, the a ttestation service informs the key management service that it \ncan proceed with delivering the secrets. \n2. After the workload's authorization to r un is confirmed, the key management service \nlocates the secrets that are associated with the workload and sends them to t", "metadata": {"source": "sg248555.pdf", "chunk_index": 279, "total_chunks": 337}}
{"text": "ey management service \nlocates the secrets that are associated with the workload and sends them to the agent. Decryption keys are among the necessary  secrets for the vo lumes to be used. \n3. The image management service inside the enclave downloads container images from the \ncontainer images registry, verifies them, and decrypts them locally to encrypted storage. At that point, the container images become usable by the enclave. \n4. The enclave software stack creates a pod and containers inside the virtual machine and \nstarts running the containers. All containers within the pod are secured. \n5  Techniques used by cyberattackers to  move deeper into a network after gaining access to obtain increased \nprivileges.\n\n94 Applying Data Protection and Confidentiality in a Hybrid Cloud EnvironmentConfidential containers go beyond prior efforts of isolating the container from only the \ninfrastructure administrator, by also is olating the containers from the Kubernetes \nadministrator. The tenant", "metadata": {"source": "sg248555.pdf", "chunk_index": 280, "total_chunks": 337}}
{"text": "ture administrator, by also is olating the containers from the Kubernetes \nadministrator. The tenant can fully use the abstraction of a managed Kubernetes to develop-once-deploy-anywhere. The tenant can deploy data and workloads with technical assurance into a fully private and isolated enclav e even if the latter is hosted and managed on \nthird-party infrastructure. \nMoreover, confidential containers reduce the set of components that interact with protected \nworkload and data so that most components within the Kubernetes cluster can operate unchanged to address the risk of compromising data. This approach fosters speed of innovation and prioritizes data protection. \nAnother key component to consider in a Kubernetes based environment is the kubelet. Not \nonly in cloud environments, this component can be delivered and managed by a 3rd party.\nThe advantage of confidential containers is that  if a service exploitation leads to a privilege \nescalation to attack, vulnerable kubelet or APIs ", "metadata": {"source": "sg248555.pdf", "chunk_index": 281, "total_chunks": 337}}
{"text": "t  if a service exploitation leads to a privilege \nescalation to attack, vulnerable kubelet or APIs at the cluster level are addressed. See Figure 4-3. \nFigure 4-3   Confidential clusters  versus confidential containers\nData and operation protection is enforced at the pod runtime level. This zero trust model \nbolsters security by strictly validating and authorizing the communication and access requests, enhancing the overall security posture of containerized environments. \n4.6.3  Confidential service platform\nFor data security based on technical assurance through zero trust policy, enforcement is \nessential to have the security within the moment of deployment. This fosters workloads confidentiality with deployment, and 3rd-party attestation can be done for validation. Hence, data and workload can be protected from the very start, based on technical measures rather than trust in a third-party service.\nSecure Execution offers the ability to have secrets being in jected as part of the enc", "metadata": {"source": "sg248555.pdf", "chunk_index": 282, "total_chunks": 337}}
{"text": "arty service.\nSecure Execution offers the ability to have secrets being in jected as part of the encrypted \nimage. Such secrets can be used for zero knowledge proofs andto decrypt artifacts within the TEE. \nThe notion of user-controlled policy enforcement at deployment for confidential containers \ncan be combined with Hyper Protect encrypted contracts. Therefore, the protection of data with technical assurance throughout all stages of the data lifecycle ensures data sovereignty where the complete control over the actual data lies with the cloud user and not the cloud provider.\nThis concept can be expanded to build a confiden tial service platform in which key aspects, \nlike identify and access management (IAM), key management, attestation of workloads, policy enforcement and audit/logging records are deployed. They are deployed by using \nconfidential containers and other workloads built on a container platform that inherits the premier zero trust value proposition. For this, the confid", "metadata": {"source": "sg248555.pdf", "chunk_index": 283, "total_chunks": 337}}
{"text": "on a container platform that inherits the premier zero trust value proposition. For this, the confidential container projects need to \n\n\nChapter 4. Application developme nt in a trusted environment 95further mature. Not only regulation needs to be defined, but also corresponding certification \nneeds to be established by the industry and acknowledged by the regulatory parties.\n4.7  Secure supply chain with SLSA\nSupply chain levels for software artifacts (SLSA) is a security framework. It is a checklist of standards and controls that prevent tampering, improve integrity, and secure both packages and infrastructure. By using this framework, you can ensure that every link in the chain is as \nresilient as possible, as illustrated in Figure 4-4. \nFigure 4-4   Secure supply chain - high-level overview\nIndustry consensus established SLSA as a set of guidelines for supply chain security that can \nbe adopted incrementally. SLSA specifications are useful for consumers and producers of software. C", "metadata": {"source": "sg248555.pdf", "chunk_index": 284, "total_chunks": 337}}
{"text": "\nbe adopted incrementally. SLSA specifications are useful for consumers and producers of software. Consumers can use the SLSA framework to decide whether to trust a software package or not. Producers can adhere to the SLSA guidelines to add security to their supply chain.\nSLSA provides the following benefits:\n/SM590000A standardized terminology for discuss ing software supp ly chain security\n/SM590000A method to enhance the security of your  incoming supply chain by assessing the \nreliability of the artifacts you use\n/SM590000A practical checklist to enhance the security of your own software\n/SM590000A method to track your progress toward complying with the Executive Order  standards in \nthe Secure Software Development Framework (SSDF)\nSLSA is designed to automate tracking of code handling, spanning from source to binary, by \nsafeguarding against tampering, regardless of the complexity of the software supply chain. This approach can provide greater confidence t hat the analysis and rev", "metadata": {"source": "sg248555.pdf", "chunk_index": 285, "total_chunks": 337}}
{"text": "f the software supply chain. This approach can provide greater confidence t hat the analysis and review conducted on the \nsource code remains valid for the binary that is consumed after the build and distribution process. \nSLSA protects against the following possible security  vulnerabilities:\n/SM590000Modification of code by providing a \u201cseal\u201d to code after source control to ensure it is not \nmodified.\n/SM590000Artifacts that have been uploaded but were not built using the anticipated CI/CD platform. \nArtifacts are \u201cstamped\u201d with their build platform when created.\n/SM590000Build platform threats.\n\n\n96 Applying Data Protection and Confidentiality in a Hybrid Cloud EnvironmentSLSA is only one part of a complete approach to supply chain security. Because of this, there \nare several areas that sit outsid e of SLSA's current framework th at still need to be considered \nalong with SLSA. Areas outside of SLSA\u2019s current framework include the following examples:\n/SM590000Quality of code. SLSA ", "metadata": {"source": "sg248555.pdf", "chunk_index": 286, "total_chunks": 337}}
{"text": " outside of SLSA\u2019s current framework include the following examples:\n/SM590000Quality of code. SLSA cannot determine if the source code that was written follo ws secure \ncoding practices.\n/SM590000Producer trust. SLSA's Build Track protects from tampering after or during the build. \nHowever, it cannot address organizations that purposefully create malicious software.\n/SM590000Transitive trust for dependencies. An artifact\u2019s SLSA level does not depend on the level of \nits dependencies. At the time of writing, there is no SLSA level that can refer to both an artifact and its transitive dependencies.\n4.7.1  Jenkins\nJenkins is an open source web server that is built for automation, and allows developers to build, test and deploy their software. This ensures that developers are able to implement continuous integration and continuous delivery (CI/CD). Jenkins interact s with various servers \nand components, meaning security is a crucial consideration. Because of the way Jenkins plug-ins and ", "metadata": {"source": "sg248555.pdf", "chunk_index": 287, "total_chunks": 337}}
{"text": "nd components, meaning security is a crucial consideration. Because of the way Jenkins plug-ins and their dependencies function, provid ing a basic authentication mechanism is not \nsufficient to fully secure the complete pipeline.  There are multiple options for configuration \nwithin Jenkins settings to enable, customize, or disable various security features.\nThe Jenkins Security Advisory process is wh ere Jenkins will constantly review and update \nplug-in vulnerabilities. The Security  Advisory is a list of vulnerab ilities and security issues that \nare identified and highlighted in a report within Jenkins. The report includes a description of the vulnerability, security risks posed, severities, versions it  affects, workarounds, and any \npossible solutions.\nThe eight key forms of security for Jenkins fall under three categories:\n1. Basic setup:\n\u2013 Controller Isolation\u2013 Access Control\n2. Build Behavior:\n\u2013 Access control for builds\u2013 Securing builds\u2013 Handling environment variables\n3. Use", "metadata": {"source": "sg248555.pdf", "chunk_index": 288, "total_chunks": 337}}
{"text": " Build Behavior:\n\u2013 Access control for builds\u2013 Securing builds\u2013 Handling environment variables\n3. User Interface:\n\u2013 Cross-Site Request Forgery (CSRF) Protection\u2013 Markup formatter\u2013 Rendering user content\n4.7.2  Source-to-image (S2I)\nThe Source-to-image (S2I) framework makes it easier to write images that take application source code as an input and output a new image that runs the assembled application as output.\nUsing S2I for constructing consis tent container images offers a primary benefit in terms of \ndeveloper convenience. Build image authors need to understand two key concepts to get the best performance out of S2I - The build process and S2I scripts.\nS2I creates images that are ready-to-run by injecting the source code into a specific container \nthat prepares it for execution.\n\nChapter 4. Application developme nt in a trusted environment 97S2I can be used to control what permissions and  privileges are available to the builder image \nbecause the build is launched in a single co nt", "metadata": {"source": "sg248555.pdf", "chunk_index": 289, "total_chunks": 337}}
{"text": " and  privileges are available to the builder image \nbecause the build is launched in a single co ntainer. In parallel with platforms like Red Hat \nOpenShift, S2I can enable admins to tightly control what privileges developers have at build time.\n4.7.3  GitHub Actions\nGitHub Actions is a continuous integration an d continuous delivery (CI/CD) platform that \nallows developers to automate their build, test, and deployment pipeline. Workflows are created that build and test every pull request to the repository or deploy merged pull requests to production.\nGitHub Actions can be configured into a workfl ow to be triggered when an event occurs in a \nrepository, such as a pull request being opened, or an issue being created. The workflow contains one or more jobs, which can run in sequential order or in parallel. Each job runs inside its own virtual machine runner, or inside a container. Each job has one or more steps that either run a script that you define or run an action, which is a reusa", "metadata": {"source": "sg248555.pdf", "chunk_index": 290, "total_chunks": 337}}
{"text": "ob has one or more steps that either run a script that you define or run an action, which is a reusable extension that can \nsimplify the workflow.\nA workflow is a configurable automated process that can run multiple jobs. Workflows are \ndefined by a YAML file that is checked in to  a repository and will run when triggered by an \nevent, manual intervention, or at a defined schedule.\nStore sensitive values as secrets and never as plain text in workflow files. Secrets can be \nconfigured at the organization, repository, or environment level, and can allow storage of sensitive information in GitHub.\nSecrets use Libsodium sealed boxes  so that they are encrypted before reaching GitHub. This \noccurs when the secret is submitted by using the UI or through the REST API. This client-side encryption helps minimize the risks that are related to accidental logging such as exception logs and request logs, within GitHub's infrastructu re. After the secret is uploaded, GitHub can \nthen decrypt it, so ", "metadata": {"source": "sg248555.pdf", "chunk_index": 291, "total_chunks": 337}}
{"text": "ogs, within GitHub's infrastructu re. After the secret is uploaded, GitHub can \nthen decrypt it, so that it can be injected into the workflow runtime.\nThere are certain proactive steps and good practices to follow to help ensure that secrets are \nredacted and to limit other risks associated with secrets:\n/SM590000Never use structured data as a secret.\n/SM590000Register all secrets used within workflows.\n/SM590000Audit how secrets are handled.\n/SM590000Use credentials that are minimally scoped.\n/SM590000Audit and rotate registered secrets.\n/SM590000Consider requiring review  for access to secrets.\n\n98 Applying Data Protection and Confidentiality in a Hybrid Cloud Environment\n\n\u00a9 Copyright IBM Corp. 2024. 99Appendix A. Client contract setup sample \nfiles \nThis appendix contains the followi ng sample files from snippets shown in \u201cClient  setup steps\u201d \non page 60.\n/SM590000\u201cSample YAML file with literal scalars\u201d on page 100\n/SM590000\u201cSample YAML file with double-quoted scalars\u201d on page 101\n", "metadata": {"source": "sg248555.pdf", "chunk_index": 292, "total_chunks": 337}}
{"text": "ith literal scalars\u201d on page 100\n/SM590000\u201cSample YAML file with double-quoted scalars\u201d on page 101\n/SM590000\u201cSample script for certificate or key files\u201d on page 103A\n\n100 Applying Data Protection and Confident iality in a Hybrid Cloud EnvironmentSample YAML file with literal scalars\nSee Example A-1 for a complete example of YAML file with literal (|) scalars. \nExample A-1   YAML file with literal (|) scalars\nenv: |\ntype: env\n   logging:      syslog:         hostname: ${HOSTIP} # eg 10.0.0.8 or ${HOSTNAME}         port: 6514         server: |            -----BEGIN CERTIFICATE-----            MIIEuDCCAyCgAwIBAgIUBR9g6L5hivov7eNT00HSXW39oD0wDQYJKoZIhvcNAQEL            BQAwXzELMAkGA1UEBhMCVVMxEzARBgNVBAgMCkNhbGlmb3JuaWExFDASBgNVBAcM            C0xvcyBBbmdlbGVzMQwwCgYDVQQKDANJQk0xFzAVBgNVBAMMDmNhLmV4YW1wbGUu            b3JnMB4XDTIzMDEyNzE4MzkzMFoXDTI1MDExNjE4MzkzMFowXzELMAkGA1UEBhMC            VVMxEzARBgNVBAgMCkNhbGlmb3JuaWExFDASBgNVBAcMC0xvcyBBbmdlbGVzMQww            CgYDVQQKDANJQk0xFzAVB", "metadata": {"source": "sg248555.pdf", "chunk_index": 293, "total_chunks": 337}}
{"text": "   VVMxEzARBgNVBAgMCkNhbGlmb3JuaWExFDASBgNVBAcMC0xvcyBBbmdlbGVzMQww            CgYDVQQKDANJQk0xFzAVBgNVBAMMDmNhLmV4YW1wbGUub3JnMIIBojANBgkqhkiG            9w0BAQEFAAOCAY8AMIIBigKCAYEAsgnjL9ZxtdlQf1IAwEWkcPXQEHA47LY03BO7            c5jai9vRSGxa16hj6SUOidzKj4lK7w9REhxnaihkk1P8zfF9Eld/FvMKANpdaniO            JUFT/FXzlwG1c+R+h3ZTv4LiEi9SzWwkbNBOhMN5YM7nCOWNxQBHptisNvdRqb6V            idQfneU0aesmmu61IDeB54wpsZXiRXB7M2fpx3c/9ppFYSCGWpC0Bibu12r6kg85            EykR4zjEQiVg4U9m4zchQE73Ljl+pDHaGuJlMlfKgPKwAdmPEGK8IBctb3WbuBff            ojmgRerlAEajDlDD0IQE4s+dX/F+bZCZiJrfpHz8CAs6i/GPqVR1U2jP7zaAJqgs            KNfWm0CXcLDsdbxgGNU8ECzVKw9pWPcG4A4bxiznZpgWXwoBHmnbqriZe1KEAjRM            fGCGJI3xyODCsT/64zGIwX1ajpn9b6cWnAGoXrjOc5HSXnPGyiRDc/7jmmSXcOKd            Cd3SaQu/ahNHXjr5X1dQ7XrzgY/1AgMBAAGjbDBqMA4GA1UdDwEB/wQEAwIChDAP            BgNVHRMBAf8EBTADAQH/MEcGA1UdEQRAMD6CEnNlcnZlci5leGFtcGxlLm9yZ4IX            c2VydmVyLmV4YW1wbGUub3JnOjY1MTSCCTkuMjAuNy45MocECRQHXDANBgkqhkiG            9w0BAQsFA", "metadata": {"source": "sg248555.pdf", "chunk_index": 294, "total_chunks": 337}}
{"text": "4IX            c2VydmVyLmV4YW1wbGUub3JnOjY1MTSCCTkuMjAuNy45MocECRQHXDANBgkqhkiG            9w0BAQsFAAOCAYEAfLdjI2j0XbVqbZcQNBIPbyL1fhsNX0I0NvPRU9tpA1M41+Ur            dCFNQKivai7jKsATzDZZVG0Adprki7YFqUocZ/NpwC6GHFETrTCICaVrjUuF2ecg            iwXLZIiHWV+qOAbycG9VoUw7eRVKarfbmd31YwZ1il27e44V1mjVd4gdJvV6a4H6            5lm3fobogin9535lnJuZjHQNQ7cbN1hrKOkNrvZpSfe5lZ6EFUZHk3S/Wdux31rz\n            1cQQAhpFfJL84KDvM/cBISKGDutgAADCb9jtH8q+ow19n7R1ff10r4/9G7CA9mv6\n            llJf8+P8Y22CGDvez3YPs3Dt7AnZe7bEEpQg1EDlgVq+WzbyEcmmaVwJcj5o7ann            ifkUIrmJOiACtDlklQXYIiZcyg8zfLIcFYkf+PHpvtYF8c5Av4DS2YFPwtc5OoLz            xUOI54V6pJZBc60aL9vNyxBAKj/cQEQKrLtUGr1vjPTOFycNW5yQAAhDL6o6E+3S            uTEClFsd2QMaCJuQ            -----END CERTIFICATE-----         cert: |            -----BEGIN CERTIFICATE-----            MIID0zCCAjsCFFS5goaaDyhsJsUHv5WooqDg9gqGMA0GCSqGSIb3DQEBCwUAMF8x            CzAJBgNVBAYTAlVTMRMwEQYDVQQIDApDYWxpZm9ybmlhMRQwEgYDVQQHDAtMb3Mg            QW5nZWxlczEMMAoGA1UECgwDSUJ", "metadata": {"source": "sg248555.pdf", "chunk_index": 295, "total_chunks": 337}}
{"text": "JBgNVBAYTAlVTMRMwEQYDVQQIDApDYWxpZm9ybmlhMRQwEgYDVQQHDAtMb3Mg            QW5nZWxlczEMMAoGA1UECgwDSUJNMRcwFQYDVQQDDA5jYS5leGFtcGxlLm9yZzAe            Fw0yMzAxMzAxNjIzMDFaFw0yNTAxMjkxNjIzMDFaMG0xCzAJBgNVBAYTAlVTMQsw            CQYDVQQIDAJDQTEUMBIGA1UEBwwLTG9zIEFuZ2VsZXMxDDAKBgNVBAoMA0lCTTEQ            MA4GA1UECwwHU3lzdGVtczEbMBkGA1UEAwwSY2xpZW50LmV4YW1wbGUuY29tMIIB            IjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAvQoaZ9z2ZU0sKCoJ+lTyzI7v            N3Mhc2QOsSYBWxrQIFUt4WW1pinXXOqlo4iPRnQsQPzhkN8blZrgI2SFk1N8IdK8            JHFcO9yVWEKmnxNeIOgiOvjrk3nSTkDH7GZyZe0p0d+Dbk671P4cKoxi32JgSK2i            FelZnYrgELiZFWbIZfKuy4YzWF0BSIPN2GZfp2IFmjzAyDpasc5ucL4ulI8jqBVd            FXzpygkBnadWNrmD57LyVgUK+aez0+JXkSOBL9XiiDjIDvSNFuSzUdZqHBBJsdNI            I2AF+e1a6JRgisK0AOU5m6Jfemnu6e+oHToY07vEUiRtueWg99Y1C0+zdnsdgwID\n\nAppendix A. Client contract setup sample files 101            AQABMA0GCSqGSIb3DQEBCwUAA4IBgQBN8StXpYafIHj6E7Knlq30kn5OIUriZSez\n            /XUm1wibmqVV/oh5YSQhMYrhJZIyX6onRl1sj2", "metadata": {"source": "sg248555.pdf", "chunk_index": 296, "total_chunks": 337}}
{"text": "3DQEBCwUAA4IBgQBN8StXpYafIHj6E7Knlq30kn5OIUriZSez\n            /XUm1wibmqVV/oh5YSQhMYrhJZIyX6onRl1sj2BHxQ7HDnZpChwo8RvYvTQE6EF2            uhAQxAd0V+pQ7U/oMTF5JzFK8YnhXWsTqJ11SI/FR5A1dLWne9B6y8FcBzEnATHV            Ly8aJJCsI7zFWwzfQZn7WL1SKDkY8f7sZaWJAfch9auoqQH+AVvoQCK7sT26dzpI            hskWkj0cwrSgmtU2XSERsO9mPCyvBCFeXO8Ig13XSyKblh4qb++zeUsS8xb4EN27            hL/YOoBH3nVcpWW5EhVU5RJfbStrp1kGT7a6CRl4LyVSDNzPX0zEtUT958fdoXNV            rkPh/xre3lCxV8pTC7BGG81kCMfDqHdKKwcp8HJpJfXc/aQ220vh2JevXNSFQtIP            2idwz4A+jn+FEVWXAKB6jOS4XBoEdNh/8nSBiJLJ6bI0c4Rz2KLprKNZ4y43toI4            +nQ1PgTmc+x6hmiSZJuV0OnGVEDGxA0=            -----END CERTIFICATE-----         key: |            -----BEGIN RSA PRIVATE KEY-----            MIIEogIBAAKCAQEAvQoaZ9z2ZU0sKCoJ+lTyzI7vN3Mhc2QOsSYBWxrQIFUt4WW1            pinXXOqlo4iPRnQsQPzhkN8blZrgI2SFk1N8IdK8JHFcO9yVWEKmnxNeIOgiOvjr            k3nSTkDH7GZyZe0p0d+Dbk671P4cKoxi32JgSK2iFelZnYrgELiZFWbIZfKuy4Yz            WF0BSIPN2GZfp2IFmjzAyDpasc5ucL4ulI8jqBV", "metadata": {"source": "sg248555.pdf", "chunk_index": 297, "total_chunks": 337}}
{"text": "p0d+Dbk671P4cKoxi32JgSK2iFelZnYrgELiZFWbIZfKuy4Yz            WF0BSIPN2GZfp2IFmjzAyDpasc5ucL4ulI8jqBVdFXzpygkBnadWNrmD57LyVgUK            +aez0+JXkSOBL9XiiDjIDvSNFuSzUdZqHBBJsdNII2AF+e1a6JRgisK0AOU5m6Jf            emnu6e+oHToY07vEUiRtueWg99Y1C0+zdnsdgwIDAQABAoIBAGUllL9iEUxeoHPV            GoWhElC1YfWvWoSdUuciSLNwg0/pg6UIgMsptBv5SStZFCBEZLFZHXAgkGfZ+He3            f2k20EJguV5ecVVuT1JsRy7yc/jze+1F5vZ/xjEspEwu/KLg5PFwwKgy5HmwhW2W            tAiGYLJChWln9BVBi2Ym/3HeDvfMmBSv4JkgVwZvjlQddlpP2ljMiZdKjblvdU45            6QUYsv0kz2WyQPOlb23B5Yy5cUmRwutYacFgqkPbTmdjbpAAwr1nYi8uIVqYn47h            72dwV9RfiqKUGKb05UmfwonQYwHecpqFIG4jlkKGjY5MeIcecgYYaq9WpoCUgk5h            Ba0fT+ECgYEA67Oo5rdlE4kGV6b4XvtIyWAsKGD5Ofavyxj9VjCSeLb10UC4vUp3            kTu42EJ1UVGN8TYKpz3sAqkT+tVTrC663KLD3bdRWf0fP6BkvHTshWP03nnWwjTN            RNjAroojjDKfSLI/Qn2BPAQm2QsJFRa5ZYMl7WMAjuZu+VOz1z+uphsCgYEAzVG2            zTZ5668AU0FU7eHjJfDdBYhiEzIjgme3zFKg3tINvlyStyLKURkxtKUmliw8Tdhk            4as3YUu0ky0Dz+XopN8IBhwBKwG", "metadata": {"source": "sg248555.pdf", "chunk_index": 298, "total_chunks": 337}}
{"text": "5668AU0FU7eHjJfDdBYhiEzIjgme3zFKg3tINvlyStyLKURkxtKUmliw8Tdhk            4as3YUu0ky0Dz+XopN8IBhwBKwGizXMHP9BYfxrIy7yOVj9Lp2WSORvjwoB7nGxJ            lWwyrer2O2tNKMx6sGynJvfgSFh9AvTddldwfLkCgYAtDnsLH6PCyD7eIpz4CzEu            zaOjVGZQHkgcmvpSr5ZQXSlAhw7JoKKasL/1Fz81/FEV+y6uKbgkCg43tO/5yjUO            WE7440I54ZlHoHGhVPihxynYHZJgLZfPwV+T/fQtqL+qNejB3RwHTQPgGavyzBVE            wn1Nk89XgdVU9Bs82n+YYQKBgBuwN1y5SfvUn9CacN+bpMxLDSNf3woDqvI9FnZB            dlxWK3BOf6Ke2HXTVfashuWdlYxR8FjWhCNk2Dc4zNjOgm8pfKWGRUoNcG0QZBvg            9u49KHMBPJi49HTgp7V342EpfoH7wHicHMGDfC1LLR6hZLJCFNCWgPKArGsnpm39            ILhRAoGARwIM8o27pBymXcoyQDSqDgobXwKs9qqDxgYqXOJudPm8F39AG/Ww3FCx            f3t+UjvqAWQEL5bt+kGeBlrIbidgr2zuQ5mlEHCRchE1GI4QcTmGSBqW7KZJpGy2            BAsiTpe4uyh4+Vk7gXqt9+pfdF7aFiWphDERYJVFUFoizytAYjY=            -----END RSA PRIVATE KEY-----\nSample YAML file with double-quoted scalars\nSee Example A-2 for a complete example of YAML file with double-quoted (\"\") scalars.\nExample A-2   YAML f", "metadata": {"source": "sg248555.pdf", "chunk_index": 299, "total_chunks": 337}}
{"text": "xample A-2 for a complete example of YAML file with double-quoted (\"\") scalars.\nExample A-2   YAML file with double-quoted (\"\") scalars\nenv: |\ntype: env\n   logging:      syslog:         hostname: ${HOSTIP} # eg 10.0.0.8 or ${HOSTNAME}         port: 6514         server: \"-----BEGIN CERTIFICATE-----\\nMIIFCTCCAvECFEp7wJLz4jNStIsVH2dUeHDN26ZyMA0GCSqGSIb3DQEBCwUAMEEx\\nCzAJBgNVBAYTAlVTMRkwFwYDVQQKDBBMb2dzdGFzaCBUZXN0IENBMRcwFQYDVQQD\\nDA5jYS5leGFtcG\n\n102 Applying Data Protection and Confident iality in a Hybrid Cloud EnvironmentxlLm9yZzAeFw0yMzAxMDUxNjU0MTNaFw0yNDAxMDUxNjU0MTNa\\nMEExCzAJBgNVBAYTAlVTMRkwFwYDVQ\nQKDBBMb2dzdGFzaCBUZXN0IENBMRcwFQYD\\nVQQDDA5jYS5leGFtcGxlLm9yZzCCAiIwDQYJKoZIhvcNAQEBBQADggIPADCCAgoC\\nggIBANe7PR4XaTXtF6h3FhWe/R4BSTVylXWopA51+ppcJ3BOMPjmRMNJ3tFAFE3h\\nF4d0RHBNJOZF0+ogT0ZEseTe4mqJXk3RgfMSrLaymNgzaefD67uhQ9ZzznE3kIXe\\nmzh/A8aDwhaUMifIKxekisrmpvjDwUJtaSs3pb27W+cOmzAPZ3cmOs09tELLY134\\nf52sp0ZqFSOgvCwcdt88PFVMm2rrFgwxP2gLgOkZL4OsM9sQykYEPR28unS+P90V\\nqnYPy27xqJNss4OdZCJrjkS7", "metadata": {"source": "sg248555.pdf", "chunk_index": 300, "total_chunks": 337}}
{"text": "tELLY134\\nf52sp0ZqFSOgvCwcdt88PFVMm2rrFgwxP2gLgOkZL4OsM9sQykYEPR28unS+P90V\\nqnYPy27xqJNss4OdZCJrjkS7lv2PbBxSoFjDq/yLjnDV8khW2+6w0MFRvamoKL34\\nn/XoXN6VCathSxcwvXg0x3wwTxa5Hevb0iziNGXHjZ9bXt+8bnu/Bhsa7KwaoUt9\\nrJJeMy0KNsdQyWhMJE904YKm9Eo/S92rrcNWzmzBIV0iecOHc24iw3SIXOnoAKNY\\n1GtDOQChSEeb7en25s1fjWTqIDyDOktWjp9DXu1ips9YDb7GKZ7raOoQnsPkGrRE\\nKOWClkWQ4qIXJ9LH73ytR1h8+AsGyInaan5ehnz7JC5SFhE96wPzJDaXCKNHBP/e\\ntfwQ0BTbgO6z8gPE8JlPGXTmdf9YF5NxMd4oJA7u7Y6x2y4KIRYacrcevDxe/lFk\\n843MwiYU2atYgqgFK07BIOHNvqv93WiqXy8WAolSmMoJ/eqdAgMBAAEwDQYJKoZI\\nhvcNAQELBQADggIBAFkQpmW3T50eI5AhAOzN6duxQtjDuIE4AhcQaejIVFu8R9H4\\nGKw8WQo1DO7jaefRK7BFy68u8Cacgyn6btCoA0AMuKYyt1StM4Jzf2ZxWrox0Tl+\\nUW5RJFP8HoIBQutMtgHaY3hWZJ4Jvcg6y7kroMynZnsV3jbK0/GmthtUYonjCpCH\\nuC1rEp/0Gkp9BPnrY6cgyRdDbgmDo3YMqmUh8BqTGLEi+F45K/PEN502kUBcMJTY\\nvpWVfgMz7nQhN4temIlQQDs8gu3LBt9lxomuMXtYkTq245LfXdtbPPkrwjvbIKzM\\nFasa1PkTmK23cXLpRWfNUu/JHChpCl27Yg8ScTm6GV/eKhJbtku8ExvLWgHAITGi\\n5Rhh2Pl//Jh4szzTL34IY5bPqSXMrqUB3vFzND5ybmWrwo0i2CyLS+gKgGqzz0Xt\\n", "metadata": {"source": "sg248555.pdf", "chunk_index": 301, "total_chunks": 337}}
{"text": "Yg8ScTm6GV/eKhJbtku8ExvLWgHAITGi\\n5Rhh2Pl//Jh4szzTL34IY5bPqSXMrqUB3vFzND5ybmWrwo0i2CyLS+gKgGqzz0Xt\\nmvQ6XCiq7EsTdNLlX1ZDWjias12EIyCVbWrmxzFsR/Ji8XQqUoKK+QXhdsQ/uA4H\\nn72jGuWsjhRAKE7WyI2i1H+TPRZ+K6VaKeS2aikC3p2JCU4VxrP2jSdWhdYYwEgL\\nC/mjDXOjxbr6TIOtrxQQSBplTuRz8yNabrPB6G2xN+e70qpB1KT5w2ee1RH7M1o+\\nUoeDoSwqneVvONAjQn/0KKL0Y7P2BURHjJeWsLtFmyUZVlkqlosg8P7Nabrj\\n-----END CERTIFICATE-----\\n\"         cert: \"-----BEGIN CERTIFICATE-----\\nMIIFETCCAvkCFBhx5DuYtRzCxRx8Bo+WIS2LFI2uMA0GCSqGSIb3DQEBCwUAMEEx\\nCzAJBgNVBAYTAlVTMRkwFwYDVQQKDBBMb2dzdGFzaCBUZXN0IENBMRcwFQYDVQQD\\nDA5jYS5leGFtcGxlLm9yZzAeFw0yMzAxMDUxNjU1MzZaFw0yNDAxMDUxNjU1MzZa\\nMEkxCzAJBgNVBAYTAlVTMR0wGwYDVQQKDBRMb2dzdGFzaCBUZXN0IENsaWVudDEb\\nMBkGA1UEAwwSY2xpZW50LmV4YW1wbGUub3JnMIICIjANBgkqhkiG9w0BAQEFAAOC\\nAg8AMIICCgKCAgEArY+N+3IEYrIQpdMPT6xMqksSS43g2+44EdYiPNonP2KjEUdG\\n/g57CBnIOaUfZyvg3Fc9ROBMhqYa6CGKCd8Yec7mL4c97tS9wBtc6I0eEBmXAeZz\\nCGy6/1HtScZ/mAHw9rshgwF1Si/j9R4NA6ZepmGvoQMdUOGJJHhSsEfovVoRR5D/\\nVO1Urpu4LYnz7Zwo+/QEzJbUmSVN52/tNWjgTlH", "metadata": {"source": "sg248555.pdf", "chunk_index": 302, "total_chunks": 337}}
{"text": "1HtScZ/mAHw9rshgwF1Si/j9R4NA6ZepmGvoQMdUOGJJHhSsEfovVoRR5D/\\nVO1Urpu4LYnz7Zwo+/QEzJbUmSVN52/tNWjgTlHFCOdQ6aZCkwBK2DCa3b2NFWSO\\nvfhhl/4GLLeYZ2hG2f9+W+L6slLMWwpMqywY9bUXn+NROcYPoLX222saH6nY74+0\\n+B9Qk4BOlNqhN493FCoXq2uzGmYb0igOx+o8UVc7gcozbhvREgW4RRa4XgamonSW\\nCccM5sQFHFSxaGZXokpE2GJtQT0wv/pim4Ku0XEIQKmZGejC1dw26fbG+CWDWPXs\\nYEmf4S5Z5exjSiQCPL2QawCXgGEJNkiUMj5ld3jeb2kY221IKb+uSE6waNTts4nO\\nRa9DveHrUKrNqq33yoEZvj4K/QZ9px9km7o0BhR+oMPAYI/YODgNOhQLSR3q2n1C\\njd+baFfg4Sb8L2OUTyW4Kd2Ok9rkCk9W/8T/YKlrBFoSrNHtPhKIi6FZLkrodn1g\\n8+lPo3E80Gn5hUZdgsIZ7Y+c2qcUAVu8X/otFaWm8FCmIDyz+ZKm/YgaX4UCAwEA\\nATANBgkqhkiG9w0BAQsFAAOCAgEACg4PxboxM01cO3pmhTfvwetBvICz8GOuAq3f\\nLWYFXcZmnMHqwDZKOx20a03XfcBaWhyF9XHdCugziEMXTdfKxGwFsIUxQIbDBT4N\\nBNCcLTXiTEdtjvXxm0TnM5QdPOE36EsI+O4YT8w+C5nlKuNMtsxsJe+bxEfBi2PS\\nJ0vU1bO+4m9p0SDc3h39jb+FLrAnqez2QbT2maby8A8wahunAMWY+ZUkQYoWpilf\\nRkGpiLKlkJ95HCYzmt7IeddH5+ZBuG+Sx4SMwCynn64J/UafNW0XV36dzeLSla59\\nvQCmWAurjAqa8fqepdvNI4I/JxVfeCQwkrZEos0gec+D7qOupfHk3Zyr6G5Zn8kS\\nYRU8HpRIRH4KvsO", "metadata": {"source": "sg248555.pdf", "chunk_index": 303, "total_chunks": 337}}
{"text": "fNW0XV36dzeLSla59\\nvQCmWAurjAqa8fqepdvNI4I/JxVfeCQwkrZEos0gec+D7qOupfHk3Zyr6G5Zn8kS\\nYRU8HpRIRH4KvsObTNIrW5Z/qbfWAFSTC3q0eflaVLWsrXfSGvBDVqlxO3arhv2q\\nra6tcD7MQOBO226i+v3aL9qJ3viWhIQTvONm7D8U+/WryrChBOHVCQ2M3AZQQLeC\\nqSkJ60wFx8jEqLj9ELWuTMuHYg5lhMZFyLI8iWOvGRPmgTUZKNH74LF1ujIEuMBx\\nE7LBWRGNx2lD0f2aYUdv+qWA8m1ETPyKYme6oUM+kDlf6sstMgahN7zT8jj/W2KD\\ndG+yzHk5G06lSQzXGbec3bi2WOpWHJ1J/kTQ8Af1HuJr4UjQmin8fLW6n06diySA\\nBSHYGWk=\\n-----END CERTIFICATE-----\\n\"         key: \"-----BEGIN PRIVATE KEY-----\\nMIIJQQIBADANBgkqhkiG9w0BAQEFAASCCSswggknAgEAAoICAQCtj437cgRishCl\\n0w9PrEyqSxJLjeDb7jgR1iI82ic/YqMRR0b+DnsIGcg5pR9nK+DcVz1E4EyGphro\\nIYoJ3xh5zuYvhz3u1L3AG1zojR4QGZcB5nMIbLr/Ue1Jxn+YAfD2uyGDAXVKL+P1\\nHg0Dpl6mYa+hAx1Q4YkkeFKwR+i9WhFHkP9U7VSum7gtifPtnCj79ATMltSZJU3n\\nb+01aOBOUcUI51DppkKTAErYMJrdvY0VZI69+GGX/gYst5hnaEbZ/35b4vqyUsxb\\nCkyrLBj1tRef41E5xg+gtfbbaxofqdjvj7T4H1CTgE6U2qE3j3cUKhera7MaZhvS\\nKA7H6jxRVzuByjNuG9ESBbhFFrheBqaidJYJxwzmxAUcVLFoZleiSkTYYm1BPTC/\\n+mKbgq7RcQhAqZkZ6MLV3Dbp9sb4JYNY9exgSZ/hL", "metadata": {"source": "sg248555.pdf", "chunk_index": 304, "total_chunks": 337}}
{"text": "RVzuByjNuG9ESBbhFFrheBqaidJYJxwzmxAUcVLFoZleiSkTYYm1BPTC/\\n+mKbgq7RcQhAqZkZ6MLV3Dbp9sb4JYNY9exgSZ/hLlnl7GNKJAI8vZBrAJeAYQk2\\nSJQyPmV3eN5vaRjbbUgpv65ITrBo1O2zic5Fr0O94etQqs2qrffKgRm+Pgr9Bn2n\\nH2SbujQGFH6gw8Bgj9g4OA06FAtJHerafUKN35toV+DhJvwvY5RPJbgp3Y6T2uQK\\nT1b/xP9gqWsEWhKs0e0+EoiLoVkuSuh2fWDz6U+jcTzQafmFRl2Cwhntj5zapxQB\\nW7\n\nAppendix A. Client contract setup sample files 103xf+i0VpabwUKYgPLP5kqb9iBpfhQIDAQABAoICACsovIzfgHmuf/dMcc1FMldS\\njb0eDeGC7ox47FCniw\nT3GUfNqri4jx2nk6PKDPIR9ju0sfaztDPzkFNTK8lioeqA\\nabs97Ue7vWfNJiBqHySvyF5fmRFqQGIHVHN5GfeJ3Aru49l4/lqxaAVnMKNMttK3\\nDf6DEMIxI3JfPWi6qQSVJiDezK+oyNsWvAkO+gqHP6XPu3XIuBtRLHs12Q3kA4tW\\nSCH7q6I+huWZOANkqs4jObctJ1XUMyihsZVjHlHwm1XQc/KTkfXQIyMsf349XAOV\\nwccvtt4gA3jaZwWPL5LaIKkJ2l2tI9NaH7BiYZ64XUs1YGdvQ7130MlEztAlzlOe\\n9M4tkvdELLcvyByEsY3JaObWe/N/RPk3vom4EP/XF+dTnIXRO0nLDP5Kwzj1Cpwb\\nRh7Jp6dmfOpBMLKtb5iEKUROPjGJT+jKORhWaTwo4zmqj6EHp1Z2cUeZdvZomQWM\\nb75xNoJyBKooLAafdGWO0ADR1nbK56+RpbF07/xHHdWR1SuJE6vppkQ33WOsLMJb\\nCo141AG+5NRPe5bn5KH9KrgsJTNPpl", "metadata": {"source": "sg248555.pdf", "chunk_index": 305, "total_chunks": 337}}
{"text": "WM\\nb75xNoJyBKooLAafdGWO0ADR1nbK56+RpbF07/xHHdWR1SuJE6vppkQ33WOsLMJb\\nCo141AG+5NRPe5bn5KH9KrgsJTNPplhNfq5KGE+xb+gfIH71KuxMgHafBp2Ng432\\njGr4ZfBJy/w8cS0jLWrzAPEvz1ZmhIEGNeiOs78QO6efeT4fCAohw7qQur23K8YB\\nTyVFdUaq63ndFq3kqBGtAoIBAQDZPs86SyDwvLttaLlgpE8z+XgxLRWZRwPCQ+yV\\nAhJKaehxyavAPkp+k5f1EaAL9g20ZCzMA3N8imsEe8zvbrDuR/xBCIUGppmQnD/E\\nCUQk4Un63znNZdJ+h7cn/kysi7D0od9oHgYxI3oj0VhPNkdwm4GSJ8lvXrL7RD/f\\ncXFKrzIOmdkOJY1DydtRAS772MKXVURxaFZ3kePFETloqiqgBIaKt1gw9uSrtkg8\\necW3NVQDI521Q/uNYQaqA2AKGmLXC9Cg4GCfxseaiLxWaEsd+cOAzzoU8v+8nPRo\\ntVdKPEg//b0TJArxh4ZQVOxogLVbgW2JoY9gsaslqZpQaRbLAoIBAQDMhcBVG8vO\\nqsmqv2qV0+251KLt5Y2hfU5k3OONsIAQl1a7sKOY4eXiVpKzT3J/emZeLsQmHnw2\\nRdIXqjaVjH5jNADV9tHsQZ2KA0qV2JO/VK7fQtjV8XIaHh/gIAXXerSyLdh7rdHp\\ng+xfHaDB1kKUmZR6MtB87hlQ6ngBI49/7xgJReTeee2oj4sN10ALVi51XyNfZ+FV\\nQu8D2VP6ssn70qvempzLaP70ZNj2eES7KK8XEm7x7Stv0ptZl7n+E+OqZ1i4OVcF\\n7UCRBCrmDYWYCLmajmR04zyBeppJfSRbH3y3mXBeNwmlFqmQz5NVNDg/YkcPbM4O\\nakCX7ZXPH0jvAoIBAFhZx/NgLIRbbSpAxet8x01O7sepGzib/fZao3OyRPgIfGUS\\nbIwhiT", "metadata": {"source": "sg248555.pdf", "chunk_index": 306, "total_chunks": 337}}
{"text": "BeNwmlFqmQz5NVNDg/YkcPbM4O\\nakCX7ZXPH0jvAoIBAFhZx/NgLIRbbSpAxet8x01O7sepGzib/fZao3OyRPgIfGUS\\nbIwhiTBTHCCpy1ox9j7f4qwR1zzWGlHXe3AAp2ow0nEsYtVimd+K/A/g6NrK2Mhz\\nUlGrUGDvFtjn/gzKPuwujOoOE9yWHg1FDVIhtAoi5B4pmi116PpxNjzMKRQDjisL\\n/I9ZTEs+Y7hc79uyuujK36vzj/7O0UALEjrzwaQUUxdFG1PGhRckadpWd8dbo9An\\nAvN+M2a7B/fKqZtSQdJNVsqmlgVE1VaOt3G4tpv5QL45CNkOPl1Zw7h1z4s8WvHT\\nYrrPFLhHsqMm9oJFnfwZ9g9cKjBb8Uu+3yhGpOMCggEAeHzfZwReGB2zev0TvLrC\\nlTS426/dtWKN2YvsHt/5Qkz2EtKoPnvuo13fRPWr/X/NaPTiJ5bUFGEjuT9Ustu2\\n5ZiQWXz0BNxPBCyWNxsFR7WK5AqMldWNI+fVXYNgDabDZyjtHUe0n35RtWNN/oPM\\na6DiwO7ItqDKl0nacslRU8w2e9gKUirAoQoXoIrLtyIJcqoeu6kGLeWly72v5MSJ\\ni+p7yEOL1aXAdZgn3WPTEfOQ2uXIKIxRh6oqTSi+sPlkqVIDCVz2cI5p+ETdRPR4\\nXK3fMjdq5RWt4pWo6VxpG6m8HqmtckO4UeK8+IvhP1PpQyYRuPuflQxxi0+zbvb+\\nTwKCAQAtxUAS8r+AP3Uufi9DvujI5z3+mWqZiM5Mxg8OJq0qNPE8V6gfrSspEgDt\\nHWF8TUNoATWLCCak1u9ImBqiPZMH9WfRXaLSofrFJsVTFt+5ZeT6QMnc0RnBZakL\\nvJMX9rKkb98leIRfCwzlnBQ84IFM41e0F15+853aIibpBAI7BEfTvJ8Eg/m20w1H\\nrPRP1j6GYhpkAIm2+TVx6DFY/JO6JM1i0tzHv7zihSeji0lw", "metadata": {"source": "sg248555.pdf", "chunk_index": 307, "total_chunks": 337}}
{"text": "RfCwzlnBQ84IFM41e0F15+853aIibpBAI7BEfTvJ8Eg/m20w1H\\nrPRP1j6GYhpkAIm2+TVx6DFY/JO6JM1i0tzHv7zihSeji0lwBMKJ7M0TRXz1dJeR\\n3GsDlD7mKwLVaBBKQ1Uxh1zYbiaUzVst1S2Wdvt13f89IV4Mmmuq2v1Uz4je7pDB\\nhJITxResgCTR2aD0nMzF8egEKJoY\\n-----END PRIVATE KEY-----\\n\"\nSample script for certificate or key files\nThis simple sample script can be  used to output certificate or key files into double-quoted \nscalar values for YAML f iles. See Example A-3.\nExample A-3   Script for certificate or key files\n~# cat yaml_doublequoted_input.sh \n#!/bin/bash\nsed 's/$/\\\\n/' $1 | tr -d '\\n'\necho \"\"\nSee Example A-4 for how to use the script.\nExample A-4   Making use of the script\n~# cat ca.pem \n-----BEGIN CERTIFICATE-----MIIEuDCCAyCgAwIBAgIUBR9g6L5hivov7eNT00HSXW39oD0wDQYJKoZIhvcNAQELBQAwXzELMAkGA1UEBhMCVVMxEzARBgNVBAgMCkNhbGlmb3JuaWExFDASBgNVBAcM\n\n104 Applying Data Protection and Confident iality in a Hybrid Cloud EnvironmentC0xvcyBBbmdlbGVzMQwwCgYDVQQKDANJQk0xFzAVBgNVBAMMDmNhLmV4YW1wbGUu\nb3JnMB4XDTIzMDEyNzE4MzkzMFoXDTI1MDExNj", "metadata": {"source": "sg248555.pdf", "chunk_index": 308, "total_chunks": 337}}
{"text": "vcyBBbmdlbGVzMQwwCgYDVQQKDANJQk0xFzAVBgNVBAMMDmNhLmV4YW1wbGUu\nb3JnMB4XDTIzMDEyNzE4MzkzMFoXDTI1MDExNjE4MzkzMFowXzELMAkGA1UEBhMCVVMxEzARBgNVBAgMCkNhbGlmb3JuaWExFDASBgNVBAcMC0xvcyBBbmdlbGVzMQwwCgYDVQQKDANJQk0xFzAVBgNVBAMMDmNhLmV4YW1wbGUub3JnMIIBojANBgkqhkiG9w0BAQEFAAOCAY8AMIIBigKCAYEAsgnjL9ZxtdlQf1IAwEWkcPXQEHA47LY03BO7c5jai9vRSGxa16hj6SUOidzKj4lK7w9REhxnaihkk1P8zfF9Eld/FvMKANpdaniOJUFT/FXzlwG1c+R+h3ZTv4LiEi9SzWwkbNBOhMN5YM7nCOWNxQBHptisNvdRqb6VidQfneU0aesmmu61IDeB54wpsZXiRXB7M2fpx3c/9ppFYSCGWpC0Bibu12r6kg85EykR4zjEQiVg4U9m4zchQE73Ljl+pDHaGuJlMlfKgPKwAdmPEGK8IBctb3WbuBffojmgRerlAEajDlDD0IQE4s+dX/F+bZCZiJrfpHz8CAs6i/GPqVR1U2jP7zaAJqgsKNfWm0CXcLDsdbxgGNU8ECzVKw9pWPcG4A4bxiznZpgWXwoBHmnbqriZe1KEAjRMfGCGJI3xyODCsT/64zGIwX1ajpn9b6cWnAGoXrjOc5HSXnPGyiRDc/7jmmSXcOKdCd3SaQu/ahNHXjr5X1dQ7XrzgY/1AgMBAAGjbDBqMA4GA1UdDwEB/wQEAwIChDAPBgNVHRMBAf8EBTADAQH/MEcGA1UdEQRAMD6CEnNlcnZlci5leGFtcGxlLm9yZ4IXc2VydmVyLmV4YW1wbGUub3JnOjY1MTSCCTkuMjAuNy45MocECRQHXDANBgkqhkiG9w0BAQsFAAOCAYEAfLdjI2j0XbVqbZcQNBIPbyL1fh", "metadata": {"source": "sg248555.pdf", "chunk_index": 309, "total_chunks": 337}}
{"text": "VyLmV4YW1wbGUub3JnOjY1MTSCCTkuMjAuNy45MocECRQHXDANBgkqhkiG9w0BAQsFAAOCAYEAfLdjI2j0XbVqbZcQNBIPbyL1fhsNX0I0NvPRU9tpA1M41+UrdCFNQKivai7jKsATzDZZVG0Adprki7YFqUocZ/NpwC6GHFETrTCICaVrjUuF2ecgiwXLZIiHWV+qOAbycG9VoUw7eRVKarfbmd31YwZ1il27e44V1mjVd4gdJvV6a4H65lm3fobogin9535lnJuZjHQNQ7cbN1hrKOkNrvZpSfe5lZ6EFUZHk3S/Wdux31rz1cQQAhpFfJL84KDvM/cBISKGDutgAADCb9jtH8q+ow19n7R1ff10r4/9G7CA9mv6llJf8+P8Y22CGDvez3YPs3Dt7AnZe7bEEpQg1EDlgVq+WzbyEcmmaVwJcj5o7annifkUIrmJOiACtDlklQXYIiZcyg8zfLIcFYkf+PHpvtYF8c5Av4DS2YFPwtc5OoLzxUOI54V6pJZBc60aL9vNyxBAKj/cQEQKrLtUGr1vjPTOFycNW5yQAAhDL6o6E+3SuTEClFsd2QMaCJuQ-----END CERTIFICATE-----~#~# ./yaml_doublequoted_input.sh ca.pem -----BEGIN CERTIFICATE-----\\nMIIEuDCCAyCgAwIBAgIUBR9g6L5hivov7eNT00HSXW39oD0wDQYJKoZIhvcNAQEL\\nBQAwXzELMAkGA1UEBhMCVVMxEzARBgNVBAgMCkNhbGlmb3JuaWExFDASBgNVBAcM\\nC0xvcyBBbmdlbGVzMQwwCgYDVQQKDANJQk0xFzAVBgNVBAMMDmNhLmV4YW1wbGUu\\nb3JnMB4XDTIzMDEyNzE4MzkzMFoXDTI1MDExNjE4MzkzMFowXzELMAkGA1UEBhMC\\nVVMxEzARBgNVBAgMCkNhbGlmb3JuaWExFDASBgNVBAcMC0xvcyBBbmd", "metadata": {"source": "sg248555.pdf", "chunk_index": 310, "total_chunks": 337}}
{"text": "zkzMFoXDTI1MDExNjE4MzkzMFowXzELMAkGA1UEBhMC\\nVVMxEzARBgNVBAgMCkNhbGlmb3JuaWExFDASBgNVBAcMC0xvcyBBbmdlbGVzMQww\\nCgYDVQQKDANJQk0xFzAVBgNVBAMMDmNhLmV4YW1wbGUub3JnMIIBojANBgkqhkiG\\n9w0BAQEFAAOCAY8AMIIBigKCAYEAsgnjL9ZxtdlQf1IAwEWkcPXQEHA47LY03BO7\\nc5jai9vRSGxa16hj6SUOidzKj4lK7w9REhxnaihkk1P8zfF9Eld/FvMKANpdaniO\\nJUFT/FXzlwG1c+R+h3ZTv4LiEi9SzWwkbNBOhMN5YM7nCOWNxQBHptisNvdRqb6V\\nidQfneU0aesmmu61IDeB54wpsZXiRXB7M2fpx3c/9ppFYSCGWpC0Bibu12r6kg85\\nEykR4zjEQiVg4U9m4zchQE73Ljl+pDHaGuJlMlfKgPKwAdmPEGK8IBctb3WbuBff\\nojmgRerlAEajDlDD0IQE4s+dX/F+bZCZiJrfpHz8CAs6i/GPqVR1U2jP7zaAJqgs\\nKNfWm0CXcLDsdbxgGNU8ECzVKw9pWPcG4A4bxiznZpgWXwoBHmnbqriZe1KEAjRM\\nfGCGJI3xyODCsT/64zGIwX1ajpn9b6cWnAGoXrjOc5HSXnPGyiRDc/7jmmSXcOKd\\nCd3SaQu/ahNHXjr5X1dQ7XrzgY/1AgMBAAGjbDBqMA4GA1UdDwEB/wQEAwIChDAP\\nBgNVHRMBAf8EBTADAQH/MEcGA1UdEQRAMD6CEnNlcnZlci5leGFtcGxlLm9yZ4IX\\nc2VydmVyLmV4YW1wbGUub3JnOjY1MTSCCTkuMjAuNy45MocECRQHXDANBgkqhkiG\\n9w0BAQsFAAOCAYEAfLdjI2j0XbVqbZcQNBIPbyL1fhsNX0I0NvPRU9tpA1M41+Ur\\ndCFNQKivai7jKsATzDZZVG0Adprki7Y", "metadata": {"source": "sg248555.pdf", "chunk_index": 311, "total_chunks": 337}}
{"text": "G\\n9w0BAQsFAAOCAYEAfLdjI2j0XbVqbZcQNBIPbyL1fhsNX0I0NvPRU9tpA1M41+Ur\\ndCFNQKivai7jKsATzDZZVG0Adprki7YFqUocZ/NpwC6GHFETrTCICaVrjUuF2ecg\\niwXLZIiHWV+qOAbycG9VoUw7eRVKarfbmd31YwZ1il27e44V1mjVd4gdJvV6a4H6\\n5lm3fobogin9535lnJuZjHQNQ7cbN1hrKOkNrvZpSfe5lZ6EFUZHk3S/Wdux31rz\\n1cQQAhpFfJL84KDvM/cBISKGDutgAADCb9jtH8q+ow19n7R1ff10r4/9G7CA9mv6\\nllJf8+P8Y22CGDvez3YPs3Dt7AnZe7bEEpQg1EDlgVq+WzbyEcmmaVwJcj5o7ann\\nifkUIrmJOiACtDlklQXYIiZcyg8zfLIcFYkf+PHpvtYF8c5Av4DS2YFPwtc5OoLz\\nxUOI54V6pJZBc60aL9vNyxBAKj/cQEQKrLtUGr1vjPTOFycNW5yQAAhDL6o6E+3S\\nuTEClFsd2QMaCJuQ\\n-----END CERTIFICATE-----\\n:~#  \nThe contents of ca.pem in Example A-2 on page 101 is the literal scalar example in \nExample A-1 on page 100. After running the command ./yaml_doublequoted_input.sh \nca.pem  the contents have been modified as such that it can be copied and pasted inside a \n\nAppendix A. Client contract setup sample files 105double-quote (\"\") in a YAML file as can be seen in the double-quoted scalar example in \nExample A-2 on page 101", "metadata": {"source": "sg248555.pdf", "chunk_index": 312, "total_chunks": 337}}
{"text": "e (\"\") in a YAML file as can be seen in the double-quoted scalar example in \nExample A-2 on page 101.\n\n106 Applying Data Protection and Confident iality in a Hybrid Cloud Environment\n\n\u00a9 Copyright IBM Corp. 2024. 107Appendix B. Creating a Hyper Protect Virtual \nServer for VPC \nThis appendix provides a walkthrough that shows how to create a Hyper Protect Virtual \nServer (HPVS) instance by using the IBM Cloud Virtual Private Cloud (VPC) user interface (UI).B\n\n108 Applying Data Protection and Confident iality in a Hybrid Cloud EnvironmentUsing the IBM Cloud VPC UI\nIn this section we sh ow the steps that are needed to cr eate a HPVS instance  using the IBM \nCloud VPC UI.\n1. Login to IBM Cloud at https://cloud.ibm.com/login . \n2. From the icons in the left panel, select VPC infrastructure. See Figure B-1.\nFigure B-1   Login to IBM Cloud\n3. Click Virtual server instances  and click Create. See Figure B-2.\nFigure B-2   Virtual server instance for VPC\n\n\nAppendix B. Creating a Hyper Protect Virt", "metadata": {"source": "sg248555.pdf", "chunk_index": 313, "total_chunks": 337}}
{"text": "Figure B-2.\nFigure B-2   Virtual server instance for VPC\n\n\nAppendix B. Creating a Hyper Protect Virtual Server for VPC 1094. Select the location of your choice, then provide a name for your virtual server. See \nFigure B-3.\nFigure B-3   Select a location\n\n\n110 Applying Data Protection and Confident iality in a Hybrid Cloud Environment5. Under the Image and Profile heading, for the CentOS image, click Change image . See \nFigure B-4.\nFigure B-4   Change image\n\n\nAppendix B. Creating a Hyper Protect Virtual Server for VPC 1116. On the next screen select  IBM Z, LinuxONE, s390 architecture . See Figure B-5.\n7. Select the switch under Confidential computing. \n8. Select the desired image.\nFigure B-5   Select architecture and confidential computing\n\n\n112 Applying Data Protection and Confident iality in a Hybrid Cloud Environment9. Click Save.\n10.Select the profile and under the Data volumes heading, select Create . See Figure B-6. \nFigure B-6   Select a profile and storage\n11.Input the contents", "metadata": {"source": "sg248555.pdf", "chunk_index": 314, "total_chunks": 337}}
{"text": "ng, select Create . See Figure B-6. \nFigure B-6   Select a profile and storage\n11.Input the contents of user_data.yam l prepared in 4.2.4, \u201cPrepare user_data.yaml\u201d on \npage 73 to \u201cUser data\u201d field. See Figure B-7.\n12.Click Create virtual server .\nFigure B-7   Create a virtual server\n\n\nAppendix B. Creating a Hyper Protect Virtual Server for VPC 11313.Monitor the serial console to see the boot process of the virtual server instance. See \nFigure B-8.\nFigure B-8   Open serial console\n14.View the messages in the serial console. See Figure B-9. If there are any errors, the \nvirtual server instance shuts down. \nFigure B-9   Virtual server boot\n\n\n114 Applying Data Protection and Confident iality in a Hybrid Cloud Environment15.Monitor IBM Log Analysis to see if the container workload is started successfully. See \nFigure B-10.\nFigure B-10   Check the container workload\n\n\n\u00a9 Copyright IBM Corp. 2024. 115Appendix C. Additional examples for HPSB \nand HPVS\nThis appendix contains the co mplete exampl", "metadata": {"source": "sg248555.pdf", "chunk_index": 315, "total_chunks": 337}}
{"text": "4. 115Appendix C. Additional examples for HPSB \nand HPVS\nThis appendix contains the co mplete examples of  the Hyper Protect Secure Build (HPSB) \nprocess from Example 4-19 on page 76 and HPVS instance verify ing disk (volume) \nencryption from Example 4-38 on page 88.\n/SM590000\u201cHyper Protect Secure Build log\u201d on page 116\n/SM590000\u201cHow to verify disk (volume) encryption with HPL13000I\u201d on page 118C\n\n116 Applying Data Protection and Confident iality in a Hybrid Cloud EnvironmentHyper Protect Secure Build log\nThe ./build.py log --log build --env  command can be used to  view the HPSB log. See \nExample C-1.\nExample C-1   HPSB log\n$ ./build.py log --log build --env sbs-config.jsonINFO:__main__:2023-07-25 08:59:36,446  build_task               INFO    starting a buildINFO:__main__:2023-07-25 08:59:36,447  build_task               INFO    cleaning up the local github repo and the github access credentialINFO:__main__:2023-07-25 08:59:36,447  clean_up                 INFO    github_dir=paynow-w", "metadata": {"source": "sg248555.pdf", "chunk_index": 316, "total_chunks": 337}}
{"text": "redentialINFO:__main__:2023-07-25 08:59:36,447  clean_up                 INFO    github_dir=paynow-websiteINFO:__main__:2023-07-25 08:59:36,448  build_task               INFO    cloning a github repoINFO:__main__:2023-07-25 08:59:36,448  clone_github_repo        INFO    github_host=github.comINFO:__main__:2023-07-25 08:59:36,448  clone_github_repo        INFO    github_dir=paynow-websiteINFO:__main__:2023-07-25 08:59:36,626  run                      INFO    run: Cloning into 'paynow-website'...INFO:__main__:2023-07-25 08:59:37,010  clone_github_repo        INFO    image_tag=v3-f29b1abINFO:__main__:2023-07-25 08:59:37,011  build_task               INFO    building a docker containerINFO:__main__:2023-07-25 08:59:37,011  build_docker_image       INFO    github_dir=paynow-websiteINFO:__main__:2023-07-25 08:59:37,025  run                      INFO    run:             environment-variable.INFO:__main__:2023-07-25 08:59:37,025  run                      INFO    run:  INFO:__main__:2023-07-25 ", "metadata": {"source": "sg248555.pdf", "chunk_index": 317, "total_chunks": 337}}
{"text": "O:__main__:2023-07-25 08:59:37,025  run                      INFO    run:  INFO:__main__:2023-07-25 08:59:37,129  run                      INFO    run: Sending build context to Docker daemon  2.842MBINFO:__main__:2023-07-25 08:59:37,131  run                      INFO    run: Step 1/7 : FROM node:19\nINFO    run: 5ac921848b31: Waiting\nINFO:__main__:2023-07-25 08:59:37,393  run                      INFO    run: 86b7a0ecd4be: WaitingINFO:__main__:2023-07-25 08:59:37,717  run                      INFO    run: e4000487deec: Verifying Checksum INFO:__main__:2023-07-25 08:59:37,719  run                      INFO    run: e4000487deec: Download completeINFO:__main__:2023-07-25 09:00:12,822  run                      INFO    run: e4000487deec: Pull completeINFO:__main__:2023-07-25 09:00:18,052  run                      INFO    run: Digest: sha256:92f06fc13bcc09f1ddc51f6ebf1aa3d21a6532b74f076f224f188bc6b9317570INFO:__main__:2023-07-25 09:01:16,173  run                      INFO    run: Status: Down", "metadata": {"source": "sg248555.pdf", "chunk_index": 318, "total_chunks": 337}}
{"text": "bc6b9317570INFO:__main__:2023-07-25 09:01:16,173  run                      INFO    run: Status: Downloaded newer image for node:19INFO:__main__:2023-07-25 09:01:16,175  run                      INFO    run:  ---> f2e8386523b1INFO:__main__:2023-07-25 09:01:16,175  run                      INFO    run: Step 2/7 : WORKDIR /appINFO:__main__:2023-07-25 09:01:29,718  run                      INFO    run: Step 3/7 : COPY app/package*.json ./\n\nAppendix C. Additional examples for HPSB and HPVS 117INFO:__main__:2023-07-25 09:01:29,878  run                      INFO    run: Step \n4/7 : RUN npm install INFO:__main__:2023-07-25 09:01:33,744  run                      INFO    run: added 65 packages, and audited 66 packages in 3s INFO:__main__:2023-07-25 09:01:35,142  run                      INFO    run: Step 5/7 : COPY app/ . INFO:__main__:2023-07-25 09:01:35,450  run                      INFO    run:  ---> 1ed7cc739746 INFO:__main__:2023-07-25 09:01:35,450  run                      INFO    run: Ste", "metadata": {"source": "sg248555.pdf", "chunk_index": 319, "total_chunks": 337}}
{"text": "  ---> 1ed7cc739746 INFO:__main__:2023-07-25 09:01:35,450  run                      INFO    run: Step 6/7 : EXPOSE 8443INFO:__main__:2023-07-25 09:01:35,572  run                      INFO    run: Step 7/7 : CMD npm startINFO:__main__:2023-07-25 09:01:35,594  run                      INFO    run:  ---> Running in fcba8cd7f8acINFO:__main__:2023-07-25 09:01:35,678  run                      INFO    run: Removing intermediate container fcba8cd7f8acINFO:__main__:2023-07-25 09:01:35,679  run                      INFO    run: Successfully built 9cae137191b0INFO:__main__:2023-07-25 09:01:35,683  run                      INFO    run: Successfully tagged devuser/samplepaymentsystem:latestINFO:__main__:2023-07-25 09:01:35,684  run                      INFO    run: return code = 0INFO:__main__:2023-07-25 09:01:35,748  run                      INFO    run: return code = 0INFO:__main__:2023-07-25 09:01:35,749  build_task               INFO    pushing a container to a docker hub INFO:__main__:2023-07-", "metadata": {"source": "sg248555.pdf", "chunk_index": 320, "total_chunks": 337}}
{"text": ":35,749  build_task               INFO    pushing a container to a docker hub INFO:__main__:2023-07-25 09:01:35,860  run                      INFO    run: INFO:__main__:2023-07-25 09:01:35,860  run                      INFO    run: Login SucceededINFO:__main__:2023-07-25 09:01:35,861  run                      INFO    run: return code = 0INFO:__main__:2023-07-25 09:01:35,910  run                      INFO    run: The push refers to repository [docker.io/devuser/samplepaymentsystem]INFO:__main__:2023-07-25 09:01:35,922  run                      INFO    run: fb4fa3257dd1: PreparingINFO:__main__:2023-07-25 09:01:35,923  run                      INFO    run: fda0660b571f: WaitingINFO:__main__:2023-07-25 09:01:36,422  run                      INFO    run: ef13dc0a223f: Mounted from library/nodeINFO:__main__:2023-07-25 09:01:37,211  run                      INFO    run: ef13dc0a223f: PushedINFO:__main__:2023-07-25 09:01:38,885  run                      INFO    run: v3-f29b1ab: digest: sha256:", "metadata": {"source": "sg248555.pdf", "chunk_index": 321, "total_chunks": 337}}
{"text": ":__main__:2023-07-25 09:01:38,885  run                      INFO    run: v3-f29b1ab: digest: sha256:d10e26e72a2f83a3fdf8a6a79da5b88f1b6747ce0af9309749afc55295973bd8 size: 2839INFO:__main__:2023-07-25 09:01:38,888  run                      INFO    run: Signing and pushing trust metadataINFO:__main__:2023-07-25 09:01:39,289  run                      INFO    run: Finished initializing \"docker.io/devuser/samplepaymentsystem\"INFO:__main__:2023-07-25 09:01:39,388  run                      INFO    run: Successfully signed docker.io/devuser/samplepaymentsystem:v3-f29b1abINFO:__main__:2023-07-25 09:01:39,390  run                      INFO    run: return code = 0INFO:__main__:2023-07-25 09:01:39,448  run                      INFO    run: The push refers to repository [docker.io/devuser/samplepaymentsystem]INFO    run: ef13dc0a223f: Layer already exists\n\n118 Applying Data Protection and Confident iality in a Hybrid Cloud EnvironmentINFO:__main__:2023-07-25 09:01:40,152  run                      I", "metadata": {"source": "sg248555.pdf", "chunk_index": 322, "total_chunks": 337}}
{"text": "ality in a Hybrid Cloud EnvironmentINFO:__main__:2023-07-25 09:01:40,152  run                      INFO    run: \nlatest: digest: sha256:d10e26e72a2f83a3fdf8a6a79da5b88f1b6747ce0af9309749afc55295973bd8 size: 2839INFO:__main__:2023-07-25 09:01:40,154  run                      INFO    run: Signing and pushing trust metadataINFO:__main__:2023-07-25 09:01:40,398  run                      INFO    run: Successfully signed docker.io/devuser/samplepaymentsystem:latestINFO:__main__:2023-07-25 09:01:40,399  run                      INFO    run: return code = 0INFO:__main__:2023-07-25 09:01:40,400  build_task               INFO    extracting an image keyid and keyINFO:__main__:2023-07-25 09:01:40,400  build_task               INFO    docker contrust value:https://notary.docker.ioINFO:__main__:2023-07-25 09:01:40,400  build_task               INFO    entered dctINFO:__main__:2023-07-25 09:01:40,400  extract_image_key_id     INFO    keyid=60340916db8868c4db38f99a9928829332b341ca5313f548ec25cc015102c", "metadata": {"source": "sg248555.pdf", "chunk_index": 323, "total_chunks": 337}}
{"text": "extract_image_key_id     INFO    keyid=60340916db8868c4db38f99a9928829332b341ca5313f548ec25cc015102c140INFO:__main__:2023-07-25 09:01:40,400  extract_image_key_id     INFO    publickey=LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUJsVENDQVR1Z0F3SUJBZ0lRV2RmQStQcm9tVjRwd2RVS01KYnFqREFLQmdncWhrak9QUVFEQWpBeE1TOHcKTFFZRFZRUURFeVprYjJOclpYSXVhVzh2WVdKb2FYSmhiV3N2YzJGdGNHeGxjR0Y1YldWdWRITjVjM1JsYlRBZQpGdzB5TXpBM01qVXdPVEF4TXpoYUZ3MHpNekEzTWpJd09UQXhNemhhTURFeEx6QXRCZ05WQkFNVEptUnZZMnRsCmNpNXBieTloWW1ocGNtRnRheTl6WVcxd2JHVndZWGx0Wlc1MGMzbHpkR1Z0TUZrd0V3WUhLb1pJemowQ0FRWUkKS29aSXpqMERBUWNEUWdBRWplMmFPYTVPYUE4UHJFUThHNTgybTZxWmlJaEFvYWo2bDZaaThsaDFwM01VbTBLNAp4TVBJcytZNHA2TzVzeE9tRFpFaW9SbmJOeU1NRDJrN05zNXVLYU0xTURNd0RnWURWUjBQQVFIL0JBUURBZ1dnCk1CTUdBMVVkSlFRTU1Bb0dDQ3NHQVFVRkJ3TURNQXdHQTFVZEV3RUIvd1FDTUFBd0NnWUlLb1pJemowRUF3SUQKU0FBd1JRSWdZUnZObW1nRkg1dTBSNnlENUhxcDFTcW9zM2k5cVczbWxRWVlJN2oyZXJVQ0lRRFZGNjhXbXo0RQplUXExeVJvaHIwZXpZck52OEh4eXQvUS9CMDBlQUY1NzlRPT0KLS0tLS1FTkQgQ0VSVElGSUNBVEUtLS0tLQo", "metadata": {"source": "sg248555.pdf", "chunk_index": 324, "total_chunks": 337}}
{"text": "RRFZGNjhXbXo0RQplUXExeVJvaHIwZXpZck52OEh4eXQvUS9CMDBlQUY1NzlRPT0KLS0tLS1FTkQgQ0VSVElGSUNBVEUtLS0tLQo=INFO:__main__:2023-07-25 09:01:40,400  build_task               INFO    generating a config fileINFO:__main__:2023-07-25 09:01:40,903  digest                   INFO    digest=636a6f000b503de6ac9f65c9c226b20d6ee72d513ed578547433f3a093061df0INFO:__main__:2023-07-25 09:01:41,284  build_task               INFO    completed a buildINFO:__main__:\nHow to verify disk (volum e) encryption with HPL13000I\nUser data volumes in the HPVS instance are encrypted with Li nux Unified Key Setup (LUKS) \nencryption. The encryption status can be verified by checking the messages in the log. Example C-2 shows verification of disk (volume) encryption. \nExample C-2   Verifying disk (volume) encryption\nconmon[991]: HPL13000I...verify-disk-encryption: Return value for disk-encrypt: 0verify-disk-encryption: Executed cmd: ('lsblk', '-b', '-n', '-o', 'NAME,SIZE')verify-disk-encryption: Return value: 0verify-disk-enc", "metadata": {"source": "sg248555.pdf", "chunk_index": 325, "total_chunks": 337}}
{"text": " cmd: ('lsblk', '-b', '-n', '-o', 'NAME,SIZE')verify-disk-encryption: Return value: 0verify-disk-encryption: Stdout: vda                                           107374182400verify-disk-encryption: ??vda1                                          4292870144verify-disk-encryption: ??vda2                                        103079215104\n\nAppendix C. Additional examples for HPSB and HPVS 119verify-disk-encryption:   ??luks-4089f10e-284b-43aa-ac29-37203fb046c9 103062437888\nverify-disk-encryption: vdb                                                 391168verify-disk-encryption: vdc                                                  45056verify-disk-encryption: List of volumes greater than or equal to 10GB are: ['/dev/vda']verify-disk-encryption: Updated Volumes list: ['/dev/vda2']verify-disk-encryption: Executed cmd: ('lsblk', '/dev/vda2', '-b', '-n', '-o', 'NAME,MOUNTPOINT')verify-disk-encryption: Return value: 0verify-disk-encryption: Stdout: vda2verify-disk-encryption: ??luks-4089f10e-2", "metadata": {"source": "sg248555.pdf", "chunk_index": 326, "total_chunks": 337}}
{"text": "yption: Return value: 0verify-disk-encryption: Stdout: vda2verify-disk-encryption: ??luks-4089f10e-284b-43aa-ac29-37203fb046c9 /verify-disk-encryption: Boot volume is /dev/vda2verify-disk-encryption: Volume /dev/vda2 has mount point /verify-disk-encryption: List of mounted volumes are: ['/dev/vda2']verify-disk-encryption: Verifying the boot disk /dev/vda2 is encrypted or notverify-disk-encryption: Executed cmd: ('lsblk', '/dev/vda2', '-b', '-n', '-o', 'NAME,TYPE')verify-disk-encryption: Return value: 0verify-disk-encryption: Stdout: vda2                                        partverify-disk-encryption: ??luks-4089f10e-284b-43aa-ac29-37203fb046c9 cryptverify-disk-encryption: Executed cmd: ('cryptsetup', 'isLuks', '/dev/vda2')verify-disk-encryption: Return value: 0verify-disk-encryption: Executed cmd: ('cryptsetup', 'luksDump', '/dev/vda2')verify-disk-encryption: Return value: 0verify-disk-encryption: HPL13003I: Checked for mount point /, LUKS encryption with 1 key slot foundverify-disk", "metadata": {"source": "sg248555.pdf", "chunk_index": 327, "total_chunks": 337}}
{"text": "k-encryption: HPL13003I: Checked for mount point /, LUKS encryption with 1 key slot foundverify-disk-encryption: HPL13001I: Boot volume and all the mounted data volumes are encrypted\n\n120 Applying Data Protection and Confident iality in a Hybrid Cloud Environment\n\n\u00a9 Copyright IBM Corp. 2024. 121Appendix D. Encryption keys explained\nKey generation is the process of creating encryption keys that can be used to encrypt and \ndecrypt sensitive data that needs to be protected from unauthorized access. The kind of keys that need to be generated depends on the algorithm used for encryption. Symmetric-key algorithms, such as AES, use a single key for encryption an d decryption. A symmetric- or \nPublic-Key algorithms, such as ECC, use a public-key to encrypt and the corresponding \nprivate-key to decrypt. The keys can be used to generate and verify signatures over data to prove their originality. This is especially useful with asymmetric keys in which the private key \nis used to generate the sign", "metadata": {"source": "sg248555.pdf", "chunk_index": 328, "total_chunks": 337}}
{"text": "his is especially useful with asymmetric keys in which the private key \nis used to generate the signatures and the public  key is sufficient to verify the signatures.\nThe keys are created with algorithms designed to ensure that each key is unique and \nunpredictable. The starting point is usually a seed that is used to generate a series of random \nnumbers to increase the statistical randomness of the algorithm used. A seed can be generated in software, but it can be embedded in hardware, which makes it secure and helps Hardware Security Modules (HSMs) generate random numbers. The generated random numbers can be used to generate encryption keys.\nThe same seed, if it is used with the same algorithm, generates the same encryption key. So, \nit is vitally important to protect the seed.\nFor more details on how seeds are used in confidential computing with Hyper Protect Virtual \nServer (HPVS), see IBM Cloud: Securing your data .\nFor further information on random number generation see 4.3.4, \u201cR", "metadata": {"source": "sg248555.pdf", "chunk_index": 329, "total_chunks": 337}}
{"text": "ee IBM Cloud: Securing your data .\nFor further information on random number generation see 4.3.4, \u201cRandom number \ngeneration\u201d on page 80.\nThis appendix covers the following topics:\n/SM590000\u201cWhat is a master key (MK)\u201d on page 122\n/SM590000\u201cWhat are data encryption keys (DEKs)\u201d on page 122\n/SM590000\u201cWhat are key encryption  keys (KEKs)\u201d on page 123\n/SM590000\u201cUsing and protecting keys\u201d on page 123\n/SM590000\u201cHow encryption keys are created using GREP11\u201d on page 124D\n\n122 Applying Data Protection and Confident iality in a Hybrid Cloud EnvironmentWhat is a master key (MK)\nA Hardware Security Module (HSM) is a physic al device that is used to protect and manage \ncryptographic keys. Before an HSM can be deployed, it must be initialized in a secure environment with a master key. Because all other keys generated by the HSM are derived from the Master Key, it is important to ensure that the master key is not compromised by any one individual. Hence, the master key is often divided into master ke", "metadata": {"source": "sg248555.pdf", "chunk_index": 330, "total_chunks": 337}}
{"text": " key is not compromised by any one individual. Hence, the master key is often divided into master key-parts with each part being owned by different individuals within an organization. See Figure D-1.\nFigure D-1   Multiple master key parts\nAfter the master key is stored in an HSM through the initialization process, the HSM is ready to derive a Data Encryption Key (DEK) or Key Encryption Keys (KEKs). See Figure D-2.\nFigure D-2   HSM initialization process\nWhat are data encryption keys (DEKs)\nA data encryption key is a type of key that is designed to encrypt and decrypt data. DEKs are \ngenerally provided by the application that owns the data being encrypted. Data is encrypted and decrypted with the help of the same DEK. Hence, a DEK must be stored for at least a specified duration for decrypting the generated cypher text. \n\n\nAppendix D. Encryption keys explained 123There are four levels in a DEK lifecycle:\n1. The key is created using the crypto module of the encryption engine.\n2. The key ", "metadata": {"source": "sg248555.pdf", "chunk_index": 331, "total_chunks": 337}}
{"text": "a DEK lifecycle:\n1. The key is created using the crypto module of the encryption engine.\n2. The key is then provided to a key vault and to various other encryption engines.3. The key is used for encrypting and decrypting data.4. The key is then suspended, terminated, or destroyed. \nA DEK can be customized to expire during a particular time frame to prevent data from being \ncompromised. Under such circumstances, it should be used once more for decrypting the data and then the resulting clear text is re-keyed, which means it is encrypted by using a new key.\nWhat are key encryption keys (KEKs)\nAs the name suggests, a key encryption key is used with envelope encryption  to protect a \nDEK from unauthorized use. Envelope encryption is the practice of encrypting plain text data with a data key and then encrypting the data key under another key. \nEnvelope encryption reduces the network load for the application or the cloud service as only \nthe request and fulfillmen t of the much smaller data ", "metadata": {"source": "sg248555.pdf", "chunk_index": 332, "total_chunks": 337}}
{"text": "the application or the cloud service as only \nthe request and fulfillmen t of the much smaller data key through KMS must go over the \nnetwork.\nUsing and protecting keys\nIf the key-generation is performed within an HSM, the seed stays in the HSM at all times. If the seed is generated within a confidential  computing enclave or Trusted Execution \nEnvironment (TEE), encryption keys generated can be used without exposing them to external threats. To achieve the best security, the technologies can be combined.\nWith a Hyper Protect Crypto Services (HPCS) instance connected to an HPVS instance that \nis protected with Secure Execution for Linux,  a simple yet secure signing setup can be \nestablished. This setup can be used to securely generate and use a certificate authority (CA).\nThe whole process can be built into containe rs running within the H PVS instance. First the \nHPCS instance is used to privately generate a new intermediate key pair. This is wrapped within the HSM and exported into ", "metadata": {"source": "sg248555.pdf", "chunk_index": 333, "total_chunks": 337}}
{"text": "to privately generate a new intermediate key pair. This is wrapped within the HSM and exported into the HPVS, where it is stored into an encrypted data volume. This wrapped key can be used only with the HSM backing the HPCS instance. To use this secure key, the container generates a CA certif icate signing request (CSR). This is then in \nturn signed using an external signer with a well-known root certificate. Alternatively the CSR can be self-signed to produce a new root certificate. The resulting certificate can be used to establish a trusted certificate chain on t he leaf certificates to be generated next.\nIn the next step, the intermediate key pair can be used to sign CSRs by itself. This further \nexpands the certificate chain to leaf certificates to be used for means such as TLS, code signing, and so on. Each of these leaf cert ificate keys can either be generated in the \napplication where it is used or within the secure environment.\n\n124 Applying Data Protection and Confident iali", "metadata": {"source": "sg248555.pdf", "chunk_index": 334, "total_chunks": 337}}
{"text": " where it is used or within the secure environment.\n\n124 Applying Data Protection and Confident iality in a Hybrid Cloud EnvironmentHow encryption keys are created using GREP11 \nSecrets like seeds, encryption keys, and certificates are required for applications to perform \ntasks that they are designed to do. Also, the secrets must be protected from unauthorized use.\nWhen you work with a confidenti al computing enclave like HPVS,  the stateless nature of the \nGREP11 (EP11) service offered by HPCS can be used effectively to keep the secrets in a tamper-proof secure  enclave of HPVS. This is  illustrated in Figure D-3.\nFigure D-3   Tamper-proof secure enclave of HPVS\n\n\nISBN DocISBNSG24-8555-00\nISBN DocISBNSG24-8555-00\nISBN DocISBNSG24-8555-00\n(0.1\u201dspine)\n0.1\u201d<->0.169\u201d\n53<->89 pages(0.2\u201dspine)\n0.17\u201d<->0.473\u201d\n90<->249 pages(1.5\u201d spine)\n1.5\u201d<-> 1.998\u201d\n789 <->1051 pages\n(1.0\u201d spine)\n0.875\u201d<->1.498\u201d\n460 <-> 788 pages\n(0.5\u201d spine)\n0.475\u201d<->0.873\u201d\n250 <-> 459 pagesApplying Data Protection and Co", "metadata": {"source": "sg248555.pdf", "chunk_index": 335, "total_chunks": 337}}
{"text": "498\u201d\n460 <-> 788 pages\n(0.5\u201d spine)\n0.475\u201d<->0.873\u201d\n250 <-> 459 pagesApplying Data Protection and Conf identiality in a Hybrid Cloud IBM Hyper Protect Platform:\nApplying Data Protection and IBM Hyper Protect Platform:\nApplying Data Protection and \nApplying Data Protection and Confidentiality in a Hybrid Cloud Environment\n\nISBN DocISBNSG24-8555-00\nISBN DocISBNSG24-8555-00\n(2.0\u201d spine)\n2.0\u201d <-> 2.498\u201d\n1052 <-> 1314 pages(2.5\u201d spine) \n2.5\u201d<->nnn.n\u201d \n1315<-> nnnn pagesIBM Hyper Protect \nPlatform:\nIBM Hyper Protect Platform:\nApplying Data Protection and \nConfidentiality in a Hybrid Cloud \n\n\n\nibm.com /redbooksPrinted in U.S.A .Back cover\nISBN 0738461490SG24-8555-00\n\u00ae\n\n", "metadata": {"source": "sg248555.pdf", "chunk_index": 336, "total_chunks": 337}}
